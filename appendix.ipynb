{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances of the agents. \n",
    "1. Log into wandb api \n",
    "2. Get the list of runs \n",
    "3. For each run, get the summary dict and the analysis df + eval df \n",
    "4. Skip the second part for now \n",
    "5. build and then group the results by\n",
    "    Multiindex,\n",
    "    Rows - tuple \n",
    "        i. algorithm type \n",
    "        ii. use rnn\n",
    "\n",
    "    Columns - \n",
    "        i. R_type_1\n",
    "        ii. R_type 2 \n",
    "    \n",
    "    For each \n",
    "        1. steps \n",
    "        2. rewards \n",
    "        3. assists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"rllib5\"\n",
    "MAX_EPISODES = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total runs: 56\n",
      "Finished runs: 24\n",
      "Failed runs: 32\n",
      "Ongoing runs: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports and connect to wandb -> 'runs' is a list of runs\n",
    "import wandb \n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "api = wandb.Api()\n",
    "entity, project = \"tpn\", WANDB_PROJECT\n",
    "all_runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "runs = []\n",
    "total_runs = finished_runs = failed_runs = ongoing_runs = 0\n",
    "for run in all_runs:\n",
    "    total_runs += 1\n",
    "    if run.state == \"finished\":\n",
    "        runs.append(run)\n",
    "        finished_runs += 1\n",
    "    elif run.state == \"crashed\":\n",
    "        failed_runs += 1\n",
    "    elif run.state == \"running\":\n",
    "        ongoing_runs +=1 \n",
    "print(f\"\"\"\n",
    "Total runs: {total_runs}\n",
    "Finished runs: {finished_runs}\n",
    "Failed runs: {failed_runs}\n",
    "Ongoing runs: {ongoing_runs}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'episode_reward_mean_x', 'episode_len_mean_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m history_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(run\u001b[38;5;241m.\u001b[39m_full_history())\n\u001b[1;32m     46\u001b[0m history_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisodes_total\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 47\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m \u001b[43msample_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_reward_mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_len_mean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m sample_df\u001b[38;5;241m.\u001b[39msort_index(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# sample_df.fillna(method=\"ffill\", inplace=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/predator-prey/.venv/lib/python3.10/site-packages/pandas/core/frame.py:10487\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10468\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10469\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10483\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10485\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10496\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/predator-prey/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    170\u001b[0m         left_df,\n\u001b[1;32m    171\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/predator-prey/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/projects/predator-prey/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:837\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    834\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[1;32m    835\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[0;32m--> 837\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    846\u001b[0m         join_index,\n\u001b[1;32m    847\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    853\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/predator-prey/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2697\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2695\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[0;32m-> 2697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2698\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2699\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2700\u001b[0m     )\n\u001b[1;32m   2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'episode_reward_mean_x', 'episode_len_mean_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "# Performanace DF 1 - all runs; check top for df structure\n",
    "from random import sample\n",
    "\n",
    "name_list = []\n",
    "runs_summary_df = pd.DataFrame(\n",
    "    [],\n",
    "    index=np.arange(len(runs)),\n",
    "    columns=[\n",
    "        \"algorithm_type\",\n",
    "        \"use_lstm\",\n",
    "        \"reward_type\",\n",
    "        \"t_steps\",\n",
    "        \"t_assists\",\n",
    "        \"t_rewards\",\n",
    "        \"e_steps\",\n",
    "        \"e_assists\",\n",
    "        \"e_rewards\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "x_series = list(range(0, MAX_EPISODES, 100))\n",
    "runs_performance_df = pd.DataFrame(\n",
    "    [], index=x_series, columns=pd.MultiIndex.from_tuples([], names=[\"name\", \"type\"])\n",
    ")\n",
    "sample_df = pd.DataFrame([], index=np.arange(0, MAX_EPISODES + 1, 100)).fillna(0)\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    name_list.append(run.name)\n",
    "    # runs_performance_df.loc[(run.config['training'][\"model\"][\"use_lstm\"], run.config[\"algorithm_type\"]),:] = \\\n",
    "    # [1, 1, 1, i, i, i]\n",
    "    runs_summary_df.loc[i] = [\n",
    "        run.config[\"algorithm_type\"],\n",
    "        run.config[\"training\"][\"model\"][\"use_lstm\"],\n",
    "        run.config[\"env_config\"][\"reward_type\"],\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        # run.summary[\"t_steps\"],\n",
    "        # run.summary[\"t_assists\"],\n",
    "        # run.summary[\"t_rewards\"],\n",
    "        # run.summary[\"e_steps\"],\n",
    "        # run.summary[\"e_assists\"],\n",
    "        # run.summary[\"e_rewards\"],\n",
    "    ]\n",
    "    run_history_df = pd.DataFrame(run._full_history())\n",
    "    run_history_df.set_index(\"episodes_total\", inplace=True)\n",
    "    sample_df = sample_df.merge(\n",
    "        run_history_df[[\"episode_reward_mean\", \"episode_len_mean\"]],\n",
    "        how=\"outer\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    sample_df = sample_df.T\n",
    "    sample_df.sort_index(axis=1, inplace=True)\n",
    "runs_history_df = pd.DataFrame(\n",
    "    [],\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [[True, False],['independent', 'centralized', 'shared']],\n",
    "        names = [\"use_rnn\", \"agent_type\"]\n",
    "    ),\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [[\"type_1\", \"type_2\"], [\"steps\", \"reward\", \"assits\"]],\n",
    "        names = [\"reward_type\", \"metric (cumulative)\"])\n",
    ").fillna(0.0)\n",
    "    # sample_df.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "print(f\"Number of runs: {len(name_list)}\")\n",
    "# print(runs_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward_type         type_1               type_2              \n",
      "metric (cumulative)  steps reward assits  steps reward assits\n",
      "use_rnn agent_type                                           \n",
      "True    independent    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "        centralized    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "        shared         0.0    0.0    0.0    0.0    0.0    0.0\n",
      "False   independent    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "        centralized    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "        shared         0.0    0.0    0.0    0.0    0.0    0.0\n"
     ]
    }
   ],
   "source": [
    "gropued_df = runs_summary_df.groupby([\"algorithm_type\", \"use_lstm\", 'reward_type']).mean()\n",
    "runs_performance_df = pd.DataFrame(\n",
    "    [],\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [[True, False],['independent', 'centralized', 'shared']],\n",
    "        names = [\"use_rnn\", \"agent_type\"]\n",
    "    ),\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [[\"type_1\", \"type_2\"], [\"steps\", \"reward\", \"assits\"]],\n",
    "        names = [\"reward_type\", \"metric (cumulative)\"])\n",
    ").fillna(0.0)\n",
    "for i, row in gropued_df.iterrows():\n",
    "    runs_performance_df.loc[(i[1], i[0]), (i[2], \"steps\")] = row[\"t_steps\"]\n",
    "    runs_performance_df.loc[(i[1], i[0]), (i[2], \"reward\")] = row[\"t_rewards\"]\n",
    "    runs_performance_df.loc[(i[1], i[0]), (i[2], \"assits\")] = row[\"t_assists\"]\n",
    "print(runs_performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training.model.use_lstm: true - _step</th>\n",
       "      <th>training.model.use_lstm: true - _step__MIN</th>\n",
       "      <th>training.model.use_lstm: true - _step__MAX</th>\n",
       "      <th>training.model.use_lstm: true - episode_len_mean</th>\n",
       "      <th>training.model.use_lstm: true - episode_len_mean__MIN</th>\n",
       "      <th>training.model.use_lstm: true - episode_len_mean__MAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1746.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8330.038946</td>\n",
       "      <td>72.928599</td>\n",
       "      <td>72.855097</td>\n",
       "      <td>73.002291</td>\n",
       "      <td>69.259543</td>\n",
       "      <td>68.966100</td>\n",
       "      <td>69.538288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4208.590735</td>\n",
       "      <td>33.811555</td>\n",
       "      <td>33.765298</td>\n",
       "      <td>33.863979</td>\n",
       "      <td>12.037706</td>\n",
       "      <td>12.008207</td>\n",
       "      <td>12.188978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "      <td>46.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4656.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>59.856250</td>\n",
       "      <td>59.402500</td>\n",
       "      <td>59.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8190.500000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>66.310000</td>\n",
       "      <td>66.065000</td>\n",
       "      <td>66.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11914.750000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>76.620000</td>\n",
       "      <td>76.120000</td>\n",
       "      <td>77.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16523.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       episodes_total  training.model.use_lstm: true - _step  \\\n",
       "count     1746.000000                            1746.000000   \n",
       "mean      8330.038946                              72.928599   \n",
       "std       4208.590735                              33.811555   \n",
       "min          2.000000                               0.000000   \n",
       "25%       4656.500000                              44.000000   \n",
       "50%       8190.500000                              73.000000   \n",
       "75%      11914.750000                             102.000000   \n",
       "max      16523.000000                             135.000000   \n",
       "\n",
       "       training.model.use_lstm: true - _step__MIN  \\\n",
       "count                                 1746.000000   \n",
       "mean                                    72.855097   \n",
       "std                                     33.765298   \n",
       "min                                      0.000000   \n",
       "25%                                     44.000000   \n",
       "50%                                     73.000000   \n",
       "75%                                    102.000000   \n",
       "max                                    135.000000   \n",
       "\n",
       "       training.model.use_lstm: true - _step__MAX  \\\n",
       "count                                 1746.000000   \n",
       "mean                                    73.002291   \n",
       "std                                     33.863979   \n",
       "min                                      0.000000   \n",
       "25%                                     44.000000   \n",
       "50%                                     73.000000   \n",
       "75%                                    102.000000   \n",
       "max                                    136.000000   \n",
       "\n",
       "       training.model.use_lstm: true - episode_len_mean  \\\n",
       "count                                       1746.000000   \n",
       "mean                                          69.259543   \n",
       "std                                           12.037706   \n",
       "min                                           46.150000   \n",
       "25%                                           59.856250   \n",
       "50%                                           66.310000   \n",
       "75%                                           76.620000   \n",
       "max                                          101.000000   \n",
       "\n",
       "       training.model.use_lstm: true - episode_len_mean__MIN  \\\n",
       "count                                        1746.000000       \n",
       "mean                                           68.966100       \n",
       "std                                            12.008207       \n",
       "min                                            46.150000       \n",
       "25%                                            59.402500       \n",
       "50%                                            66.065000       \n",
       "75%                                            76.120000       \n",
       "max                                           101.000000       \n",
       "\n",
       "       training.model.use_lstm: true - episode_len_mean__MAX  \n",
       "count                                        1746.000000      \n",
       "mean                                           69.538288      \n",
       "std                                            12.188978      \n",
       "min                                            46.150000      \n",
       "25%                                            59.982500      \n",
       "50%                                            66.590000      \n",
       "75%                                            77.130000      \n",
       "max                                           101.000000      "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance graphs data load from csvs and plot   \n",
    "steps_df = pd.read_csv(\"/home/priyam/projects/predator-prey/temp/wandb_export_2023-12-10T18 32 01.717+11 00.csv\")\n",
    "# matplolib make figure \n",
    "# 2x3 subplots\n",
    "# 1. subplot 1.[1-3] - steps, rewards, assists vs epsiodes (without rnns)\n",
    "# 2. subplot 1.[4-6] - steps, rewards, assists vs epsiodes (with rnns)\n",
    "# for each subplot 3 lines - independent, centralized, shared\n",
    "steps_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
