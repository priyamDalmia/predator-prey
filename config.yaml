algorithm_type: "independent"
algorithm_class: "ppo"
framework: "torch"
tune:
   tune: true # if true, tune hyperparameters in main!
   num_samples: 2
   max_episodes: 25000
   max_concurrent_trials: 6
training:
   lr: 0.0001
   use_critic: true
   use_kl_loss: true
   sgd_minibatch_size: 128
   num_sgd_iter: 5
   train_batch_size: 500
   model: 
      conv_filters: [[16, [3, 3], 2]]
      fcnet_hiddens: [256, 256]
      fcnet_activation: "relu"
      conv_activation: "relu"
evaluate:
   eval_episodes: 100
rollouts:
   num_rollout_workers: 0
   batch_mode: "complete_episodes"
wandb: 
   wandb_init: true 
   wandb_project: "rllib4"
   wandb_entity: "tpn"
   wandb_notes: "testing setup"
   wandb_log_freq: 10
env_name: "discrete_pp_v1"
env_config:
   map_size: 15
   pred_vision: 2
   prey_type: "static"
   max_cycles: 100
   npred: 2
   nprey: 6
   reward_type: "type_1"
ray:
   init_dashboard: false