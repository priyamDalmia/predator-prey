algorithm_type: "independent"
algorithm_class: "ppo"
framework: "torch"
tune:
   tune: true # if true, tune hyperparameters in main!
   num_samples: 1
   max_episodes: 100000
training:
   lr: 0.0001
   use_critic: true
   use_kl_loss: true
   sgd_minibatch_size: 128
   num_sgd_iter: 10
   train_batch_size: 200
   model: 
      conv_filters: [[16, [2, 2], 2], [16, [4, 4], 1]]
      fcnet_hiddens: [256, 256]
      fcnet_activation: "relu"
evaluate:
   eval_episodes: 100
rollouts:
   num_rollout_workers: 0
wandb: 
   wandb_init: false 
   wandb_project: "rllib3"
   wandb_entity: "tpn"
   wandb_notes: "testing setup"
env_name: "discrete_pp_v1"
env_config:
   map_size: 20
   pred_vision: 2
   prey_type: "static"
   max_cycles: 100
   npred: 2
   nprey: 6
   reward_type: "type_1"
ray:
   init_dashboard: false