
Name of the cluster on which the job is executing:
	 spartan
Number of CPUs on the allocated node: 
	 6
Number of CPUs requested per task: 
	 6
Numer of GPUs requested: 
	 
Requested GPU count per allocated node: 
	 
Requested GPU count per allocated task:
	  
The ID of the job allocation:
	  53748017
Count of processors available to the job on this node:
	  6
Name of the job:
	  tst.slurm
List of nodes allocated to the job:
	  spartan-gpgpu092
Total number of nodes in the job’s resource allocation:
	  1
Name of the partition in which the job is running:
	  deeplearn
Minimum memory required per allocated CPU:
	  4000
Requested memory per allocated GPU:
	  
Total amount of memory per node that the job needs:
	  
List of nodes allocated to the job:
	  spartan-gpgpu092
Total number of CPUs allocated:
	  1
Maximum number of MPI tasks (that’s processes): 
	 1
Number of tasks requested per core: 
	 
Number of tasks requested per GPU: 
	 
Number of tasks requested per node:
	  1
The scheduling priority (nice value) at the time of job submission. This value is propagated to the spawned processes: 
	 0
The MPI rank (or relative process ID) of the current process: 
	 0
The directory from which SBATCH was invoked: 
	 /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey
The Hostname of the computer from which SBATCH was invoked: 
	 spartan-login1.hpc.unimelb.edu.au
The process ID of the corresponding task: 
	 152505



 LOADING MODULES: 




 PYTHON SCRIPT OUTPUT: 

2023-11-24 01:36:29,086	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2023-11-24 01:36:30,723	INFO worker.py:1673 -- Started a local Ray instance.
2023-11-24 01:36:32,700	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2023-11-24 01:36:32,701	INFO tune.py:595 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
[36m(pid=153971)[0m 2023-11-24 01:36:35,468	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2023-11-24 01:36:35,755	INFO wandb.py:307 -- Already logged into W&B.
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id fye3a144.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m `UnifiedLogger` will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   return UnifiedLogger(config, logdir, loggers=None)
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 02:34:37,183	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████████▇▇▆▇▆▇▅▆▆▃▄▆▅▄▄▃▃▃▅▃▅▄▄▃▂▂▄▁▂
wandb:   episode_reward_mean ▁▁▁▂▁▂▂▃▄▄▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇██
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 88.1
wandb:   episode_reward_mean 4.75
wandb:        episodes_total 10000
wandb: num_env_steps_sampled 961858
wandb: num_env_steps_trained 0
wandb:          time_total_s 3298.09098
wandb:    training_iteration 4452
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_013636-fye3a144
wandb: Find logs at: ./wandb/offline-run-20231124_013636-fye3a144/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 8iz2375p.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m `UnifiedLogger` will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   return UnifiedLogger(config, logdir, loggers=None)
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=153971)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=153971)[0m The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=153971)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 03:09:59,597	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean █████████▇▇▇▇▆▇▆▇▇▇▇▆▆▆▅▃▄▃▄▃▂▂▂▃▂▃▂▂▂▂▁
wandb:   episode_reward_mean ▁▁▁▂▃▃▄▅▄▅▅▅▅▆▅▆▅▅▆▆▆▆▆▇▇▇█▇████████████
wandb:        episodes_total ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 63.0
wandb:   episode_reward_mean 5.79
wandb:        episodes_total 9992
wandb: num_env_steps_sampled 833705
wandb: num_env_steps_trained 0
wandb:          time_total_s 1999.47818
wandb:    training_iteration 3696
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_023437-8iz2375p
wandb: Find logs at: ./wandb/offline-run-20231124_023437-8iz2375p/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id yf075i3c.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 04:06:08,549	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean █████████████▆▇▇▇▆▆▆▆▅▅▆▆▅▅▃▅▄▃▄▄▃▂▃▂▁▁▂
wandb:   episode_reward_mean ▁▁▁▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇█▇████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 82.34
wandb:   episode_reward_mean 5.315
wandb:        episodes_total 9999
wandb: num_env_steps_sampled 950372
wandb: num_env_steps_trained 0
wandb:          time_total_s 3189.28878
wandb:    training_iteration 4368
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_030959-yf075i3c
wandb: Find logs at: ./wandb/offline-run-20231124_030959-yf075i3c/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 5zbt9szd.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 04:42:11,685	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████████▇█▇▇▇▇▇▇▆▇▇▆▆▆▆▅▅▄▃▃▃▂▃▁▃▂▁▂▁
wandb:   episode_reward_mean ▁▁▁▁▂▂▃▃▄▄▅▄▅▅▅▅▅▅▅▆▆▅▆▆▆▆▆▇▇███████████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇██
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 67.5
wandb:   episode_reward_mean 5.85
wandb:        episodes_total 9997
wandb: num_env_steps_sampled 857855
wandb: num_env_steps_trained 0
wandb:          time_total_s 2034.25587
wandb:    training_iteration 3852
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_040608-5zbt9szd
wandb: Find logs at: ./wandb/offline-run-20231124_040608-5zbt9szd/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id quozj8t5.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 05:39:06,101	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ██████████▇▇▇▇▇▅▅▅▃▅▅▃▅▄▅▁▃▄▄▂▃▄▄▃▄▃▄▃▃▁
wandb:   episode_reward_mean ▁▁▁▁▂▂▂▃▃▅▅▅▆▆▆▇▇▇▆▇▇█▇█▇██▇▇███▇███████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 87.75
wandb:   episode_reward_mean 5.18
wandb:        episodes_total 9999
wandb: num_env_steps_sampled 960653
wandb: num_env_steps_trained 0
wandb:          time_total_s 3229.63098
wandb:    training_iteration 4437
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_044211-quozj8t5
wandb: Find logs at: ./wandb/offline-run-20231124_044211-quozj8t5/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 0sgz6yl4.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 06:18:59,390	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████▇▇▆▇▇▅▅▆▄▅▅▃▄▃▃▄▄▂▃▂▂▃▄▃▃▂▃▂▃▃▅▁▃
wandb:   episode_reward_mean ▁▂▂▂▄▄▄▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇█▇▇█▇▇▇▇▇▇██▇▆▇▇
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 91.74
wandb:   episode_reward_mean 4.76
wandb:        episodes_total 9995
wandb: num_env_steps_sampled 946875
wandb: num_env_steps_trained 0
wandb:          time_total_s 2246.1579
wandb:    training_iteration 4323
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_053906-0sgz6yl4
wandb: Find logs at: ./wandb/offline-run-20231124_053906-0sgz6yl4/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 7gymh50n.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=153971)[0m Install gputil for GPU system monitoring.
2023-11-24 07:11:49,826	ERROR tune_controller.py:1383 -- Trial task failed for trial train_algo_b2630_00006
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=153971, ip=172.26.92.193, actor_id=f8f993ff725b9bd4909f99e501000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 249, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 208, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 122] Disk quota exceeded
╭───────────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_algo_2023-11-24_01-36-29   │
├───────────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator            │
│ Scheduler                        FIFOScheduler                    │
│ Number of trials                 30                               │
╰───────────────────────────────────────────────────────────────────╯

View detailed results here: /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/experiments/train_algo_2023-11-24_01-36-29
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/dalmiapriyam/ray_results/train_algo_2023-11-24_01-36-29`

Trial status: 1 PENDING
Current time: 2023-11-24 01:36:32. Total running time: 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
╭───────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type   │
├───────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   PENDING    independent        type_1                 │
╰───────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00000 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00000 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 1 RUNNING
Current time: 2023-11-24 01:37:02. Total running time: 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1458c00e28c0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                       35            24.0352   7070    1.47143                      5                      0                  101                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:37:33. Total running time: 1min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c1832e0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                       76            52.5018   15352       1.69                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:38:03. Total running time: 1min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c182200>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      117            80.9283   23634       1.67                      4                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:38:33. Total running time: 2min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c181a20>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      158             109.37   31916       1.69                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:39:03. Total running time: 2min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c182560>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      199            137.693   40198        1.6                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:39:33. Total running time: 3min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c06ee60>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      240            166.017   48480       1.62                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:40:03. Total running time: 3min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c182320>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      280                194   56627       1.73                      6                      0               100.66                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:40:33. Total running time: 4min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1458c013e170>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      321            222.356   64909       1.83                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:41:03. Total running time: 4min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c06e680>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      362            250.709   73191       1.85                      4                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:41:33. Total running time: 5min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c06f400>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      403            279.168   81473       1.88                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:42:03. Total running time: 5min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1458c013e170>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      444             307.51   89755       1.69                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:42:33. Total running time: 6min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.92 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c06c5e0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      484            335.636   97928       1.77                      6                      0               100.92                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:43:03. Total running time: 6min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.78 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c181b40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      525            364.181   106289       1.87                      6                      0               100.78                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:43:33. Total running time: 7min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c181510>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      566            392.442   114571       2.07                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:44:03. Total running time: 7min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c0d4700>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      607             420.81   122853       2.14                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:44:33. Total running time: 8min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c181510>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      648            449.159   131135       2.18                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:45:03. Total running time: 8min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c0d6dd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      689            477.621   139417       1.89                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:45:33. Total running time: 9min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c0d6dd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      730            506.031   147699       1.99                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:46:04. Total running time: 9min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c0d7400>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      771            534.354   155981       2.25                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:46:34. Total running time: 10min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817744c10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      812            562.952   164263       2.48                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:47:04. Total running time: 10min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.9 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c182680>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      852            590.928   172434       2.63                      6                      0                100.9                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:47:34. Total running time: 11min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.9 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c182170>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      893            619.298   180716       2.68                      6                      0                100.9                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:48:04. Total running time: 11min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817761ea0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      934            647.713   188998       2.89                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:48:34. Total running time: 12min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.15 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817761750>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                      974            675.748   197195       2.87                      6                      0               100.15                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:49:04. Total running time: 12min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.41 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14589856ec20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1015             704.36   205549       2.71                      6                      0               100.41                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:49:34. Total running time: 13min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.68 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817746c20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1055             732.47   213726       2.87                      6                      0               100.68                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:50:04. Total running time: 13min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.14 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817747490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1095            761.239   222128       3.16                      6                      0               100.14                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:50:34. Total running time: 14min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448177627a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1135            789.788   230452       3.31                      6                      0                100.1                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:51:04. Total running time: 14min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c06e4d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1175            817.651   238599       3.18                      6                      0               100.66                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:51:34. Total running time: 15min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=98.43 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c06e4d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1215            846.192   246927       3.41                      6                      0                98.43                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:52:04. Total running time: 15min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.82 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c0d6dd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1255             874.62   255191        3.3                      6                      0               100.82                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:52:34. Total running time: 16min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=100.31 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14589856ec20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1295            903.299   263518       3.63                      6                      1               100.31                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:53:04. Total running time: 16min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=99.89 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817760b80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1334            931.795   271790       3.62                      6                      0                99.89                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:53:34. Total running time: 17min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=99.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817795bd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1373            959.784   279965       3.66                      6                      0                99.66                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:54:04. Total running time: 17min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=99.65 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481779cca0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1412            988.057   288228       3.67                      6                      0                99.65                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:54:34. Total running time: 18min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=98.91 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14589856ec20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1451            1017.16   296719       3.74                      6                      1                98.91                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:55:04. Total running time: 18min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=98.07 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817797be0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1491            1045.64   305018       3.57                      6                      0                98.07                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:55:34. Total running time: 19min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=99.65 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817795900>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1530            1073.55   313165       3.73                      6                      1                99.65                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:56:04. Total running time: 19min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=99.32 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448177940d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1569            1102.42   321582        3.8                      6                      0                99.32                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:56:34. Total running time: 20min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=97.94 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14589856ec20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1607            1130.33   329707       3.89                      6                      1                97.94                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:57:05. Total running time: 20min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.52 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14589856ec20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1646            1158.83   338054        3.9                      6                      1                96.52                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:57:35. Total running time: 21min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=98.9 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817760b80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1686            1187.69   346485       3.78                      6                      0                 98.9                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:58:05. Total running time: 21min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=98.27 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144816352b90>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1725            1215.99   354702       3.79                      6                      0                98.27                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:58:35. Total running time: 22min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.38 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817747c70>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1763            1244.59   363052       4.08                      6                      0                96.38                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:59:05. Total running time: 22min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=99.26 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481779f9a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1802            1273.18   371384        3.8                      6                      0                99.26                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:59:35. Total running time: 23min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=98.94 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144816384ee0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1839            1301.25   379561       3.92                      6                      1                98.94                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:00:05. Total running time: 23min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=97.3 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144816386e60>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1877            1329.46   387790       4.06                      6                      0                 97.3                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:00:35. Total running time: 24min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.68 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163b9000>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1917            1358.74   396322       4.03                      6                      1                95.68                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:01:05. Total running time: 24min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=97.03 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144816353520>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1954             1386.8   404511        4.1                      6                      1                97.03                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:01:35. Total running time: 25min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=97.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144817747c70>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     1992            1415.13   412774       4.09                      6                      0                97.66                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:02:05. Total running time: 25min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.32 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144816386a70>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2031             1443.9   421155       4.31                      6                      2                96.32                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:02:35. Total running time: 26min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163bad40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2069            1472.56   429575       4.18                      6                      1                96.93                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:03:05. Total running time: 26min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.19 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163b93f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2106            1501.19   437900       4.19                      6                      1                94.19                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:03:35. Total running time: 27min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.32 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163bb5b0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2144            1529.45   446187       4.24                      6                      1                96.32                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:04:05. Total running time: 27min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.61 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163b8dc0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2182            1558.21   454601          4                      6                      0                96.61                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:04:35. Total running time: 28min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.89 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144816353520>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2220            1586.92   462973       4.21                      6                      0                95.89                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:05:05. Total running time: 28min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.14 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b04790>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2258            1615.56   471364       4.23                      6                      2                93.14                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:05:35. Total running time: 29min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.88 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3c1f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2294            1644.07   479648       4.32                      6                      2                95.88                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:06:05. Total running time: 29min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.88 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3ea70>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2331            1672.09   487824       4.54                      6                      1                93.88                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:06:35. Total running time: 30min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.5 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3e8c0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2370            1700.47   496086       4.26                      6                      1                 96.5                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:07:06. Total running time: 30min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.94 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3d750>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2409            1729.71   504642       4.17                      6                      0                94.94                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:07:36. Total running time: 31min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.35 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b04790>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2447            1757.99   512888       4.28                      6                      1                96.35                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:08:06. Total running time: 31min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.85 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b751b0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2483            1786.41   521160        4.2                      6                      0                95.85                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:08:36. Total running time: 32min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=97.06 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b74c10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2521            1814.89   529469       4.16                      6                      0                97.06                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:09:06. Total running time: 32min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.34 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3c0d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2558            1843.27   537739       4.43                      6                      1                95.34                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:09:36. Total running time: 33min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.56 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b77760>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2596            1872.03   546115       4.24                      6                      0                96.56                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:10:06. Total running time: 33min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.42 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3e3b0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2633            1900.46   554424       4.45                      6                      2                94.42                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:10:36. Total running time: 34min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.07 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3de10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2670            1929.45   562873       4.36                      6                      0                96.07                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:11:06. Total running time: 34min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.2 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b06e60>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2707            1957.46   571053       4.03                      6                      0                 96.2                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:11:36. Total running time: 35min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.77 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163bad40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2744            1986.16   579420       4.32                      6                      1                93.77                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:12:06. Total running time: 35min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.35 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b77490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2781            2014.61   587710       4.52                      6                      1                92.35                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:12:36. Total running time: 36min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.61 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163bad40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2819            2043.35   596123       4.41                      6                      0                94.61                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:13:06. Total running time: 36min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.07 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfeb0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2856            2071.44   604285       4.47                      6                      1                96.07                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:13:36. Total running time: 37min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.38 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbc5e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2893            2100.21   612713       4.31                      6                      1                94.38                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:14:06. Total running time: 37min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.39 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbea70>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2929            2128.75   621043        4.5                      6                      0                92.39                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:14:36. Total running time: 38min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.04 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b77490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     2968            2157.22   629323       4.24                      6                      1                96.04                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:15:06. Total running time: 38min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.74 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448149ff400>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3006             2185.6   637607       4.43                      6                      0                93.74                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:15:36. Total running time: 39min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.42 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b76c20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3043            2213.86   645858       4.24                      6                      0                93.42                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:16:06. Total running time: 39min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.92 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbd510>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3081            2242.39   654153        4.4                      6                      1                92.92                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:16:36. Total running time: 40min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=90.97 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b05e10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3117            2271.06   662487       4.64                      6                      0                90.97                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:17:06. Total running time: 40min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=91.27 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448149ff9a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3154            2300.11   670960       4.49                      6                      2                91.27                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:17:36. Total running time: 41min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.77 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3de10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3191             2328.3   679207       4.35                      6                      1                94.77                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:18:06. Total running time: 41min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.04 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814a47130>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3229            2356.99   687549       4.21                      6                      2                96.04                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:18:37. Total running time: 42min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.96 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448163bad40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3267            2385.18   695789       4.28                      6                      1                95.96                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:19:07. Total running time: 42min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.35 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814aa0040>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3304            2413.49   704046       4.38                      6                      2                96.35                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:19:37. Total running time: 43min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.09 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814a47b50>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3343            2443.07   712678       4.27                      6                      1                93.09                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:20:07. Total running time: 43min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=89.78 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3de10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3380            2471.63   721013       4.54                      6                      1                89.78                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:20:37. Total running time: 44min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.6 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b77d90>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3417            2499.82   729214       4.46                      6                      1                 92.6                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:21:07. Total running time: 44min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=97.39 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814aa3f40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3455            2528.23   737511       4.36                      6                      1                97.39                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:21:37. Total running time: 45min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.69 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814b3de10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3493            2557.32   745992       4.48                      6                      1                95.69                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:22:07. Total running time: 45min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.62 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814aa3e20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3531            2586.02   754360       4.43                      6                      1                93.62                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:22:37. Total running time: 46min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=94.27 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814aa30a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3567            2613.81   762426        4.5                      6                      0                94.27                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:23:07. Total running time: 46min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad5ab0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3604            2643.17   770929       4.44                      6                      1                92.66                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:23:37. Total running time: 47min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=96.78 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad79a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3643            2671.37   779187       4.36                      6                      1                96.78                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:24:07. Total running time: 47min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.46 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814aa3640>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3680            2699.62   787423       4.56                      6                      1                92.46                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:24:37. Total running time: 48min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.74 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad5bd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3719            2728.28   795750       4.35                      6                      1                92.74                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:25:07. Total running time: 48min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.53 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad6170>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3757            2757.18   804195       4.66                      6                      0                92.53                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:25:37. Total running time: 49min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=91.04 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad67a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3794            2785.37   812351       4.52                      6                      1                91.04                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:26:07. Total running time: 49min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.39 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814912b90>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3833            2814.17   820758       4.48                      6                      0                92.39                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:26:37. Total running time: 50min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.73 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814912ef0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3870            2842.81   829095        4.5                      6                      1                93.73                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:27:07. Total running time: 50min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.49 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad75b0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3906            2870.88   837279       4.39                      6                      0                92.49                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:27:37. Total running time: 51min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=91.73 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814a45480>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3944            2899.78   845717       4.37                      6                      1                91.73                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:28:07. Total running time: 51min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=95.01 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448149391b0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     3981             2927.9   853900       4.17                      6                      0                95.01                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:28:37. Total running time: 52min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=91.65 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481493a8c0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4017            2956.75   862349       4.68                      6                      1                91.65                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:29:08. Total running time: 52min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.08 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481493b7f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4054            2984.83   870529       4.32                      6                      1                93.08                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:29:38. Total running time: 53min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=92.5 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448149a0c10>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4092            3014.16   879090       4.44                      6                      0                 92.5                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:30:08. Total running time: 53min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=91.72 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad7490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4128            3042.81   887447       4.31                      6                      1                91.72                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:30:38. Total running time: 54min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.73 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad7490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4165            3070.73   895558       4.36                      6                      0                93.73                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:31:08. Total running time: 54min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=93.41 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad6440>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4203               3099   903831       4.39                      6                      0                93.41                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:31:38. Total running time: 55min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.84 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448149a3eb0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4239            3128.37   912395       4.55                      6                      2                88.84                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:32:08. Total running time: 55min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814a44820>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4274             3156.8   920655       4.74                      6                      1                88.66                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:32:38. Total running time: 56min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=91.75 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad5cf0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4312            3185.44   929014       4.49                      6                      2                91.75                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:33:08. Total running time: 56min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=90.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814ad67a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4348            3213.98   937349       4.57                      6                      1                 90.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:33:38. Total running time: 57min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=86.69 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814913be0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4383            3242.97   945816       4.84                      6                      1                86.69                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:34:08. Total running time: 57min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=90.66 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448149e1ea0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00000   RUNNING    independent        type_1                     4419            3271.13   954034       4.63                      6                      1                90.66                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00000 completed after 4452 iterations at 2023-11-24 02:34:37. Total running time: 58min 4s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00000 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                       10000 │
│ time_this_iter_s                                                                   0.98303 │
│ time_total_s                                                                    3298.09098 │
│ timesteps_total                                                                     961858 │
│ training_iteration                                                                    4452 │
│ agent_timesteps_total                                                              1923716 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                         0.003401517868041992 │
│ connector_metrics/StateBufferConnector_ms                             0.002613067626953125 │
│ connector_metrics/ViewRequirementAgentConnector_ms                     0.16125833988189697 │
│ counters/num_agent_steps_sampled                                                   1923716 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      961858 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               0 │
│ custom_metrics/assists_mean                                                            0.0 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             4.75 │
│ custom_metrics/kills_min                                                                 2 │
│ custom_metrics/predator_0_assists_max                                                    0 │
│ custom_metrics/predator_0_assists_mean                                                 0.0 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      6 │
│ custom_metrics/predator_0_kills_mean                                                  2.35 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    0 │
│ custom_metrics/predator_1_assists_mean                                                 0.0 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      6 │
│ custom_metrics/predator_1_kills_mean                                                   2.4 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                      88.1 │
│ episode_reward_max                                                                      6. │
│ episode_reward_mean                                                                   4.75 │
│ episode_reward_min                                                                      2. │
│ episodes_this_iter                                                                       4 │
│ hist_stats/episode_lengths                                            ... 86, 57, 39, 101] │
│ hist_stats/episode_reward                                             ...0, 6.0, 6.0, 4.0] │
│ hist_stats/policy_predator_0_reward                                   ...0, 4.0, 4.0, 3.0] │
│ hist_stats/policy_predator_1_reward                                   ...0, 2.0, 2.0, 1.0] │
│ info/learner/__all__/num_agent_steps_trained                                         256.0 │
│ info/learner/__all__/num_env_steps_trained                                           283.0 │
│ info/learner/__all__/total_loss                                         2.4287803868452706 │
│ info/learner/predator_0/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_0/curr_lr                                                     0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_0/entropy                                          1.250554084777832 │
│ info/learner/predator_0/mean_kl_loss                                 7.794139345188947e-06 │
│ info/learner/predator_0/policy_loss                                   0.026012492055694263 │
│ info/learner/predator_0/total_loss                                      2.4287803868452706 │
│ info/learner/predator_0/vf_explained_var                              0.039013803005218506 │
│ info/learner/predator_0/vf_loss                                         1.0204485480984051 │
│ info/learner/predator_0/vf_loss_unclipped                               1.0204485480984051 │
│ info/learner/predator_1/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_1/curr_lr                                                     0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_1/entropy                                          1.261138955752055 │
│ info/learner/predator_1/mean_kl_loss                                 5.337602891586357e-05 │
│ info/learner/predator_1/policy_loss                                   -0.06060700615247091 │
│ info/learner/predator_1/total_loss                                      1.3823193063338597 │
│ info/learner/predator_1/vf_explained_var                              -0.20331707100073496 │
│ info/learner/predator_1/vf_loss                                         1.4429263000686963 │
│ info/learner/predator_1/vf_loss_unclipped                                1.451655941704909 │
│ info/num_agent_steps_sampled                                                       1923716 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          961858 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1923716 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               961858 │
│ num_env_steps_sampled_this_iter                                                        283 │
│ num_env_steps_sampled_throughput_per_sec                                         288.97678 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                 8.65 │
│ perf/ram_util_percent                                                                 19.6 │
│ policy_reward_max/predator_0                                                           6.0 │
│ policy_reward_max/predator_1                                                           6.0 │
│ policy_reward_mean/predator_0                                                         2.35 │
│ policy_reward_mean/predator_1                                                          2.4 │
│ policy_reward_min/predator_0                                                           0.0 │
│ policy_reward_min/predator_1                                                           0.0 │
│ sampler_perf/mean_action_processing_ms                                 0.15092669513666054 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.11021224723600874 │
│ sampler_perf/mean_inference_ms                                          2.2616434234115643 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5880215861376598 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms         0.003401517868041992 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.002613067626953125 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms     0.16125833988189697 │
│ sampler_results/custom_metrics/assists_max                                               0 │
│ sampler_results/custom_metrics/assists_mean                                            0.0 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             4.75 │
│ sampler_results/custom_metrics/kills_min                                                 2 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    0 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                 0.0 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                  2.35 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    0 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                 0.0 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   2.4 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                      88.1 │
│ sampler_results/episode_reward_max                                                     6.0 │
│ sampler_results/episode_reward_mean                                                   4.75 │
│ sampler_results/episode_reward_min                                                     2.0 │
│ sampler_results/episodes_this_iter                                                       4 │
│ sampler_results/hist_stats/episode_lengths                            ... 86, 57, 39, 101] │
│ sampler_results/hist_stats/episode_reward                             ...0, 6.0, 6.0, 4.0] │
│ sampler_results/hist_stats/policy_predator_0_reward                   ...0, 4.0, 4.0, 3.0] │
│ sampler_results/hist_stats/policy_predator_1_reward                   ...0, 2.0, 2.0, 1.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/predator_0                                           6.0 │
│ sampler_results/policy_reward_max/predator_1                                           6.0 │
│ sampler_results/policy_reward_mean/predator_0                                         2.35 │
│ sampler_results/policy_reward_mean/predator_1                                          2.4 │
│ sampler_results/policy_reward_min/predator_0                                           0.0 │
│ sampler_results/policy_reward_min/predator_1                                           0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                 0.15092669513666054 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.11021224723600874 │
│ sampler_results/sampler_perf/mean_inference_ms                          2.2616434234115643 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5880215861376598 │
│ timers/sample_time_ms                                                              756.193 │
│ timers/synch_weights_time_ms                                                         0.933 │
│ timers/training_iteration_time_ms                                                  824.098 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00001 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00001 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:34:39. Total running time: 58min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                                                                                                                                                           │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:35:09. Total running time: 58min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                       57            27.7048    11514       1.7                       4                      0                101                        2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:35:39. Total running time: 59min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      115            56.0932    23230       1.85                      4                      0                101                        2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:36:09. Total running time: 59min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      172            84.0343    34744       1.74                      5                      0                101                        2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:36:39. Total running time: 1hr 0min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      229            111.996    46258       2.17                      6                      0                101                        2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:37:09. Total running time: 1hr 0min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      286            139.854    57772       2.05                      5                      0                101                        2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:37:39. Total running time: 1hr 1min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      343            168.079    69430       2.41                      6                      0               100.42                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:38:09. Total running time: 1hr 1min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      400            196.377    81068       2.68                      6                      0               100.22                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:38:39. Total running time: 1hr 2min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      457            224.458    92679       2.88                      6                      0               100.96                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:39:09. Total running time: 1hr 2min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      512            252.316   104197       3.15                      6                      1               100.03                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:39:39. Total running time: 1hr 3min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      568            280.623   115869       3.36                      6                      0                99.82                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:40:09. Total running time: 1hr 3min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      624            309.172   127662       3.59                      6                      1                99.75                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:40:39. Total running time: 1hr 4min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      678            337.141   139232       3.66                      6                      0                98.53                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:41:09. Total running time: 1hr 4min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      732            365.281   150803       4.17                      6                      1                97.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:41:39. Total running time: 1hr 5min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      787            393.546   162512       3.76                      6                      0                 99                        2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:42:09. Total running time: 1hr 5min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      841            421.918   174201       3.91                      6                      1                98.34                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:42:40. Total running time: 1hr 6min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      896            450.332   185965       4.16                      6                      0                96.79                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:43:10. Total running time: 1hr 6min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                      949            478.558   197627       3.9                       6                      0                95.57                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:43:40. Total running time: 1hr 7min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1002            506.644   209229       4.06                      6                      1                98.02                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:44:10. Total running time: 1hr 7min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1055            535.263   221047       4.29                      6                      0                97.37                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:44:40. Total running time: 1hr 8min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1108            563.365   232666       4.31                      6                      1                97.01                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:45:10. Total running time: 1hr 8min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1161            591.745   244373       4.17                      6                      0                95.45                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:45:40. Total running time: 1hr 9min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1215            620.273   256178       4.17                      6                      1                 95.3                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:46:10. Total running time: 1hr 9min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1269            648.421   267827       4.58                      6                      0                90.43                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:46:40. Total running time: 1hr 10min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1322            676.738   279442       4.06                      6                      1                95.08                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:47:10. Total running time: 1hr 10min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1374             705.22   291238       4.43                      6                      1                91.05                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:47:40. Total running time: 1hr 11min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1425            733.671   303006       4.38                      6                      2                94.74                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:48:10. Total running time: 1hr 11min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1476            761.816   314597       4.46                      6                      2                90.21                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:48:40. Total running time: 1hr 12min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1529            790.178   326307       4.14                      6                      1                97.04                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:49:10. Total running time: 1hr 12min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1583            818.812   338133       4.4                       6                      1                93.11                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:49:40. Total running time: 1hr 13min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1636            846.819   349667       4.34                      6                      1                92.74                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:50:10. Total running time: 1hr 13min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1687            875.626   361584       4.43                      6                      0                91.53                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:50:40. Total running time: 1hr 14min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1739            903.955   373241       4.39                      6                      2                92.88                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:51:11. Total running time: 1hr 14min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1791            932.059   384863       4.61                      6                      2                 91.5                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:51:41. Total running time: 1hr 15min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1843            960.499   396657       4.57                      6                      1                94.25                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:52:11. Total running time: 1hr 15min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=87.06 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814938820>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1894            988.933   408397       4.81                      6                      0                87.06                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:52:41. Total running time: 1hr 16min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=86.26 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14482c1bbeb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1945            1017.15   420020       4.75                      6                      1                86.26                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:53:11. Total running time: 1hr 16min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     1998            1045.39   431703       4.54                      6                      1                91.22                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:53:41. Total running time: 1hr 17min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00000 with episode_len_mean=88.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814bbfbe0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2051            1074.22   443674       4.53                      6                      1                92.27                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:54:11. Total running time: 1hr 17min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=85.89 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448143465f0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2103            1102.42   455529       4.94                      6                      2                85.89                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:54:41. Total running time: 1hr 18min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=82.97 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481488ff40>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2155            1130.9    467493       5.14                      6                      2                82.97                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:55:11. Total running time: 1hr 18min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=81.59 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448143ae680>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2205            1159.13   479385       5.24                      6                      1                81.59                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:55:41. Total running time: 1hr 19min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=76.54 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448141f83a0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2256            1187.47   491372       5.34                      6                      1                76.54                      5 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:56:11. Total running time: 1hr 19min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=74.43 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448141f8b80>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2307            1216.39   503560       5.56                      6                      3                74.43                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:56:41. Total running time: 1hr 20min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=77.22 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481485c940>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2357            1244.89   515547       5.58                      6                      2                77.22                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:57:11. Total running time: 1hr 20min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=76.35 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481485c280>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2405            1273.11   527464       5.64                      6                      3                76.35                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:57:41. Total running time: 1hr 21min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=74.71 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448141f96c0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2457            1301.83   539587       5.63                      6                      3                74.71                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:58:11. Total running time: 1hr 21min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=72.2 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481485f7f0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2506            1329.98   551455       5.63                      6                      3                 72.2                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:58:41. Total running time: 1hr 22min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=74.38 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448141f8310>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2557            1358.59   563557       5.45                      6                      3                74.38                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:59:11. Total running time: 1hr 22min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=74.78 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448143465f0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2609            1386.98   575511       5.57                      6                      3                74.78                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:59:41. Total running time: 1hr 23min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=73.39 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448143465f0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2660            1415.47   587543       5.54                      6                      3                73.39                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:00:11. Total running time: 1hr 23min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=73.88 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448143acdc0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2710            1444.04   599624       5.55                      6                      3                73.88                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:00:41. Total running time: 1hr 24min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=70.08 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481426ed40>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2760            1472.54   611630       5.61                      6                      2                70.08                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:01:11. Total running time: 1hr 24min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=75.54 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481426eb00>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2810            1501.18   623736       5.68                      6                      4                75.54                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:01:42. Total running time: 1hr 25min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=76.78 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481426f490>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2860            1529.46   635674       5.52                      6                      3                76.78                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:02:12. Total running time: 1hr 25min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=68.26 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481426e440>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2910            1557.82   647601       5.75                      6                      4                68.26                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:02:42. Total running time: 1hr 26min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=73.1 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448143465f0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     2963            1586.55   659707       5.66                      6                      4                 73.1                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:03:12. Total running time: 1hr 26min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=70.48 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421f640>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3010            1614.89   671636       5.69                      6                      4                70.48                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:03:42. Total running time: 1hr 27min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=71.88 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421f2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3062            1643.4    683669       5.68                      6                      4                71.88                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:04:12. Total running time: 1hr 27min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=66.55 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814295d80>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3114            1671.7    695631       5.73                      6                      3                66.55                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:04:42. Total running time: 1hr 28min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=67.64 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481426f910>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3165            1700.35   707701       5.74                      6                      4                67.64                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:05:12. Total running time: 1hr 28min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=73.78 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814296cb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3215            1728.35   719502       5.6                       6                      4                73.78                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:05:42. Total running time: 1hr 29min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=71.43 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481426f9a0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3266            1756.92   731539       5.65                      6                      4                71.43                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:06:12. Total running time: 1hr 29min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=67.28 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448142eadd0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3316            1785.88   743739       5.66                      6                      2                67.28                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:06:42. Total running time: 1hr 30min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=75.64 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3365            1813.88   755500       5.57                      6                      3                75.64                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:07:12. Total running time: 1hr 30min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=71.2 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814938820>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3417            1842.73   767679       5.67                      6                      3                 71.2                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                 88.1                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:07:42. Total running time: 1hr 31min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=68.15 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448142ebf40>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3469            1871.08   779637       5.71                      6                      3                68.15                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:08:12. Total running time: 1hr 31min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=68.55 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x144814297880>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3519            1899.54   791609       5.67                      6                      3                68.55                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:08:42. Total running time: 1hr 32min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=68.95 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448141f8dc0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3570            1928.14   803691       5.65                      6                      4                68.95                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:09:12. Total running time: 1hr 32min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=69.98 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1448142e8280>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3622            1956.3    815520       5.64                      6                      3                69.98                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:09:42. Total running time: 1hr 33min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=70.15 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00001   RUNNING      shared             type_1                     3671            1984.85   827560       5.65                      6                      2                70.15                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00001 completed after 3698 iterations at 2023-11-24 03:09:59. Total running time: 1hr 33min 26s
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00001 result                                                         │
├─────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                         │
│ episodes_total                                                                         9999 │
│ time_this_iter_s                                                                    0.55956 │
│ time_total_s                                                                     2000.58179 │
│ timesteps_total                                                                      834171 │
│ training_iteration                                                                     3698 │
│ agent_timesteps_total                                                               1668342 │
│ callback_ok                                                                            True │
│ connector_metrics/ObsPreprocessorConnector_ms                          0.004744291305541992 │
│ connector_metrics/StateBufferConnector_ms                             0.0035583972930908203 │
│ connector_metrics/ViewRequirementAgentConnector_ms                       0.3121325969696045 │
│ counters/num_agent_steps_sampled                                                    1668342 │
│ counters/num_agent_steps_trained                                                          0 │
│ counters/num_env_steps_sampled                                                       834171 │
│ counters/num_env_steps_trained                                                            0 │
│ custom_metrics/assists_max                                                                0 │
│ custom_metrics/assists_mean                                                             0.0 │
│ custom_metrics/assists_min                                                                0 │
│ custom_metrics/kills_max                                                                  6 │
│ custom_metrics/kills_mean                                                              5.78 │
│ custom_metrics/kills_min                                                                  4 │
│ custom_metrics/predator_0_assists_max                                                     0 │
│ custom_metrics/predator_0_assists_mean                                                  0.0 │
│ custom_metrics/predator_0_assists_min                                                     0 │
│ custom_metrics/predator_0_kills_max                                                       6 │
│ custom_metrics/predator_0_kills_mean                                                   2.76 │
│ custom_metrics/predator_0_kills_min                                                       0 │
│ custom_metrics/predator_1_assists_max                                                     0 │
│ custom_metrics/predator_1_assists_mean                                                  0.0 │
│ custom_metrics/predator_1_assists_min                                                     0 │
│ custom_metrics/predator_1_kills_max                                                       6 │
│ custom_metrics/predator_1_kills_mean                                                   3.02 │
│ custom_metrics/predator_1_kills_min                                                       0 │
│ episode_len_mean                                                                      63.07 │
│ episode_reward_max                                                                       6. │
│ episode_reward_mean                                                                    5.78 │
│ episode_reward_min                                                                       4. │
│ episodes_this_iter                                                                        3 │
│ hist_stats/episode_lengths                                             ... 56, 91, 45, 101] │
│ hist_stats/episode_reward                                              ...0, 6.0, 6.0, 5.0] │
│ hist_stats/policy_shared_policy_reward                                 ...0, 4.0, 1.0, 4.0] │
│ info/learner/__all__/num_agent_steps_trained                                          128.0 │
│ info/learner/__all__/num_env_steps_trained                                            474.0 │
│ info/learner/__all__/total_loss                                          0.6110172512892046 │
│ info/learner/shared_policy/curr_entropy_coeff                                           0.0 │
│ info/learner/shared_policy/curr_kl_coeff                                                0.0 │
│ info/learner/shared_policy/curr_lr                                                   0.0001 │
│ info/learner/shared_policy/default_optimizer_lr                                      0.0001 │
│ info/learner/shared_policy/entropy                                        0.570080241090373 │
│ info/learner/shared_policy/mean_kl_loss                               3.783332524682536e-05 │
│ info/learner/shared_policy/policy_loss                               -0.0056012366947374844 │
│ info/learner/shared_policy/total_loss                                    0.6110172512892046 │
│ info/learner/shared_policy/vf_explained_var                              0.3160393583147149 │
│ info/learner/shared_policy/vf_loss                                       0.6166184952384547 │
│ info/learner/shared_policy/vf_loss_unclipped                             0.6166184952384547 │
│ info/num_agent_steps_sampled                                                        1668342 │
│ info/num_agent_steps_trained                                                              0 │
│ info/num_env_steps_sampled                                                           834171 │
│ info/num_env_steps_trained                                                                0 │
│ num_agent_steps_sampled                                                             1668342 │
│ num_agent_steps_trained                                                                   0 │
│ num_env_steps_sampled                                                                834171 │
│ num_env_steps_sampled_this_iter                                                         237 │
│ num_env_steps_sampled_throughput_per_sec                                          426.23048 │
│ num_env_steps_trained                                                                     0 │
│ num_env_steps_trained_this_iter                                                           0 │
│ num_env_steps_trained_throughput_per_sec                                                 0. │
│ num_faulty_episodes                                                                       0 │
│ num_healthy_workers                                                                       0 │
│ num_in_flight_async_reqs                                                                  0 │
│ num_remote_worker_restarts                                                                0 │
│ num_steps_trained_this_iter                                                               0 │
│ perf/cpu_util_percent                                                                   8.8 │
│ perf/ram_util_percent                                                                  19.7 │
│ policy_reward_max/shared_policy                                                         6.0 │
│ policy_reward_mean/shared_policy                                                       2.89 │
│ policy_reward_min/shared_policy                                                         0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.12706256544596933 │
│ sampler_perf/mean_env_render_ms                                                         0.0 │
│ sampler_perf/mean_env_wait_ms                                           0.10412091656411922 │
│ sampler_perf/mean_inference_ms                                           1.2761477779250203 │
│ sampler_perf/mean_raw_obs_processing_ms                                  0.5672129313512084 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms          0.004744291305541992 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.0035583972930908203 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms       0.3121325969696045 │
│ sampler_results/custom_metrics/assists_max                                                0 │
│ sampler_results/custom_metrics/assists_mean                                             0.0 │
│ sampler_results/custom_metrics/assists_min                                                0 │
│ sampler_results/custom_metrics/kills_max                                                  6 │
│ sampler_results/custom_metrics/kills_mean                                              5.78 │
│ sampler_results/custom_metrics/kills_min                                                  4 │
│ sampler_results/custom_metrics/predator_0_assists_max                                     0 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                  0.0 │
│ sampler_results/custom_metrics/predator_0_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.76 │
│ sampler_results/custom_metrics/predator_0_kills_min                                       0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                     0 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                  0.0 │
│ sampler_results/custom_metrics/predator_1_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   3.02 │
│ sampler_results/custom_metrics/predator_1_kills_min                                       0 │
│ sampler_results/episode_len_mean                                                      63.07 │
│ sampler_results/episode_reward_max                                                      6.0 │
│ sampler_results/episode_reward_mean                                                    5.78 │
│ sampler_results/episode_reward_min                                                      4.0 │
│ sampler_results/episodes_this_iter                                                        3 │
│ sampler_results/hist_stats/episode_lengths                             ... 56, 91, 45, 101] │
│ sampler_results/hist_stats/episode_reward                              ...0, 6.0, 6.0, 5.0] │
│ sampler_results/hist_stats/policy_shared_policy_reward                 ...0, 4.0, 1.0, 4.0] │
│ sampler_results/num_faulty_episodes                                                       0 │
│ sampler_results/policy_reward_max/shared_policy                                         6.0 │
│ sampler_results/policy_reward_mean/shared_policy                                       2.89 │
│ sampler_results/policy_reward_min/shared_policy                                         0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.12706256544596933 │
│ sampler_results/sampler_perf/mean_env_render_ms                                         0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                           0.10412091656411922 │
│ sampler_results/sampler_perf/mean_inference_ms                           1.2761477779250203 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                  0.5672129313512084 │
│ timers/sample_time_ms                                                               500.589 │
│ timers/synch_weights_time_ms                                                          0.518 │
│ timers/training_iteration_time_ms                                                   571.362 │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00002 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00002 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_2 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:10:12. Total running time: 1hr 33min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                       15            10.0657     3030    1.78333                    4.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858    4.75                       6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171    5.78                       6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:10:42. Total running time: 1hr 34min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                       57            38.5684    11514       1.71                      4                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:11:12. Total running time: 1hr 34min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                       99            66.9707    19998      1.875                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:11:43. Total running time: 1hr 35min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      140            94.7967    28280      1.885                    6.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:12:13. Total running time: 1hr 35min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      182            123.393    36764       1.65                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:12:43. Total running time: 1hr 36min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      224            151.818    45248      1.735                    4.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:13:13. Total running time: 1hr 36min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      266            180.334    53732       1.57                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:13:43. Total running time: 1hr 37min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      307            208.306    62112       2.06                      6                      0               100.97                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:14:13. Total running time: 1hr 37min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      349            236.787    70596       1.96                      4                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:14:43. Total running time: 1hr 38min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      390            264.876    78954      1.975                      6                      0               100.75                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:15:13. Total running time: 1hr 38min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      432            293.339    87438      1.965                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:15:43. Total running time: 1hr 39min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      474            321.836    95922       1.79                    5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:16:13. Total running time: 1hr 39min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      515            349.544   104204       2                       5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:16:43. Total running time: 1hr 40min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      557            378.401   112782       2.08                      6                      0               100.93                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:17:13. Total running time: 1hr 40min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      598            406.121   121064       2.23                      6                      0               100.93                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:17:43. Total running time: 1hr 41min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      640            434.522   129548      2.115                    5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:18:13. Total running time: 1hr 41min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      682            463.032   138032       2.1                       5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:18:43. Total running time: 1hr 42min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      724            491.439   146516       2.37                    5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:19:13. Total running time: 1hr 42min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      765            519.261   154798       2.29                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:19:43. Total running time: 1hr 43min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      807            547.676   163282      2.405                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:20:13. Total running time: 1hr 43min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      849            576.139   171766       2.72                      5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:20:43. Total running time: 1hr 44min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      891            604.643   180250      2.565                    5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:21:13. Total running time: 1hr 44min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      932            632.966   188717      2.845                      6                      0               100.83                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:21:43. Total running time: 1hr 45min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                      974            661.461   197201       2.6                     5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:22:14. Total running time: 1hr 45min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1015             689.21   205481       2.8                       6                      0               100.98                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:22:44. Total running time: 1hr 46min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1056            717.385   213839      2.985                    6.5                      0               100.75                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:23:14. Total running time: 1hr 46min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1098            745.964   222322      2.985                    6.5                      1               100.99                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:23:44. Total running time: 1hr 47min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1140             774.68   230892       2.89                      6                      0               100.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:24:14. Total running time: 1hr 47min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1180            803.019   239314       3.41                    6.5                      0                99.37                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:24:44. Total running time: 1hr 48min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1221            831.263   247751      3.295                      6                      1                99.88                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:25:14. Total running time: 1hr 48min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1262            859.645   256235      3.705                    7.5                      1                99.95                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:25:44. Total running time: 1hr 49min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1301            887.697   264573      3.485                    7.5                      0                99.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:26:14. Total running time: 1hr 49min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1341            915.909   272971      3.425                    6.5                      0                99.9                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:26:44. Total running time: 1hr 50min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1380            944.321   281370       3.51                    6.5                      0                99.01                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:27:14. Total running time: 1hr 50min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1419            972.598   289819       3.64                    6.5                      0                98.34                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:27:44. Total running time: 1hr 51min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1459            1001.61   298462      3.885                      6                      0                97.54                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:28:14. Total running time: 1hr 51min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1498            1029.8    306835      4.165                      6                      0                97.96                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:28:44. Total running time: 1hr 52min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1539            1058.29   315343      3.545                      7                      0                99.5                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:29:14. Total running time: 1hr 52min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1578            1086.39   323691       3.78                    6.5                      0                98.12                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:29:44. Total running time: 1hr 53min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1617            1114.82   332161       3.94                    6.5                      1                97.66                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:30:14. Total running time: 1hr 53min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1657            1143.5    340729       3.69                      7                      0                98.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:30:44. Total running time: 1hr 54min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1697            1171.75   349153      4.205                      7                      2                97.97                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:31:14. Total running time: 1hr 54min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1737            1200.23   357677      4.265                    6.5                      1                96.96                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:31:44. Total running time: 1hr 55min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1776            1228.47   366063       3.98                    7.5                      1                97.94                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:32:14. Total running time: 1hr 55min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1816            1257.35   374673      3.845                      7                      0                98.05                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:32:45. Total running time: 1hr 56min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1856            1285.66   383136       4.13                    6.5                      1                96.99                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:33:15. Total running time: 1hr 56min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1894            1314.05   391588       4.16                      7                      1                96.64                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:33:45. Total running time: 1hr 57min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1934            1342.81   400156       4.13                    6.5                      1                97.92                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:34:15. Total running time: 1hr 57min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     1973            1371.23   408626      4.355                    7.5                      1                96.13                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:34:45. Total running time: 1hr 58min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2013            1400.12   417255       4.35                      7                      1                97                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:35:15. Total running time: 1hr 58min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2052            1428.05   425598       4.14                      7                      0                97.3                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:35:45. Total running time: 1hr 59min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2090            1456.46   434081       4.29                    7.5                      1                96.73                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:36:15. Total running time: 1hr 59min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2129            1485.5    442791       4.19                    6.5                      0                96.19                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:36:45. Total running time: 2hr 0min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2168            1513.84   451218       4.34                      7                      2                97.11                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:37:15. Total running time: 2hr 0min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2207            1542.66   459845      4.445                    6.5                      1                95.36                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:37:45. Total running time: 2hr 1min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2247            1570.9    468269      4.495                    6.5                      1                97.98                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:38:15. Total running time: 2hr 1min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2286            1599.21   476702      4.335                    6.5                      1                95.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:38:45. Total running time: 2hr 2min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2323            1627.66   485212       4.52                      7                      1                93.18                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:39:15. Total running time: 2hr 2min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2363            1656.09   493683       4.13                      7                      0                96.45                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:39:45. Total running time: 2hr 3min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2401            1684.75   502263      4.155                    7.5                      0                96.26                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:40:15. Total running time: 2hr 3min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2439            1713.45   510832       4.38                    7.5                      1                94.03                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:40:45. Total running time: 2hr 4min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2477            1742.15   519390       4.52                    6.5                      0                95.17                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:41:15. Total running time: 2hr 4min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2515            1770.09   527765      4.485                    6.5                      1                95.47                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:41:45. Total running time: 2hr 5min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2554            1798.97   536381       4.32                      7                      0                94.94                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:42:15. Total running time: 2hr 5min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2593            1827.08   544756      4.435                    6.5                      1                95.39                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:42:45. Total running time: 2hr 6min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2633            1855.96   553398      4.515                      7                      0                94.68                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:43:16. Total running time: 2hr 6min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2671            1884.14   561775      4.395                    6.5                      0                96.61                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:43:46. Total running time: 2hr 7min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2710            1913.08   570397       4.43                    7.5                      1                92.13                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:44:16. Total running time: 2hr 7min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2747            1941.06   578722       4.24                      7                      1                96.58                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:44:46. Total running time: 2hr 8min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2785            1969.83   587282      4.365                    6.5                      1                94.69                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:45:16. Total running time: 2hr 8min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2822            1998.37   595797       4.4                     7.5                      0                90.76                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:45:46. Total running time: 2hr 9min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2861            2027.03   604319      4.435                      8                      1                93.23                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:46:16. Total running time: 2hr 9min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2899            2055.71   612854      4.525                      8                      1                95.63                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:46:46. Total running time: 2hr 10min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2936            2083.91   621241      4.315                      7                      0                95.36                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:47:16. Total running time: 2hr 10min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     2973            2112.76   629836       4.66                      7                      1                91.97                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:47:46. Total running time: 2hr 11min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3010            2141.36   638383       4.7                       8                      2                91.18                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:48:16. Total running time: 2hr 11min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3047            2169.64   646759      4.425                    7.5                      1                94.83                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:48:46. Total running time: 2hr 12min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3084            2198.6    655394       4.72                      6                      1                88.37                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:49:16. Total running time: 2hr 12min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3119            2226.82   663802      4.895                    7.5                      2                93.64                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:49:46. Total running time: 2hr 13min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3157            2255.35   672303       4.53                    7.5                      0                94.57                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:50:16. Total running time: 2hr 13min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3194            2284.04   680878      4.855                    6.5                      2                92.42                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:50:46. Total running time: 2hr 14min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3231            2312.52   689355      4.745                    6.5                      0                93.5                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:51:16. Total running time: 2hr 14min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3268            2340.88   697792      4.735                    6.5                      1                93.26                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:51:46. Total running time: 2hr 15min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3305            2370.04   706456      4.915                    6.5                      2                89.44                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:52:17. Total running time: 2hr 15min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3343            2398.53   714964       4.81                      7                      2                90.8                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:52:47. Total running time: 2hr 16min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3379            2427.33   723503       4.88                      7                      2                89.31                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:53:17. Total running time: 2hr 16min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3414            2455.59   731901      4.945                    6.5                      2                86.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:53:47. Total running time: 2hr 17min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3452            2484.21   740454      4.845                      7                      1                90.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:54:17. Total running time: 2hr 17min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3489            2512.94   749008      4.775                      7                      1                91.59                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:54:47. Total running time: 2hr 18min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3527            2541.48   757557       4.65                    6.5                      1                91.51                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:55:17. Total running time: 2hr 18min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3565            2569.73   765987       4.64                    7.5                      1                93.34                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:55:47. Total running time: 2hr 19min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3602            2598.06   774404       4.66                    6.5                      1                90.45                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:56:17. Total running time: 2hr 19min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3641            2626.59   782929      4.535                    6.5                      2                92.82                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:56:47. Total running time: 2hr 20min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3678            2655.28   791458      4.975                    6.5                      1                90                         3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:57:17. Total running time: 2hr 20min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3717            2684.02   800034       4.7                       7                      2                92.05                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:57:47. Total running time: 2hr 21min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3755            2713.09   808701      4.945                      7                      2                90.71                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:58:17. Total running time: 2hr 21min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3792            2741.62   817162      5.015                    6.5                      2                87.64                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:58:47. Total running time: 2hr 22min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3830            2770.3    825717      4.595                      7                      1                91.61                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:59:17. Total running time: 2hr 22min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3867            2798.31   834028      4.985                    6.5                      2                90.41                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:59:47. Total running time: 2hr 23min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3905            2827.46   842721      4.955                    6.5                      2                88.95                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:00:17. Total running time: 2hr 23min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3942            2855.58   851072      4.815                      7                      1                90.55                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:00:47. Total running time: 2hr 24min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     3979            2884.09   859512      4.605                    6.5                      1                88.54                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:01:17. Total running time: 2hr 24min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4015            2912.73   868057       4.76                    6.5                      1                90.17                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:01:47. Total running time: 2hr 25min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4053            2941.63   876638      5.215                      7                      2                86.82                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:02:17. Total running time: 2hr 25min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4089            2969.93   885071      5.045                      7                      2                86.35                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:02:47. Total running time: 2hr 26min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4125            2999.08   893754      5.035                      7                      2                86.83                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                       6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                       6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:03:18. Total running time: 2hr 26min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4161            3027.44   902176       5.13                    6.5                      2                89.61                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:03:48. Total running time: 2hr 27min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4197            3055.84   910675       5.3                     7.5                      1                82.05                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                    6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                    6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:04:18. Total running time: 2hr 27min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4234            3084.57   919196       4.99                      7                      1                91                         3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:04:48. Total running time: 2hr 28min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4271            3113.5    927816      5.325                    8.5                    1.5                83.17                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                      2                  88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                      4                  63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:05:18. Total running time: 2hr 28min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4308            3142.24   936398      5.135                    6.5                      2                85.82                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:05:48. Total running time: 2hr 29min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00002   RUNNING      independent        type_2                     4344            3170.31   944710       5.29                      8                      3                85.14                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858       4.75                      6                      2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171       5.78                      6                      4                63.07                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00002 completed after 4368 iterations at 2023-11-24 04:06:08. Total running time: 2hr 29min 35s
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00002 result                                                         │
├─────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                         │
│ episodes_total                                                                         9999 │
│ time_this_iter_s                                                                    0.67686 │
│ time_total_s                                                                     3189.28878 │
│ timesteps_total                                                                      950372 │
│ training_iteration                                                                     4368 │
│ agent_timesteps_total                                                               1900744 │
│ callback_ok                                                                            True │
│ connector_metrics/ObsPreprocessorConnector_ms                          0.003458261489868164 │
│ connector_metrics/StateBufferConnector_ms                               0.00254213809967041 │
│ connector_metrics/ViewRequirementAgentConnector_ms                       0.1584261655807495 │
│ counters/num_agent_steps_sampled                                                    1900744 │
│ counters/num_agent_steps_trained                                                          0 │
│ counters/num_env_steps_sampled                                                       950372 │
│ counters/num_env_steps_trained                                                            0 │
│ custom_metrics/assists_max                                                                2 │
│ custom_metrics/assists_mean                                                            0.09 │
│ custom_metrics/assists_min                                                                0 │
│ custom_metrics/kills_max                                                                  6 │
│ custom_metrics/kills_mean                                                              5.27 │
│ custom_metrics/kills_min                                                                  3 │
│ custom_metrics/predator_0_assists_max                                                     1 │
│ custom_metrics/predator_0_assists_mean                                                 0.06 │
│ custom_metrics/predator_0_assists_min                                                     0 │
│ custom_metrics/predator_0_kills_max                                                       5 │
│ custom_metrics/predator_0_kills_mean                                                   2.42 │
│ custom_metrics/predator_0_kills_min                                                       0 │
│ custom_metrics/predator_1_assists_max                                                     2 │
│ custom_metrics/predator_1_assists_mean                                                 0.03 │
│ custom_metrics/predator_1_assists_min                                                     0 │
│ custom_metrics/predator_1_kills_max                                                       6 │
│ custom_metrics/predator_1_kills_mean                                                   2.85 │
│ custom_metrics/predator_1_kills_min                                                       0 │
│ episode_len_mean                                                                      82.34 │
│ episode_reward_max                                                                      6.5 │
│ episode_reward_mean                                                                   5.315 │
│ episode_reward_min                                                                       3. │
│ episodes_this_iter                                                                        2 │
│ hist_stats/episode_lengths                                             ...9, 101, 101, 101] │
│ hist_stats/episode_reward                                              ...5, 5.0, 6.0, 4.5] │
│ hist_stats/policy_predator_0_reward                                    ..., 2.0, 1.5, 3.75] │
│ hist_stats/policy_predator_1_reward                                    ..., 3.0, 4.5, 0.75] │
│ info/learner/__all__/num_agent_steps_trained                                          256.0 │
│ info/learner/__all__/num_env_steps_trained                                            202.0 │
│ info/learner/__all__/total_loss                                          1.8930862098932266 │
│ info/learner/predator_0/curr_entropy_coeff                                              0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                   0.0 │
│ info/learner/predator_0/curr_lr                                                      0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                         0.0001 │
│ info/learner/predator_0/entropy                                          1.2527012079954147 │
│ info/learner/predator_0/mean_kl_loss                                 1.1403335946624793e-05 │
│ info/learner/predator_0/policy_loss                                   -0.003011303022503853 │
│ info/learner/predator_0/total_loss                                       1.8930862098932266 │
│ info/learner/predator_0/vf_explained_var                                0.08277586847543716 │
│ info/learner/predator_0/vf_loss                                          0.4325396791100502 │
│ info/learner/predator_0/vf_loss_unclipped                                0.4325396791100502 │
│ info/learner/predator_1/curr_entropy_coeff                                              0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                   0.0 │
│ info/learner/predator_1/curr_lr                                                      0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                         0.0001 │
│ info/learner/predator_1/entropy                                           1.141471117734909 │
│ info/learner/predator_1/mean_kl_loss                                 1.2072295398013466e-05 │
│ info/learner/predator_1/policy_loss                                   -0.017165452241897583 │
│ info/learner/predator_1/total_loss                                       1.4635578244924545 │
│ info/learner/predator_1/vf_explained_var                               0.007050968706607819 │
│ info/learner/predator_1/vf_loss                                          1.4807232916355133 │
│ info/learner/predator_1/vf_loss_unclipped                                1.4807232916355133 │
│ info/num_agent_steps_sampled                                                        1900744 │
│ info/num_agent_steps_trained                                                              0 │
│ info/num_env_steps_sampled                                                           950372 │
│ info/num_env_steps_trained                                                                0 │
│ num_agent_steps_sampled                                                             1900744 │
│ num_agent_steps_trained                                                                   0 │
│ num_env_steps_sampled                                                                950372 │
│ num_env_steps_sampled_this_iter                                                         202 │
│ num_env_steps_sampled_throughput_per_sec                                           300.1024 │
│ num_env_steps_trained                                                                     0 │
│ num_env_steps_trained_this_iter                                                           0 │
│ num_env_steps_trained_throughput_per_sec                                                 0. │
│ num_faulty_episodes                                                                       0 │
│ num_healthy_workers                                                                       0 │
│ num_in_flight_async_reqs                                                                  0 │
│ num_remote_worker_restarts                                                                0 │
│ num_steps_trained_this_iter                                                               0 │
│ perf/cpu_util_percent                                                                   7.9 │
│ perf/ram_util_percent                                                                  19.7 │
│ policy_reward_max/predator_0                                                           5.75 │
│ policy_reward_max/predator_1                                                            6.0 │
│ policy_reward_mean/predator_0                                                        2.4575 │
│ policy_reward_mean/predator_1                                                        2.8575 │
│ policy_reward_min/predator_0                                                            0.0 │
│ policy_reward_min/predator_1                                                            0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.14541617042502705 │
│ sampler_perf/mean_env_render_ms                                                         0.0 │
│ sampler_perf/mean_env_wait_ms                                           0.10853027930838868 │
│ sampler_perf/mean_inference_ms                                            2.209648092365393 │
│ sampler_perf/mean_raw_obs_processing_ms                                  0.5781546364055199 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms          0.003458261489868164 │
│ sampler_results/connector_metrics/StateBufferConnector_ms               0.00254213809967041 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms       0.1584261655807495 │
│ sampler_results/custom_metrics/assists_max                                                2 │
│ sampler_results/custom_metrics/assists_mean                                            0.09 │
│ sampler_results/custom_metrics/assists_min                                                0 │
│ sampler_results/custom_metrics/kills_max                                                  6 │
│ sampler_results/custom_metrics/kills_mean                                              5.27 │
│ sampler_results/custom_metrics/kills_min                                                  3 │
│ sampler_results/custom_metrics/predator_0_assists_max                                     1 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                 0.06 │
│ sampler_results/custom_metrics/predator_0_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                       5 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.42 │
│ sampler_results/custom_metrics/predator_0_kills_min                                       0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                     2 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                 0.03 │
│ sampler_results/custom_metrics/predator_1_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   2.85 │
│ sampler_results/custom_metrics/predator_1_kills_min                                       0 │
│ sampler_results/episode_len_mean                                                      82.34 │
│ sampler_results/episode_reward_max                                                      6.5 │
│ sampler_results/episode_reward_mean                                                   5.315 │
│ sampler_results/episode_reward_min                                                      3.0 │
│ sampler_results/episodes_this_iter                                                        2 │
│ sampler_results/hist_stats/episode_lengths                             ...9, 101, 101, 101] │
│ sampler_results/hist_stats/episode_reward                              ...5, 5.0, 6.0, 4.5] │
│ sampler_results/hist_stats/policy_predator_0_reward                    ..., 2.0, 1.5, 3.75] │
│ sampler_results/hist_stats/policy_predator_1_reward                    ..., 3.0, 4.5, 0.75] │
│ sampler_results/num_faulty_episodes                                                       0 │
│ sampler_results/policy_reward_max/predator_0                                           5.75 │
│ sampler_results/policy_reward_max/predator_1                                            6.0 │
│ sampler_results/policy_reward_mean/predator_0                                        2.4575 │
│ sampler_results/policy_reward_mean/predator_1                                        2.8575 │
│ sampler_results/policy_reward_min/predator_0                                            0.0 │
│ sampler_results/policy_reward_min/predator_1                                            0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.14541617042502705 │
│ sampler_results/sampler_perf/mean_env_render_ms                                         0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                           0.10853027930838868 │
│ sampler_results/sampler_perf/mean_inference_ms                            2.209648092365393 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                  0.5781546364055199 │
│ timers/sample_time_ms                                                               677.835 │
│ timers/synch_weights_time_ms                                                          0.923 │
│ timers/training_iteration_time_ms                                                   739.162 │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00003 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00003 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_2 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:06:18. Total running time: 2hr 29min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                       15             7.1692     3030    1.63333                    3                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858    4.75                       6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171    5.78                       6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372    5.315                      6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:06:48. Total running time: 2hr 30min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                       73            35.1336    14809      1.755                    6.5                      0               100.62                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:07:18. Total running time: 2hr 30min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      131            62.8812    26525      1.875                    5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:07:48. Total running time: 2hr 31min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      190            91.1425    38443      1.82                     5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:08:18. Total running time: 2hr 31min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      248            118.986    50159      1.875                    5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:08:48. Total running time: 2hr 32min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      307            147.226    62077      2.025                    6.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:09:18. Total running time: 2hr 32min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      365            175.039    73793      1.96                     4.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:09:48. Total running time: 2hr 33min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      424            203.398    85801      2.345                    6                        0               100.89                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:10:18. Total running time: 2hr 33min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      483            231.556    97719      2.535                    5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:10:48. Total running time: 2hr 34min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      541            259.591   109528      2.46                     7                        0               100.92                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:11:19. Total running time: 2hr 34min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      598            287.419   121281      2.855                    6                        0               100.43                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:11:49. Total running time: 2hr 35min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      657            315.612   133199      3.14                     5.5                      0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:12:19. Total running time: 2hr 35min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      714            343.695   145003      3.17                     6.5                      0                99.86                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:12:49. Total running time: 2hr 36min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      772            371.772   156856      3.515                    7                        0               100.35                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:13:19. Total running time: 2hr 36min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      830            399.926   168778      3.585                    6                        0               100.03                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:13:49. Total running time: 2hr 37min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      887            428.185   180692      3.655                    6.5                      1               100.48                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:14:19. Total running time: 2hr 37min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                      944            456.327   192569      3.69                     6.5                      1                99.58                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:14:49. Total running time: 2hr 38min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1001            484.514   204465      3.91                     6.5                      1                98.18                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:15:19. Total running time: 2hr 38min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1057            512.919   216485      3.885                    6.5                      0                97.39                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:15:49. Total running time: 2hr 39min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1112            540.661   228212      3.92                     7.5                      0                95.83                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:16:19. Total running time: 2hr 39min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1167            568.933   240110      4.065                    6.5                      1                98.08                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:16:49. Total running time: 2hr 40min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1221            597.296   252055      4.2                      7.5                      1                96.18                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:17:19. Total running time: 2hr 40min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1275            625.574   264023      4.345                    6.5                      1                94.35                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:17:49. Total running time: 2hr 41min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1330            653.874   275986      4.175                    7                        0                94.95                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:18:19. Total running time: 2hr 41min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1384            681.969   287825      4.15                     7                        1                96.06                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:18:49. Total running time: 2hr 42min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1439            710.361   299828      4.235                    7                        1                95.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:19:19. Total running time: 2hr 42min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1494            738.598   311715      4.28                     6.5                      0                97.04                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:19:49. Total running time: 2hr 43min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1550            767.088   323785      4.21                     6.5                      1                97.94                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:20:19. Total running time: 2hr 43min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1605            795.248   335703      4.285                    7.5                      0                95.75                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:20:49. Total running time: 2hr 44min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1657            823.101   347438      4.415                    6.5                      0                92.4                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:21:19. Total running time: 2hr 44min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1712            851.747   359572      4.255                    6.5                      1                93.55                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:21:50. Total running time: 2hr 45min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1766            879.796   371474      4.285                    7                        1                95.74                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:22:20. Total running time: 2hr 45min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1818            908.159   383455      4.59                     7.5                      1                93.03                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:22:50. Total running time: 2hr 46min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1872            936.641   395419      4.67                     7.5                      2                90.51                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:23:20. Total running time: 2hr 46min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1924            964.601   407174      4.215                    6.5                      0                91.68                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:23:50. Total running time: 2hr 47min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     1978             993.19   419302      4.545                    7                        1                94.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:24:20. Total running time: 2hr 47min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2032            1021.42   431258      4.33                     7                        1                94.71                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:24:50. Total running time: 2hr 48min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2088            1049.77   443206      4.22                     6.5                      0                96.45                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:25:20. Total running time: 2hr 48min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2141            1078.1    455177      4.56                     7                        1                90.97                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:25:50. Total running time: 2hr 49min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2196            1106.58   467246      4.52                     6.5                      1                92.73                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:26:20. Total running time: 2hr 49min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2249            1134.86   479155      4.575                    6.5                      1                91.44                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:26:50. Total running time: 2hr 50min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2301            1163.02   491043      4.885                    7.5                      1                87.39                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:27:20. Total running time: 2hr 50min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2354            1191.58   503139      4.755                    7                        2                91.11                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:27:50. Total running time: 2hr 51min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2403            1219.66   515041      5.075                    7.5                      1                86.8                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:28:20. Total running time: 2hr 51min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2455            1248.4    527148      4.99                     6.5                      0                86.92                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:28:50. Total running time: 2hr 52min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2506            1276.55   539055      5.265                    6.5                      1                83.82                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:29:20. Total running time: 2hr 52min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2557            1305.24   551130      4.92                     7                      1.5                85.57                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                      2                  88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                      4                  63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                    3                  82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:29:50. Total running time: 2hr 53min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2609            1333.62   563115      4.835                    7                        1                87.24                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:30:20. Total running time: 2hr 53min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2660            1361.66   574941      5.25                     7.5                    1.5                86.33                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                      2                  88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                      4                  63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                    3                  82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:30:50. Total running time: 2hr 54min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2710            1390.22   586969      5.525                    7                        4                80.37                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:31:20. Total running time: 2hr 54min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2759            1418.66   599015      5.66                     7.5                      3                79.53                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:31:50. Total running time: 2hr 55min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2810            1447.24   611050      5.66                     7.5                    2.5                78.67                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                      2                  88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                      4                  63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                    3                  82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:32:21. Total running time: 2hr 55min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2860            1476.17   623215      5.77                     8                      2.5                73.72                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                      2                  88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                      4                  63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                    3                  82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:32:51. Total running time: 2hr 56min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2909            1504.17   635018      5.725                    7.5                      3                75.14                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:33:21. Total running time: 2hr 56min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     2960            1532.8    647052      5.735                    7.5                      3                72.22                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:33:51. Total running time: 2hr 57min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3011            1561.12   658976      5.745                    7.5                      1                71.51                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:34:21. Total running time: 2hr 57min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3062            1589.86   671073      5.925                    7                        4                65.19                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:34:51. Total running time: 2hr 58min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3113            1618.37   683042      5.795                    7.5                      2                68.95                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:35:21. Total running time: 2hr 58min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3163            1646.51   694891      5.96                     7.5                      4                69.76                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:35:51. Total running time: 2hr 59min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3213            1674.9    706848      5.83                     7.5                      3                74                         3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:36:21. Total running time: 2hr 59min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3265            1703.62   718918      5.845                    7.5                      3                74.12                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:36:51. Total running time: 3hr 0min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3315            1731.86   730759      5.935                    8                        4                67.1                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:37:21. Total running time: 3hr 0min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3365            1760.27   742697      5.845                    7.5                      3                72.84                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:37:51. Total running time: 3hr 1min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3416            1788.84   754738      5.855                    8                        3                72.64                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:38:21. Total running time: 3hr 1min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3467            1817.21   766647      5.795                    7                        3                68.18                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:38:51. Total running time: 3hr 2min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3517            1845.48   778514      5.87                     8                        4                68.24                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:39:21. Total running time: 3hr 2min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3568            1874.18   790538      5.845                    8                        4                72.63                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:39:51. Total running time: 3hr 3min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3619            1902.83   802566      5.93                     7.5                      4                69                         4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:40:21. Total running time: 3hr 3min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3669            1930.81   814346      5.74                     7.5                      2                68.92                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:40:51. Total running time: 3hr 4min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3719            1959.28   826298      5.99                     8.5                      3                66.74                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:41:21. Total running time: 3hr 4min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3771            1987.68   838271      5.845                    7.5                      4                68.19                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:41:51. Total running time: 3hr 5min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00003   RUNNING      shared             type_2                     3821            2016.46   850360      5.825                    7.5                      3                68.58                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00003 completed after 3853 iterations at 2023-11-24 04:42:11. Total running time: 3hr 5min 38s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00003 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                       10000 │
│ time_this_iter_s                                                                   0.50917 │
│ time_total_s                                                                    2034.76503 │
│ timesteps_total                                                                     858069 │
│ training_iteration                                                                    3853 │
│ agent_timesteps_total                                                              1716138 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                         0.004719734191894531 │
│ connector_metrics/StateBufferConnector_ms                             0.003516674041748047 │
│ connector_metrics/ViewRequirementAgentConnector_ms                     0.31241607666015625 │
│ counters/num_agent_steps_sampled                                                   1716138 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      858069 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               3 │
│ custom_metrics/assists_mean                                                           0.42 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             5.63 │
│ custom_metrics/kills_min                                                                 3 │
│ custom_metrics/predator_0_assists_max                                                    2 │
│ custom_metrics/predator_0_assists_mean                                                0.21 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      6 │
│ custom_metrics/predator_0_kills_mean                                                  2.85 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    2 │
│ custom_metrics/predator_1_assists_mean                                                0.21 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      6 │
│ custom_metrics/predator_1_kills_mean                                                  2.78 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     67.61 │
│ episode_reward_max                                                                      7. │
│ episode_reward_mean                                                                   5.84 │
│ episode_reward_min                                                                      3. │
│ episodes_this_iter                                                                       3 │
│ hist_stats/episode_lengths                                            ...101, 78, 101, 35] │
│ hist_stats/episode_reward                                             ...0, 6.0, 5.5, 6.0] │
│ hist_stats/policy_shared_policy_reward                                ..., 4.75, 4.0, 2.0] │
│ info/learner/__all__/num_agent_steps_trained                                         128.0 │
│ info/learner/__all__/num_env_steps_trained                                           428.0 │
│ info/learner/__all__/total_loss                                         0.9905436599955839 │
│ info/learner/shared_policy/curr_entropy_coeff                                          0.0 │
│ info/learner/shared_policy/curr_kl_coeff                                               0.0 │
│ info/learner/shared_policy/curr_lr                                                  0.0001 │
│ info/learner/shared_policy/default_optimizer_lr                                     0.0001 │
│ info/learner/shared_policy/entropy                                       0.634287532638101 │
│ info/learner/shared_policy/mean_kl_loss                              0.0001574163196999186 │
│ info/learner/shared_policy/policy_loss                               -0.032065890072023165 │
│ info/learner/shared_policy/total_loss                                   0.9905436599955839 │
│ info/learner/shared_policy/vf_explained_var                             0.1113747568691478 │
│ info/learner/shared_policy/vf_loss                                      1.0226095581755918 │
│ info/learner/shared_policy/vf_loss_unclipped                            1.0347420836196226 │
│ info/num_agent_steps_sampled                                                       1716138 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          858069 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1716138 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               858069 │
│ num_env_steps_sampled_this_iter                                                        214 │
│ num_env_steps_sampled_throughput_per_sec                                         423.29365 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                 10.4 │
│ perf/ram_util_percent                                                                 19.8 │
│ policy_reward_max/shared_policy                                                        6.0 │
│ policy_reward_mean/shared_policy                                                      2.92 │
│ policy_reward_min/shared_policy                                                        0.0 │
│ sampler_perf/mean_action_processing_ms                                 0.12493803403548588 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.10363620483450185 │
│ sampler_perf/mean_inference_ms                                          1.2615821667837563 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5598768269922734 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms         0.004719734191894531 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.003516674041748047 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms     0.31241607666015625 │
│ sampler_results/custom_metrics/assists_max                                               3 │
│ sampler_results/custom_metrics/assists_mean                                           0.42 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             5.63 │
│ sampler_results/custom_metrics/kills_min                                                 3 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    2 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                0.21 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                  2.85 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    2 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                0.21 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                  2.78 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     67.61 │
│ sampler_results/episode_reward_max                                                     7.0 │
│ sampler_results/episode_reward_mean                                                   5.84 │
│ sampler_results/episode_reward_min                                                     3.0 │
│ sampler_results/episodes_this_iter                                                       3 │
│ sampler_results/hist_stats/episode_lengths                            ...101, 78, 101, 35] │
│ sampler_results/hist_stats/episode_reward                             ...0, 6.0, 5.5, 6.0] │
│ sampler_results/hist_stats/policy_shared_policy_reward                ..., 4.75, 4.0, 2.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/shared_policy                                        6.0 │
│ sampler_results/policy_reward_mean/shared_policy                                      2.92 │
│ sampler_results/policy_reward_min/shared_policy                                        0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                 0.12493803403548588 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.10363620483450185 │
│ sampler_results/sampler_perf/mean_inference_ms                          1.2615821667837563 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5598768269922734 │
│ timers/sample_time_ms                                                              505.657 │
│ timers/synch_weights_time_ms                                                         0.523 │
│ timers/training_iteration_time_ms                                                  576.624 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00004 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00004 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_3 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:42:22. Total running time: 3hr 5min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                       10             6.7474     2020      2.35                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:42:52. Total running time: 3hr 6min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                       52            35.0881    10504      2.07                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:43:22. Total running time: 3hr 6min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                       93            63.1412    18866      1.74                     6                        0               100.79                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:43:52. Total running time: 3hr 7min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      135            91.6099    27350      1.99                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:44:22. Total running time: 3hr 7min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      177            120.072    35834      1.85                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:44:52. Total running time: 3hr 8min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      218             147.95    44116      1.94                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:45:22. Total running time: 3hr 8min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      260            176.426    52600      2.05                     8                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:45:52. Total running time: 3hr 9min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      302            205.022    61084      2                        7                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:46:22. Total running time: 3hr 9min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      343            232.751    69366      1.88                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:46:52. Total running time: 3hr 10min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      385            261.339    77850      1.93                     7                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:47:22. Total running time: 3hr 10min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      427            289.778    86334      1.81                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:47:52. Total running time: 3hr 11min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      468            317.621    94616      2.19                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:48:22. Total running time: 3hr 11min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      510            346.065   103100      2.41                     8                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:48:52. Total running time: 3hr 12min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      552            374.542   111584      2.36                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:49:22. Total running time: 3hr 12min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      593            402.454   119866      2.28                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:49:52. Total running time: 3hr 13min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      635            430.917   128350      2.53                     9                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:50:22. Total running time: 3hr 13min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      677            459.474   136833      2.58                     8                        0               100.99                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:50:52. Total running time: 3hr 14min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      718            487.254   145115      2.5                      7                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:51:22. Total running time: 3hr 14min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      760            515.767   153599      2.93                     8                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:51:52. Total running time: 3hr 15min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      802            544.402   162083      2.74                     7                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:52:22. Total running time: 3hr 15min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      843            572.459   170442      3.1                      7                        0               100.76                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:52:52. Total running time: 3hr 16min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      883            600.748   178858      3.38                    12                        0               100.32                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:53:22. Total running time: 3hr 16min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      925            629.327   187342      2.97                     7                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:53:53. Total running time: 3hr 17min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                      967            657.716   195826      3.17                     9                        1               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:54:23. Total running time: 3hr 17min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1008            685.549   204108      3.15                     9                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:54:53. Total running time: 3hr 18min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1049            714.223   212633      3.54                     7                        0               100.4                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:55:23. Total running time: 3hr 18min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1089            742.229   220971      3.82                    13                        0                99.16                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:55:53. Total running time: 3hr 19min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1130            770.802   229465      3.86                    13                        0                99.08                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:56:23. Total running time: 3hr 19min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1171             799.19   237921      3.54                     9                        0               100.7                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:56:53. Total running time: 3hr 20min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1212            827.466   246310      3.71                    10                        0                99.95                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:57:23. Total running time: 3hr 20min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1253            856.055   254850      3.79                     9                        1                99.72                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:57:53. Total running time: 3hr 21min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1293            884.432   263269      3.84                    10                        0                99.12                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:58:23. Total running time: 3hr 21min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1333            912.551   271647      3.66                     7                        0                99.88                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:58:53. Total running time: 3hr 22min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1374             940.83   280086      3.99                    12                        1                99.51                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:59:23. Total running time: 3hr 22min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1414            969.502   288612      4.21                     9                        1                99.4                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:59:53. Total running time: 3hr 23min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1452            997.804   297053      4.36                    10                        0                96.53                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:00:23. Total running time: 3hr 23min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1492            1025.89   305403      4.08                     8                        1                98.52                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:00:53. Total running time: 3hr 24min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1532            1054.61   313935      4.33                     8                        0                99.46                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:01:23. Total running time: 3hr 24min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1571            1082.8    322334      4.23                     9                        0                98.71                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:01:53. Total running time: 3hr 25min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1611            1111.46   330857      4.17                    10                        1                98.94                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:02:23. Total running time: 3hr 25min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1651            1139.89   339333      3.9                     10                        0                99.56                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:02:53. Total running time: 3hr 26min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1689            1167.65   347623      4.64                    10                        2                97.88                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:03:23. Total running time: 3hr 26min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1728            1196.84   356306      4.6                     11                        0                96.63                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:03:53. Total running time: 3hr 27min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1767            1225.38   364814      4.47                    10                        1                96.9                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:04:23. Total running time: 3hr 27min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1805            1253.27   373133      4.28                     8                        0                95.37                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:04:54. Total running time: 3hr 28min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1844            1281.74   381614      4.55                    10                        0                96.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:05:24. Total running time: 3hr 28min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1886            1310.77   390276      4.31                    11                        1                99.02                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:05:54. Total running time: 3hr 29min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1924            1338.86   398619      4.61                    13                        0                96.26                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:06:24. Total running time: 3hr 29min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     1962            1367.01   407001      4.42                     8                        0                96.79                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:06:54. Total running time: 3hr 30min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2001            1395.52   415455      4.59                    10                        0                96.45                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:07:24. Total running time: 3hr 30min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2041            1424.53   424092      4.41                     9                        1                93.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:07:54. Total running time: 3hr 31min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2079            1452.63   432434      4.58                    12                        0                92.68                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:08:24. Total running time: 3hr 31min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2117            1481.48   441011      4.73                    14                        0                95.6                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:08:54. Total running time: 3hr 32min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2156            1509.64   449400      4.62                    10                        1                96.23                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:09:24. Total running time: 3hr 32min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2195            1538.17   457874      4.85                     9                        1                96.86                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:09:54. Total running time: 3hr 33min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2233            1566.75   466404      4.54                    14                        1                97.42                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:10:24. Total running time: 3hr 33min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2271            1595.39   474918      4.58                     8                        0                95.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:10:54. Total running time: 3hr 34min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2309            1623.7    483357      4.52                    10                        0                94.12                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:11:24. Total running time: 3hr 34min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2347            1652.5    491944      4.61                    12                        0                95.97                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:11:54. Total running time: 3hr 35min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2386            1681.1    500419      4.66                    10                        1                92.54                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:12:24. Total running time: 3hr 35min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2425            1709.58   508910      4.82                    10                        1                95                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:12:54. Total running time: 3hr 36min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2463            1737.73   517277      4.86                     9                        1                95.35                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:13:25. Total running time: 3hr 36min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2501            1766.18   525732      4.43                     8                        1                96.22                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:13:55. Total running time: 3hr 37min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2541            1795.28   534429      4.66                    11                        1                95.54                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:14:25. Total running time: 3hr 37min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2579            1823.89   542967      5.07                    12                        2                93.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:14:55. Total running time: 3hr 38min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2617            1852.13   551388      4.63                    10                        1                94.23                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:15:25. Total running time: 3hr 38min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2655            1880.27   559768      4.74                    10                        0                94.64                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:15:55. Total running time: 3hr 39min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2694            1909.44   568431      4.67                    10                        1                96.14                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:16:25. Total running time: 3hr 39min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2732            1937.64   576854      4.64                    10                        1                96.35                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:16:55. Total running time: 3hr 40min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2771            1965.98   585272      4.84                    11                        1                96.3                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:17:25. Total running time: 3hr 40min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2809            1995.26   594007      4.88                    14                        1                92.54                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:17:55. Total running time: 3hr 41min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2847            2023.73   602451      4.93                    14                        1                90.11                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:18:25. Total running time: 3hr 41min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2885            2051.76   610803      4.81                     9                        0                97.2                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:18:55. Total running time: 3hr 42min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2923            2080.13   619235      4.89                    12                        1                93.29                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:19:25. Total running time: 3hr 42min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     2961            2108.97   627775      4.67                     9                        1                94.49                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:19:56. Total running time: 3hr 43min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3000            2137.74   636341      4.68                    11                        2                92.61                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:20:26. Total running time: 3hr 43min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3037            2166.33   644797      4.91                    11                        1                92.98                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:20:56. Total running time: 3hr 44min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3075            2194.99   653315      4.7                     10                        0                94.34                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:21:26. Total running time: 3hr 44min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3112            2222.96   661624      4.62                    10                        1                92.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:21:56. Total running time: 3hr 45min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3151            2252.01   670249      4.64                     9                        1                94.53                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:22:26. Total running time: 3hr 45min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3189            2280.42   678682      4.7                     14                        1                92.8                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:22:56. Total running time: 3hr 46min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3227            2308.65   687019      4.68                     8                        1                95.51                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:23:26. Total running time: 3hr 46min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3265            2337.51   695619      4.96                    10                        2                90.24                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:23:56. Total running time: 3hr 47min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3303            2365.83   704038      4.82                     8                        1                93.17                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:24:26. Total running time: 3hr 47min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3342            2394.7    712591      4.66                    11                        1                94.56                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:24:56. Total running time: 3hr 48min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3378            2422.79   720958      4.5                      8                        1                95.06                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:25:26. Total running time: 3hr 48min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3415            2451.06   729340      4.86                    10                        2                92.53                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:25:56. Total running time: 3hr 49min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3453            2480.18   737985      4.95                    12                        1                91.33                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:26:26. Total running time: 3hr 49min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3492            2508.87   746520      4.83                    10                        1                94.71                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:26:56. Total running time: 3hr 50min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3529            2536.87   754817      4.98                    10                        1                94                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:27:26. Total running time: 3hr 50min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3568            2565.87   763472      5.11                    10                        1                92.7                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:27:56. Total running time: 3hr 51min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3605            2594.21   771893      4.44                     8                        0                94.35                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:28:26. Total running time: 3hr 51min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3641            2623.02   780451      5.05                    11                        2                89.91                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:28:56. Total running time: 3hr 52min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3679            2651.47   788937      4.59                    10                        1                95.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:29:26. Total running time: 3hr 52min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3717            2679.99   797381      5.11                    10                        1                94.5                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:29:56. Total running time: 3hr 53min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3754            2708.12   805729      4.89                    10                        1                93.49                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:30:26. Total running time: 3hr 53min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3793            2736.84   814249      4.73                    10                        1                95.77                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:30:56. Total running time: 3hr 54min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3831            2764.88   822596      4.77                     8                        0                94.55                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:31:26. Total running time: 3hr 54min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3869            2793.88   831218      5.05                    13                        0                92.44                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:31:56. Total running time: 3hr 55min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3908            2821.81   839493      4.48                    10                        0                97.83                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:32:27. Total running time: 3hr 55min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3946            2850.77   848109      5.2                     11                        0                92.22                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:32:57. Total running time: 3hr 56min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     3983            2879.76   856683      5.09                    12                        1                91.04                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:33:27. Total running time: 3hr 56min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4019            2908.06   865096      5.07                    10                        0                90.48                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:33:57. Total running time: 3hr 57min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4058            2936.67   873605      4.93                    16                        0                94.18                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:34:27. Total running time: 3hr 57min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4095            2964.92   881984      4.82                    10                        1                91.87                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:34:57. Total running time: 3hr 58min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4134            2993.61   890508      4.6                     10                        1                93.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:35:27. Total running time: 3hr 58min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4172            3022.38   899050      4.85                    10                        1                92.91                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:35:57. Total running time: 3hr 59min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4208            3050.29   907368      5.09                    11                        1                88.7                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:36:27. Total running time: 3hr 59min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4245            3079.14   915942      5.05                     9                        1                91.69                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:36:57. Total running time: 4hr 0min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4283            3108.13   924553      4.9                     11                        0                91.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:37:27. Total running time: 4hr 0min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4318            3136.13   932895      5.11                    10                        2                89.85                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:37:57. Total running time: 4hr 1min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4355            3165.1    941503      5.18                    13                        0                89.18                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:38:27. Total running time: 4hr 1min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4392            3193.81   950027      4.97                     9                        1                91.9                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:38:57. Total running time: 4hr 2min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00004   RUNNING      independent        type_3                     4428            3221.91   958389      5.16                    10                        1                88.43                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00004 completed after 4437 iterations at 2023-11-24 05:39:06. Total running time: 4hr 2min 33s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00004 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                        9999 │
│ time_this_iter_s                                                                   1.08441 │
│ time_total_s                                                                    3229.63098 │
│ timesteps_total                                                                     960653 │
│ training_iteration                                                                    4437 │
│ agent_timesteps_total                                                              1921306 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                        0.0033534765243530273 │
│ connector_metrics/StateBufferConnector_ms                            0.0025408267974853516 │
│ connector_metrics/ViewRequirementAgentConnector_ms                     0.15821552276611328 │
│ counters/num_agent_steps_sampled                                                   1921306 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      960653 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               2 │
│ custom_metrics/assists_mean                                                            0.2 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             4.78 │
│ custom_metrics/kills_min                                                                 1 │
│ custom_metrics/predator_0_assists_max                                                    2 │
│ custom_metrics/predator_0_assists_mean                                                 0.1 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      5 │
│ custom_metrics/predator_0_kills_mean                                                   2.4 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    1 │
│ custom_metrics/predator_1_assists_mean                                                 0.1 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      6 │
│ custom_metrics/predator_1_kills_mean                                                  2.38 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     87.75 │
│ episode_reward_max                                                                     10. │
│ episode_reward_mean                                                                   5.18 │
│ episode_reward_min                                                                      1. │
│ episodes_this_iter                                                                       3 │
│ hist_stats/episode_lengths                                            ...01, 90, 101, 101] │
│ hist_stats/episode_reward                                             ...0, 6.0, 5.0, 4.0] │
│ hist_stats/policy_predator_0_reward                                   ...5, 1.0, 3.0, 2.0] │
│ hist_stats/policy_predator_1_reward                                   ...5, 5.0, 2.0, 2.0] │
│ info/learner/__all__/num_agent_steps_trained                                         256.0 │
│ info/learner/__all__/num_env_steps_trained                                           292.0 │
│ info/learner/__all__/total_loss                                         1.2786639978488286 │
│ info/learner/predator_0/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_0/curr_lr                                                     0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_0/entropy                                         1.2934683163960774 │
│ info/learner/predator_0/mean_kl_loss                                 9.130869936295008e-06 │
│ info/learner/predator_0/policy_loss                                    0.03298100270330906 │
│ info/learner/predator_0/total_loss                                      1.2786639978488286 │
│ info/learner/predator_0/vf_explained_var                               0.18391280869642893 │
│ info/learner/predator_0/vf_loss                                         0.4418540808061759 │
│ info/learner/predator_0/vf_loss_unclipped                               0.4418540808061759 │
│ info/learner/predator_1/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_1/curr_lr                                                     0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_1/entropy                                         1.2168435752391815 │
│ info/learner/predator_1/mean_kl_loss                                 1.665999392722976e-05 │
│ info/learner/predator_1/policy_loss                                   -0.06381634374459584 │
│ info/learner/predator_1/total_loss                                      0.8038288975755373 │
│ info/learner/predator_1/vf_explained_var                                0.2528969496488571 │
│ info/learner/predator_1/vf_loss                                          0.867645217726628 │
│ info/learner/predator_1/vf_loss_unclipped                                0.867645217726628 │
│ info/num_agent_steps_sampled                                                       1921306 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          960653 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1921306 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               960653 │
│ num_env_steps_sampled_this_iter                                                        292 │
│ num_env_steps_sampled_throughput_per_sec                                         270.21351 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                  7.6 │
│ perf/ram_util_percent                                                                 19.6 │
│ policy_reward_max/predator_0                                                           5.5 │
│ policy_reward_max/predator_1                                                           6.0 │
│ policy_reward_mean/predator_0                                                          2.6 │
│ policy_reward_mean/predator_1                                                         2.58 │
│ policy_reward_min/predator_0                                                           0.0 │
│ policy_reward_min/predator_1                                                           0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.1458700330298428 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.10846152912111454 │
│ sampler_perf/mean_inference_ms                                          2.2153559667626346 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5780643738070517 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms        0.0033534765243530273 │
│ sampler_results/connector_metrics/StateBufferConnector_ms            0.0025408267974853516 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms     0.15821552276611328 │
│ sampler_results/custom_metrics/assists_max                                               2 │
│ sampler_results/custom_metrics/assists_mean                                            0.2 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             4.78 │
│ sampler_results/custom_metrics/kills_min                                                 1 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    2 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                 0.1 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      5 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.4 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    1 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                 0.1 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                  2.38 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     87.75 │
│ sampler_results/episode_reward_max                                                    10.0 │
│ sampler_results/episode_reward_mean                                                   5.18 │
│ sampler_results/episode_reward_min                                                     1.0 │
│ sampler_results/episodes_this_iter                                                       3 │
│ sampler_results/hist_stats/episode_lengths                            ...01, 90, 101, 101] │
│ sampler_results/hist_stats/episode_reward                             ...0, 6.0, 5.0, 4.0] │
│ sampler_results/hist_stats/policy_predator_0_reward                   ...5, 1.0, 3.0, 2.0] │
│ sampler_results/hist_stats/policy_predator_1_reward                   ...5, 5.0, 2.0, 2.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/predator_0                                           5.5 │
│ sampler_results/policy_reward_max/predator_1                                           6.0 │
│ sampler_results/policy_reward_mean/predator_0                                          2.6 │
│ sampler_results/policy_reward_mean/predator_1                                         2.58 │
│ sampler_results/policy_reward_min/predator_0                                           0.0 │
│ sampler_results/policy_reward_min/predator_1                                           0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.1458700330298428 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.10846152912111454 │
│ sampler_results/sampler_perf/mean_inference_ms                          2.2153559667626346 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5780643738070517 │
│ timers/sample_time_ms                                                              781.076 │
│ timers/synch_weights_time_ms                                                         0.927 │
│ timers/training_iteration_time_ms                                                  850.908 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00005 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00005 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_3 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:39:27. Total running time: 4hr 2min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                       38            18.1103     7676    1.73684                    5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858    4.75                       6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171    5.78                       6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372    5.315                      6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069    5.84                       7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437          3229.63     960653    5.18                      10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:39:57. Total running time: 4hr 3min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                       96            46.0115    19490      1.98                     8                        0               100.97                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437          3229.63     960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:40:28. Total running time: 4hr 3min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      155            74.2569    31408      2.05                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437          3229.63     960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:40:58. Total running time: 4hr 4min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      214             102.46    43326      2.12                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:41:28. Total running time: 4hr 4min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      272            130.208    55042      2.27                     7                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:41:58. Total running time: 4hr 5min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      331            158.536    66960      2.25                     9                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:42:28. Total running time: 4hr 5min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      388            186.209    78614      2.42                     8                        0               100.38                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:42:58. Total running time: 4hr 6min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      447            214.508    90531      2.9                     10                        0               100.99                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:43:28. Total running time: 4hr 6min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      504             242.47   102251      3.16                     8                        0               100.03                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:43:58. Total running time: 4hr 7min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      562            270.332   113967      3.46                     9                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:44:28. Total running time: 4hr 7min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      619            298.565   125864      3.6                      8                        0                99.78                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:44:58. Total running time: 4hr 8min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      677            326.528   137646      3.23                     7                        0               100.65                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:45:28. Total running time: 4hr 8min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      735            354.563   149489      3.88                    10                        1               100.27                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:45:58. Total running time: 4hr 9min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      791             382.77   161349      4.12                    10                        1                98.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:46:28. Total running time: 4hr 9min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      846            410.795   173161      4.31                    11                        0                98.27                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:46:58. Total running time: 4hr 10min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      902             439.21   185098      4.35                    10                        0                98.3                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:47:28. Total running time: 4hr 10min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                      958            467.553   197044      4                        9                        0                99.6                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:47:58. Total running time: 4hr 11min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1012            495.324   208735      4.4                     10                        0                97.37                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:48:28. Total running time: 4hr 11min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1067            523.763   220753      4.34                     9                        0                98.22                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:48:58. Total running time: 4hr 12min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1121            551.696   232573      4.6                     11                        0                95.46                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:49:28. Total running time: 4hr 12min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1175            580.154   244556      4.76                    10                        1                95.16                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:49:59. Total running time: 4hr 13min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1230            608.269   256395      4.27                     9                        1                96.55                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:50:29. Total running time: 4hr 13min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1283            636.181   268148      4.62                    12                        0                95.93                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:50:59. Total running time: 4hr 14min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1339            665.028   280270      4.25                     9                        1                96.34                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:51:29. Total running time: 4hr 14min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1392            692.974   292086      4.79                    14                        1                91.98                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:51:59. Total running time: 4hr 15min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1447             721.24   304024      4.71                    14                        0                97.59                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:52:29. Total running time: 4hr 15min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1502            749.595   315915      4.68                    12                        1                94.67                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:52:59. Total running time: 4hr 16min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1557            778.063   327937      4.7                     10                        1                94.33                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:53:29. Total running time: 4hr 16min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1610            806.174   339754      4.86                    13                        1                94.43                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:53:59. Total running time: 4hr 17min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1664            834.623   351780      4.94                    10                        1                93.82                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:54:29. Total running time: 4hr 17min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1719            863.125   363836      4.75                    12                        1                95.22                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:54:59. Total running time: 4hr 18min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1770             890.95   375545      4.88                    12                        1                96.1                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:55:29. Total running time: 4hr 18min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1824            919.409   387565      4.67                    10                        0                96.69                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:55:59. Total running time: 4hr 19min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1878            947.704   399497      4.45                    10                        0                96.38                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:56:29. Total running time: 4hr 19min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1931            975.961   411376      5.02                    10                        1                91.83                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:56:59. Total running time: 4hr 20min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     1984            1004.37   423314      4.77                    10                        1                95.33                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:57:29. Total running time: 4hr 20min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2039            1032.67   435237      4.85                    14                        1                91.47                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:57:59. Total running time: 4hr 21min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2092            1060.8    447060      4.49                    10                        1                94.7                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:58:29. Total running time: 4hr 21min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2146            1088.88   458916      5.14                    14                        1                87.12                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:58:59. Total running time: 4hr 22min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2201            1117.73   471081      4.92                    13                        1                92.45                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:59:29. Total running time: 4hr 22min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2254            1145.86   482923      4.73                    10                        1                94.45                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:59:59. Total running time: 4hr 23min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2307            1174.35   494933      5.05                    12                        1                90.58                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:00:30. Total running time: 4hr 23min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2361            1202.88   506987      4.58                    12                        1                94.19                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:01:00. Total running time: 4hr 24min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2416            1230.9    518780      4.43                    10                        1                95.8                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:01:30. Total running time: 4hr 24min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2467            1259.08   530691      4.92                    11                        1                93.59                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:02:00. Total running time: 4hr 25min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2520            1287.95   542848      5.04                    10                        1                90.69                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:02:30. Total running time: 4hr 25min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2573            1316.3    554837      4.94                    10                        0                93.26                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:03:00. Total running time: 4hr 26min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2625            1344.55   566777      5.04                    12                        1                92.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:03:30. Total running time: 4hr 26min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2679            1372.8    578664      4.97                    11                        1                93.26                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:04:00. Total running time: 4hr 27min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2733            1401.32   590723      5.14                    12                        1                89.16                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:04:30. Total running time: 4hr 27min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2788            1429.71   602751      4.64                     9                        1                94.32                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:05:00. Total running time: 4hr 28min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2840            1457.86   614609      4.83                     9                        1                91.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:05:30. Total running time: 4hr 28min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2892            1486.32   626651      4.98                    10                        0                90.27                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:06:00. Total running time: 4hr 29min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2943            1514.63   638563      5.1                     10                        1                90.93                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:06:30. Total running time: 4hr 29min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     2996            1543.04   650574      5.09                    14                        0                93.24                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:07:00. Total running time: 4hr 30min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3049            1570.92   662287      4.92                     9                        1                92.73                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:07:30. Total running time: 4hr 30min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3101            1599.62   674430      4.77                    10                        0                93.32                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:08:00. Total running time: 4hr 31min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3154            1627.93   686329      4.94                    12                        1                93.73                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:08:30. Total running time: 4hr 31min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3208            1656.22   698324      4.83                    11                        0                95.12                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:09:01. Total running time: 4hr 32min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3261            1684.34   710182      5.1                     12                        1                93.95                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:09:31. Total running time: 4hr 32min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3313            1712.47   722020      4.91                    12                        0                91.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:10:01. Total running time: 4hr 33min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3367            1741.01   734060      4.9                      9                        0                92.43                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:10:31. Total running time: 4hr 33min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3419            1769.05   745895      4.66                    10                        1                92.92                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:11:01. Total running time: 4hr 34min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3473            1797.65   757897      4.55                    11                        1                93.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:11:31. Total running time: 4hr 34min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3525            1825.92   769833      5.12                    11                        1                87.61                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:12:01. Total running time: 4hr 35min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3579            1854.07   781684      4.78                    11                        2                92.35                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:12:31. Total running time: 4hr 35min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3632            1882.62   793752      4.95                    10                        1                92.21                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:13:01. Total running time: 4hr 36min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3683            1910.69   805594      4.89                     9                        1                92.52                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:13:31. Total running time: 4hr 36min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3736            1939.01   817485      5.15                    10                        0                90.35                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:14:01. Total running time: 4hr 37min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3791            1967.66   829583      4.77                    12                        2                94.42                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:14:31. Total running time: 4hr 37min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3843            1995.72   841419      5.01                    11                        1                93.01                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:15:01. Total running time: 4hr 38min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3897            2024.13   853408      4.88                    14                        0                91.68                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:15:31. Total running time: 4hr 38min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     3949            2052.34   865322      4.86                    14                        2                92.88                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:16:01. Total running time: 4hr 39min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     4003            2080.55   877211      4.75                    13                        0                94.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:16:31. Total running time: 4hr 39min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     4059            2108.78   889082      4.32                    10                        1                95.48                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:17:01. Total running time: 4hr 40min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     4113            2137.05   900932      5.07                    11                        1                94.73                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:17:31. Total running time: 4hr 40min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     4167            2165.33   912841      4.65                    11                        1                90.72                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:18:01. Total running time: 4hr 41min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     4222            2193.42   924644      4.2                      8                        0                96.7                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:18:31. Total running time: 4hr 41min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00005   RUNNING      shared             type_3                     4276            2221.79   936606      4.96                    10                        2                92.39                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00005 completed after 4325 iterations at 2023-11-24 06:18:59. Total running time: 4hr 42min 26s
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00005 result                                                         │
├─────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                         │
│ episodes_total                                                                        10000 │
│ time_this_iter_s                                                                    0.66282 │
│ time_total_s                                                                     2247.30357 │
│ timesteps_total                                                                      947356 │
│ training_iteration                                                                     4325 │
│ agent_timesteps_total                                                               1894712 │
│ callback_ok                                                                            True │
│ connector_metrics/ObsPreprocessorConnector_ms                          0.004979133605957031 │
│ connector_metrics/StateBufferConnector_ms                             0.0035784244537353516 │
│ connector_metrics/ViewRequirementAgentConnector_ms                       0.3117246627807617 │
│ counters/num_agent_steps_sampled                                                    1894712 │
│ counters/num_agent_steps_trained                                                          0 │
│ counters/num_env_steps_sampled                                                       947356 │
│ counters/num_env_steps_trained                                                            0 │
│ custom_metrics/assists_max                                                                2 │
│ custom_metrics/assists_mean                                                             0.2 │
│ custom_metrics/assists_min                                                                0 │
│ custom_metrics/kills_max                                                                  6 │
│ custom_metrics/kills_mean                                                               4.4 │
│ custom_metrics/kills_min                                                                  1 │
│ custom_metrics/predator_0_assists_max                                                     2 │
│ custom_metrics/predator_0_assists_mean                                                  0.1 │
│ custom_metrics/predator_0_assists_min                                                     0 │
│ custom_metrics/predator_0_kills_max                                                       5 │
│ custom_metrics/predator_0_kills_mean                                                   2.25 │
│ custom_metrics/predator_0_kills_min                                                       0 │
│ custom_metrics/predator_1_assists_max                                                     2 │
│ custom_metrics/predator_1_assists_mean                                                  0.1 │
│ custom_metrics/predator_1_assists_min                                                     0 │
│ custom_metrics/predator_1_kills_max                                                       6 │
│ custom_metrics/predator_1_kills_mean                                                   2.15 │
│ custom_metrics/predator_1_kills_min                                                       0 │
│ episode_len_mean                                                                      92.11 │
│ episode_reward_max                                                                      10. │
│ episode_reward_mean                                                                     4.8 │
│ episode_reward_min                                                                       1. │
│ episodes_this_iter                                                                        3 │
│ hist_stats/episode_lengths                                             ...01, 77, 101, 101] │
│ hist_stats/episode_reward                                              ...0, 8.0, 2.0, 3.0] │
│ hist_stats/policy_shared_policy_reward                                 ...0, 1.0, 1.0, 2.0] │
│ info/learner/__all__/num_agent_steps_trained                                          128.0 │
│ info/learner/__all__/num_env_steps_trained                                            558.0 │
│ info/learner/__all__/total_loss                                          0.3380318483845754 │
│ info/learner/shared_policy/curr_entropy_coeff                                           0.0 │
│ info/learner/shared_policy/curr_kl_coeff                                                0.0 │
│ info/learner/shared_policy/curr_lr                                                   0.0001 │
│ info/learner/shared_policy/default_optimizer_lr                       9.999999999999999e-05 │
│ info/learner/shared_policy/entropy                                        1.263212350281802 │
│ info/learner/shared_policy/mean_kl_loss                              0.00019711935951766628 │
│ info/learner/shared_policy/policy_loss                                 -0.01208450577475808 │
│ info/learner/shared_policy/total_loss                                    0.3380318483845754 │
│ info/learner/shared_policy/vf_explained_var                             0.35000514713200653 │
│ info/learner/shared_policy/vf_loss                                      0.35011635246601974 │
│ info/learner/shared_policy/vf_loss_unclipped                             0.3519715185869824 │
│ info/num_agent_steps_sampled                                                        1894712 │
│ info/num_agent_steps_trained                                                              0 │
│ info/num_env_steps_sampled                                                           947356 │
│ info/num_env_steps_trained                                                                0 │
│ num_agent_steps_sampled                                                             1894712 │
│ num_agent_steps_trained                                                                   0 │
│ num_env_steps_sampled                                                                947356 │
│ num_env_steps_sampled_this_iter                                                         279 │
│ num_env_steps_sampled_throughput_per_sec                                          423.20665 │
│ num_env_steps_trained                                                                     0 │
│ num_env_steps_trained_this_iter                                                           0 │
│ num_env_steps_trained_throughput_per_sec                                                 0. │
│ num_faulty_episodes                                                                       0 │
│ num_healthy_workers                                                                       0 │
│ num_in_flight_async_reqs                                                                  0 │
│ num_remote_worker_restarts                                                                0 │
│ num_steps_trained_this_iter                                                               0 │
│ perf/cpu_util_percent                                                                   8.5 │
│ perf/ram_util_percent                                                                  19.8 │
│ policy_reward_max/shared_policy                                                         6.0 │
│ policy_reward_mean/shared_policy                                                        2.4 │
│ policy_reward_min/shared_policy                                                         0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.12476145765424082 │
│ sampler_perf/mean_env_render_ms                                                         0.0 │
│ sampler_perf/mean_env_wait_ms                                           0.10326564459132287 │
│ sampler_perf/mean_inference_ms                                            1.264883273528015 │
│ sampler_perf/mean_raw_obs_processing_ms                                  0.5584028170658353 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms          0.004979133605957031 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.0035784244537353516 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms       0.3117246627807617 │
│ sampler_results/custom_metrics/assists_max                                                2 │
│ sampler_results/custom_metrics/assists_mean                                             0.2 │
│ sampler_results/custom_metrics/assists_min                                                0 │
│ sampler_results/custom_metrics/kills_max                                                  6 │
│ sampler_results/custom_metrics/kills_mean                                               4.4 │
│ sampler_results/custom_metrics/kills_min                                                  1 │
│ sampler_results/custom_metrics/predator_0_assists_max                                     2 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                  0.1 │
│ sampler_results/custom_metrics/predator_0_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                       5 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.25 │
│ sampler_results/custom_metrics/predator_0_kills_min                                       0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                     2 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                  0.1 │
│ sampler_results/custom_metrics/predator_1_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   2.15 │
│ sampler_results/custom_metrics/predator_1_kills_min                                       0 │
│ sampler_results/episode_len_mean                                                      92.11 │
│ sampler_results/episode_reward_max                                                     10.0 │
│ sampler_results/episode_reward_mean                                                     4.8 │
│ sampler_results/episode_reward_min                                                      1.0 │
│ sampler_results/episodes_this_iter                                                        3 │
│ sampler_results/hist_stats/episode_lengths                             ...01, 77, 101, 101] │
│ sampler_results/hist_stats/episode_reward                              ...0, 8.0, 2.0, 3.0] │
│ sampler_results/hist_stats/policy_shared_policy_reward                 ...0, 1.0, 1.0, 2.0] │
│ sampler_results/num_faulty_episodes                                                       0 │
│ sampler_results/policy_reward_max/shared_policy                                         6.0 │
│ sampler_results/policy_reward_mean/shared_policy                                        2.4 │
│ sampler_results/policy_reward_min/shared_policy                                         0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.12476145765424082 │
│ sampler_results/sampler_perf/mean_env_render_ms                                         0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                           0.10326564459132287 │
│ sampler_results/sampler_perf/mean_inference_ms                            1.264883273528015 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                  0.5584028170658353 │
│ timers/sample_time_ms                                                                437.75 │
│ timers/synch_weights_time_ms                                                          0.521 │
│ timers/training_iteration_time_ms                                                   499.158 │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b2630_00006 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b2630_00006 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x1458c0226cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:19:02. Total running time: 4hr 42min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                                                                                                                                                           │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:19:32. Total running time: 4hr 42min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                       42            28.6401     8484    1.63095                    4                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858    4.75                       6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171    5.78                       6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372    5.315                      6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069    5.84                       7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437          3229.63     960653    5.18                      10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325          2247.3      947356    4.8                       10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:20:02. Total running time: 4hr 43min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                       83            56.5892    16766      1.76                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437          3229.63     960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325          2247.3      947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:20:32. Total running time: 4hr 43min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      125            85.3115    25248      1.91                     6                        0               100.98                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452          3298.09     961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698          2000.58     834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368          3189.29     950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853          2034.77     858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437          3229.63     960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325          2247.3      947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:21:02. Total running time: 4hr 44min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      166            113.504    33588      1.71                     6                        0               100.57                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:21:32. Total running time: 4hr 44min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      207            141.508    41870      1.56                     4                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:22:02. Total running time: 4hr 45min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      249            170.213    50354      1.62                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:22:32. Total running time: 4hr 45min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      290            198.283    58636      1.68                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:23:02. Total running time: 4hr 46min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      331            226.285    66918      1.83                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:23:32. Total running time: 4hr 46min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      373            254.966    75402      1.84                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:24:02. Total running time: 4hr 47min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      415            283.509    83886      1.84                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:24:32. Total running time: 4hr 47min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      456            311.515    92168      1.9                      5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:25:02. Total running time: 4hr 48min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      497            339.399   100450      1.95                     6                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:25:32. Total running time: 4hr 49min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      539            368.076   108934      2.27                     4                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:26:02. Total running time: 4hr 49min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      580            396.135   117216      2.16                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:26:32. Total running time: 4hr 50min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      621            424.371   125578      2.19                     6                        0               100.79                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:27:03. Total running time: 4hr 50min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      663            453.394   134148      2.34                     6                        0               100.85                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:27:33. Total running time: 4hr 51min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      704            481.609   142501      2.33                     6                        0               100.55                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:28:03. Total running time: 4hr 51min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      745             509.62   150783      2.43                     6                        0               100.7                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:28:33. Total running time: 4hr 52min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      787            538.349   159315      2.49                     6                        0               100.47                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:29:03. Total running time: 4hr 52min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      828            566.343   167597      2.48                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:29:33. Total running time: 4hr 53min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      869            594.392   175879      2.75                     5                        0               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:30:03. Total running time: 4hr 53min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      911             623.02   184363      2.85                     5                        1               101                         2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:30:33. Total running time: 4hr 54min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      952            651.689   192816      3.01                     6                        0               100.69                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:31:03. Total running time: 4hr 54min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                      992            679.318   200978      2.8                      6                        0               100.5                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:31:33. Total running time: 4hr 55min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1033            707.797   209416      2.84                     6                        0               100.54                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:32:03. Total running time: 4hr 55min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1074            736.155   217783      3.04                     6                        0               100.67                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:32:33. Total running time: 4hr 56min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1114            764.392   226119      3.12                     6                        0               100.53                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:33:03. Total running time: 4hr 56min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1154             792.72   234460      3.57                     6                        1                99.37                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:33:33. Total running time: 4hr 57min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1195            821.557   243000      3.54                     6                        1                99.73                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:34:03. Total running time: 4hr 57min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1235            849.666   251335      3.64                     6                        1                99.41                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:34:33. Total running time: 4hr 58min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1276            878.567   259852      3.57                     6                        0                99.65                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:35:03. Total running time: 4hr 58min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1316            906.727   268210      3.74                     6                        1                98.54                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:35:33. Total running time: 4hr 59min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1355            934.821   276491      3.45                     6                        1                99.98                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:36:03. Total running time: 4hr 59min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1396            963.618   285018      3.62                     6                        0                99.08                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:36:33. Total running time: 5hr 0min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1434            991.884   293374      3.88                     6                        1                98.37                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452           3298.09    961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698           2000.58    834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368           3189.29    950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853           2034.77    858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437           3229.63    960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325           2247.3     947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:37:04. Total running time: 5hr 0min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1475            1020.51   301850      3.71                     6                        0                99.39                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:37:34. Total running time: 5hr 1min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1515            1048.5    310159      3.69                     6                        0                99.77                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:38:04. Total running time: 5hr 1min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1554            1076.8    318479      3.9                      6                        1                98.35                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:38:34. Total running time: 5hr 2min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1593            1105.1    326875      3.86                     6                        1                97.82                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:39:04. Total running time: 5hr 2min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1632            1134      335417      4.15                     6                        1                95.57                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:39:34. Total running time: 5hr 3min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1672            1162.1    343719      3.96                     6                        1                99.32                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:40:04. Total running time: 5hr 3min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1711            1190.86   352224      4.21                     6                        1                97.17                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:40:34. Total running time: 5hr 4min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1750            1219.17   360560      3.89                     6                        1                99.33                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:41:04. Total running time: 5hr 4min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1789            1247.66   368988      3.89                     6                        0                97.41                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:41:34. Total running time: 5hr 5min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1829            1276.34   377466      3.98                     6                        1                96.96                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:42:04. Total running time: 5hr 5min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1868            1304.62   385803      3.96                     6                        1                99.05                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:42:34. Total running time: 5hr 6min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1907            1333.07   394222      4.09                     6                        1                98.33                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:43:04. Total running time: 5hr 6min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1946            1361.65   402629      4.28                     6                        1                97.15                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:43:34. Total running time: 5hr 7min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     1984            1390.65   411220      4.38                     6                        1                94.61                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:44:04. Total running time: 5hr 7min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2021            1419.05   419632      4.35                     6                        2                96.99                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:44:34. Total running time: 5hr 8min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2059            1447.44   428011      4.23                     6                        1                96.65                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:45:04. Total running time: 5hr 8min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2098            1475.78   436411      4.36                     6                        2                96.19                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:45:34. Total running time: 5hr 9min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2136            1504.41   444876      4.08                     6                        1                96.2                       3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:46:04. Total running time: 5hr 9min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2175            1532.96   453324      4.16                     6                        1                96.23                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:46:34. Total running time: 5hr 10min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2214            1561.7    461829      4.35                     6                        1                94.43                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:47:04. Total running time: 5hr 10min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2250            1590.14   470285      4.43                     6                        0                95.26                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:47:34. Total running time: 5hr 11min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2287            1618.23   478605      4.21                     6                        0                95.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:48:04. Total running time: 5hr 11min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2326            1647.23   487176      4.04                     6                        0                97.23                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:48:35. Total running time: 5hr 12min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2364            1675.81   495637      4.19                     6                        1                97.28                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:49:05. Total running time: 5hr 12min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2402            1704.04   503961      4.29                     6                        2                96.86                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:49:35. Total running time: 5hr 13min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2441            1732.75   512442      4.5                      6                        1                93.27                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:50:05. Total running time: 5hr 13min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2479            1760.85   520752      4.39                     6                        1                96.79                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:50:35. Total running time: 5hr 14min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2515            1789.42   529180      4.45                     6                        2                92.36                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:51:05. Total running time: 5hr 14min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2553            1818.13   537707      4.3                      6                        1                95.09                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:51:35. Total running time: 5hr 15min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2591            1846.69   546137      4.29                     6                        1                95.63                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:52:05. Total running time: 5hr 15min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2629            1874.95   554498      4.43                     6                        1                94.99                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:52:35. Total running time: 5hr 16min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2666            1903.63   562966      4.39                     6                        1                94.2                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:53:05. Total running time: 5hr 16min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2704            1932.41   571451      4.45                     6                        1                91.92                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:53:35. Total running time: 5hr 17min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2742            1961.01   579947      4.57                     6                        2                93.42                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:54:05. Total running time: 5hr 17min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2780            1989.85   588486      4.46                     6                        1                92.97                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:54:35. Total running time: 5hr 18min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2818            2018.52   596930      4.46                     6                        1                93.21                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:55:05. Total running time: 5hr 18min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2856            2046.97   605332      4.38                     6                        0                91.81                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:55:35. Total running time: 5hr 19min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2893            2075.04   613599      4.33                     6                        0                92.55                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:56:05. Total running time: 5hr 19min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2930            2103.46   622005      4.41                     6                        0                93.86                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:56:35. Total running time: 5hr 20min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     2968            2132.4    630530      4.38                     6                        1                91.97                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:57:05. Total running time: 5hr 20min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3006            2160.12   638745      4.32                     6                        1                95.8                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:57:35. Total running time: 5hr 21min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3043            2189.27   647390      4.49                     6                        1                90.94                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:58:06. Total running time: 5hr 21min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3082            2217.81   655795      4.3                      6                        1                97.01                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:58:36. Total running time: 5hr 22min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3118            2246.45   664275      4.57                     6                        0                90.49                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:59:06. Total running time: 5hr 22min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3154            2274.53   672549      4.4                      6                        1                93.85                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:59:36. Total running time: 5hr 23min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3190            2303.53   681112      4.48                     6                        1                91.73                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:00:06. Total running time: 5hr 23min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3226            2331.69   689461      4.53                     6                        1                94.01                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:00:36. Total running time: 5hr 24min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3264            2361.12   698155      4.56                     6                        2                89.55                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:01:06. Total running time: 5hr 24min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3302            2389.29   706519      4.49                     6                        1                95.57                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:01:36. Total running time: 5hr 25min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3340            2417.98   715006      4.49                     6                        1                91.94                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:02:06. Total running time: 5hr 25min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3378            2446.18   723289      4.57                     6                        1                90.9                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:02:36. Total running time: 5hr 26min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3417            2475.19   731872      4.41                     6                        2                93.73                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:03:06. Total running time: 5hr 26min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3455            2503.89   740339      4.51                     6                        1                92.84                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:03:36. Total running time: 5hr 27min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3493            2532.42   748791      4.54                     6                        2                93.93                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:04:06. Total running time: 5hr 27min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3529            2560.47   757086      4.65                     6                        1                90.72                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:04:36. Total running time: 5hr 28min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3566            2588.81   765463      4.49                     6                        1                94.29                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:05:06. Total running time: 5hr 28min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3604            2617.87   774075      4.49                     6                        1                93.19                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:05:37. Total running time: 5hr 29min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3639            2646.1    782405      4.7                      6                        0                92.11                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:06:07. Total running time: 5hr 29min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3677            2675.04   790936      4.75                     6                        2                91.2                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:06:37. Total running time: 5hr 30min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3714            2703.76   799395      4.64                     6                        1                91.13                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:07:07. Total running time: 5hr 30min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3752            2731.8    807698      4.24                     6                        0                93.92                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:07:37. Total running time: 5hr 31min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3788            2760.33   816143      4.54                     6                        2                91.52                      4 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:08:07. Total running time: 5hr 31min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3825            2788.94   824562      4.61                     6                        1                91.17                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:08:37. Total running time: 5hr 32min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3862            2817.21   832920      4.47                     6                        1                94.5                       2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:09:07. Total running time: 5hr 32min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3898            2845.54   841280      4.8                      6                        1                89.03                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:09:37. Total running time: 5hr 33min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3938            2874.68   849873      4.6                      6                        2                92.73                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:10:07. Total running time: 5hr 33min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     3975            2903.46   858401      4.83                     6                        1                90.33                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:10:37. Total running time: 5hr 34min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     4013            2931.53   866706      4.51                     6                        1                93.81                      3 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:11:07. Total running time: 5hr 34min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     4052            2960.39   875260      4.26                     6                        1                95.04                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:11:37. Total running time: 5hr 35min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b2630_00001 with episode_len_mean=63.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14481421ecb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b2630_00006   RUNNING      independent        type_1                     4089            2988.94   883686      4.45                     6                        1                94.66                      2 │
│ train_algo_b2630_00000   TERMINATED   independent        type_1                     4452            3298.09   961858      4.75                     6                        2                88.1                       4 │
│ train_algo_b2630_00001   TERMINATED   shared             type_1                     3698            2000.58   834171      5.78                     6                        4                63.07                      3 │
│ train_algo_b2630_00002   TERMINATED   independent        type_2                     4368            3189.29   950372      5.315                    6.5                      3                82.34                      2 │
│ train_algo_b2630_00003   TERMINATED   shared             type_2                     3853            2034.77   858069      5.84                     7                        3                67.61                      3 │
│ train_algo_b2630_00004   TERMINATED   independent        type_3                     4437            3229.63   960653      5.18                    10                        1                87.75                      3 │
│ train_algo_b2630_00005   TERMINATED   shared             type_3                     4325            2247.3    947356      4.8                     10                        1                92.11                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=153971, ip=172.26.92.193, actor_id=f8f993ff725b9bd4909f99e501000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 249, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 208, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1297, in _on_error
    on_error(trial, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1384, in _trial_task_failure
    self._process_trial_failure(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1406, in _process_trial_failure
    self._schedule_trial_stop(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1432, in _schedule_trial_stop
    trial.handle_error(exc=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/experiment/trial.py", line 741, in handle_error
    with open(self.pickled_error_file, "wb") as f:
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 364, in fit
    return self._local_tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 526, in fit
    analysis = self._fit_internal(trainable, param_space)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 645, in _fit_internal
    analysis = run(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tune.py", line 1007, in run
    runner.step()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 731, in step
    if not self._actor_manager.next(timeout=0.1):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 224, in next
    self._actor_task_events.resolve_future(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 113, in resolve_future
    on_error(e)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 770, in on_error
    self._actor_task_failed(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 289, in _actor_task_failed
    tracked_actor_task._on_error(tracked_actor, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1306, in _on_error
    raise TuneError(traceback.format_exc())
ray.tune.error.TuneError: Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=153971, ip=172.26.92.193, actor_id=f8f993ff725b9bd4909f99e501000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 249, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 208, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1297, in _on_error
    on_error(trial, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1384, in _trial_task_failure
    self._process_trial_failure(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1406, in _process_trial_failure
    self._schedule_trial_stop(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1432, in _schedule_trial_stop
    trial.handle_error(exc=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/experiment/trial.py", line 741, in handle_error
    with open(self.pickled_error_file, "wb") as f:
OSError: [Errno 122] Disk quota exceeded


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 254, in <module>
    main()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 248, in main
    results = tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 366, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore("/home/dalmiapriyam/ray_results/train_algo_2023-11-24_01-36-29", trainable=...)`.
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=153971, ip=172.26.92.193, actor_id=f8f993ff725b9bd4909f99e501000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 249, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 208, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1297, in _on_error
    on_error(trial, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1384, in _trial_task_failure
    self._process_trial_failure(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1406, in _process_trial_failure
    self._schedule_trial_stop(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1432, in _schedule_trial_stop
    trial.handle_error(exc=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/experiment/trial.py", line 741, in handle_error
    with open(self.pickled_error_file, "wb") as f:
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 364, in fit
    return self._local_tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 526, in fit
    analysis = self._fit_internal(trainable, param_space)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 645, in _fit_internal
    analysis = run(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tune.py", line 1007, in run
    runner.step()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 731, in step
    if not self._actor_manager.next(timeout=0.1):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 224, in next
    self._actor_task_events.resolve_future(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 113, in resolve_future
    on_error(e)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 770, in on_error
    self._actor_task_failed(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 289, in _actor_task_failed
    tracked_actor_task._on_error(tracked_actor, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1306, in _on_error
    raise TuneError(traceback.format_exc())
ray.tune.error.TuneError: Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=153971, ip=172.26.92.193, actor_id=f8f993ff725b9bd4909f99e501000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 249, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 208, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1297, in _on_error
    on_error(trial, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1384, in _trial_task_failure
    self._process_trial_failure(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1406, in _process_trial_failure
    self._schedule_trial_stop(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1432, in _schedule_trial_stop
    trial.handle_error(exc=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/experiment/trial.py", line 741, in handle_error
    with open(self.pickled_error_file, "wb") as f:
OSError: [Errno 122] Disk quota exceeded


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 254, in <module>
    main()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 248, in main
    results = tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 366, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore("/home/dalmiapriyam/ray_results/train_algo_2023-11-24_01-36-29", trainable=...)`.
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x144809e10310>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 156, in close
    self.flush()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 148, in flush
    self._ev_writer.flush()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 69, in flush
    self._py_recordio_writer.flush()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 193, in flush
    self._writer.flush()
OSError: [Errno 122] Disk quota exceeded
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████████▇▇▇▇▇▇▇▇▄▅▄▆▆▃▅▃▃▃▃▁▃▂▃▃▂▃▃▃▄
wandb:   episode_reward_mean ▁▂▁▂▂▂▂▃▄▄▄▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇██▇▇███▇██▇██▇
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 89.48
wandb:   episode_reward_mean 4.53
wandb:        episodes_total 9211
wandb: num_env_steps_sampled 886453
wandb: num_env_steps_trained 0
wandb:          time_total_s 2998.38481
wandb:    training_iteration 4101
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_061859-7gymh50n
wandb: Find logs at: ./wandb/offline-run-20231124_061859-7gymh50n/logs
Exception in thread Thread-72:
Traceback (most recent call last):
  File "/apps/easybuild-2022/easybuild/software/Compiler/GCCcore/11.3.0/Python/3.10.4/lib/python3.10/threading.py", line 1009, in _bootstrap_inner
    self.run()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/apps/easybuild-2022/easybuild/software/Compiler/GCCcore/11.3.0/Python/3.10.4/lib/python3.10/multiprocessing/queues.py", line 117, in get
    res = self._recv_bytes()
  File "/apps/easybuild-2022/easybuild/software/Compiler/GCCcore/11.3.0/Python/3.10.4/lib/python3.10/multiprocessing/connection.py", line 221, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/apps/easybuild-2022/easybuild/software/Compiler/GCCcore/11.3.0/Python/3.10.4/lib/python3.10/multiprocessing/connection.py", line 419, in _recv_bytes
    buf = self._recv(4)
  File "/apps/easybuild-2022/easybuild/software/Compiler/GCCcore/11.3.0/Python/3.10.4/lib/python3.10/multiprocessing/connection.py", line 388, in _recv
    raise EOFError
EOFError
Job ID           : 53748017
Cluster          : spartan
User/Project     : dalmiapriyam/punim1355
Nodes            : 1
Wall-clock time  : 05:35:34 / 20:00:00

Displaying overall resources usage from 2023-11-24 01:36:25 to 2023-11-24 07:11:59:

NODE            CPU#        TOT%   ( USR   / SYS   / WIO   / IDLE  ) 

spartan-gpgpu092 : 
                CPU# 1    : 2.2    (   1.1 /   1.0 /   0.0 /  81.2 ) 
                CPU# 2    : 2.1    (   1.0 /   1.1 /   0.0 /  82.2 ) 
                CPU# 3    : 2.0    (   1.0 /   1.0 /   0.0 /  81.4 ) 
                CPU# 4    : 2.0    (   1.0 /   1.0 /   0.0 /  81.8 ) 
                CPU# 5    : 2.1    (   1.0 /   1.1 /   0.0 /  81.8 ) 
                CPU# 6    : 2.1    (   1.0 /   1.1 /   0.0 /  81.1 ) 

                GPU# 1    : 0.0   


Allocated CPUs            : 6    
  CPUs with usage <25%    : 6    
  CPUs with usage <50%    : 0    
  CPUs with usage >50%    : 0    


Allocated GPUs            : 1    
  GPUs with usage <25%    : 1    
  GPUs with usage <50%    : 0    
  GPUs with usage >50%    : 0    

Memory used (RAM)         : 14.4%  [3636MB of 25166MB]

--------------------------------------------

