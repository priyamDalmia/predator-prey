
Name of the cluster on which the job is executing:	 spartan
Number of CPUs on the allocated node: 	 12
Number of CPUs requested per task: 	 12
Numer of GPUs requested: 	 
Requested GPU count per allocated node: 	 
Requested GPU count per allocated task:	  
The ID of the job allocation:	  54156206
Count of processors available to the job on this node:	  12
Name of the job:	  tst.slurm
List of nodes allocated to the job:	  spartan-gpgpu079
Total number of nodes in the jobâ€™s resource allocation:	  1
Name of the partition in which the job is running:	  deeplearn
Minimum memory required per allocated CPU:	  4000
Requested memory per allocated GPU:	  
Total amount of memory per node that the job needs:	  
List of nodes allocated to the job:	  spartan-gpgpu079
Total number of CPUs allocated:	  1
Maximum number of MPI tasks (thatâ€™s processes): 	 1
Number of tasks requested per core: 	 
Number of tasks requested per GPU: 	 
Number of tasks requested per node:	  1
The scheduling priority (nice value) at the time of job submission. This value is propagated to the spawned processes: 	 0
The MPI rank (or relative process ID) of the current process: 	 0

The directory from which SBATCH was invoked: 	 /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey
The Hostname of the computer from which SBATCH was invoked: 	 spartan-login3.hpc.unimelb.edu.au
The process ID of the corresponding task: 	 286234



 LOADING MODULES: 




 PYTHON SCRIPT OUTPUT: 

2023-12-06 22:44:36,250	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2023-12-06 22:44:39,733	INFO worker.py:1673 -- Started a local Ray instance.
2023-12-06 22:44:41,082	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2023-12-06 22:44:41,084	INFO tune.py:595 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
[36m(pid=288492)[0m 2023-12-06 22:45:05,317	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
[36m(train_algo pid=288483)[0m 2023-12-06 22:45:08,404	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=288483)[0m 2023-12-06 22:45:08,404	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=288465)[0m 2023-12-06 22:45:10,185	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!
[36m(pid=288479)[0m 2023-12-06 22:45:09,784	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.[32m [repeated 27x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(train_algo pid=288495)[0m wandb: Currently logged in as: theputernerdai (tpn). Use `wandb login --relogin` to force relogin
[36m(train_algo pid=288464)[0m 2023-12-06 22:45:12,303	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future![32m [repeated 27x across cluster][0m
[36m(train_algo pid=288464)[0m 2023-12-06 22:45:12,303	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future![32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
[36m(train_algo pid=288461)[0m wandb: - Waiting for wandb.init()...
[36m(train_algo pid=288483)[0m wandb: wandb version 0.16.1 is available!  To upgrade, please run:
[36m(train_algo pid=288483)[0m wandb:  $ pip install wandb --upgrade
[36m(train_algo pid=288483)[0m wandb: Tracking run with wandb version 0.16.0
[36m(train_algo pid=288483)[0m wandb: Run data is saved locally in /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/wandb/run-20231206_224512-73mct4ap
[36m(train_algo pid=288483)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(train_algo pid=288483)[0m wandb: Syncing run df1701933564
[36m(train_algo pid=288483)[0m wandb: â­ï¸ View project at https://wandb.ai/tpn/rllib5
[36m(train_algo pid=288483)[0m wandb: ðŸš€ View run at https://wandb.ai/tpn/rllib5/runs/73mct4ap
[36m(train_algo pid=288461)[0m wandb: \ Waiting for wandb.init()...
[36m(train_algo pid=288480)[0m wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...
[36m(train_algo pid=288495)[0m wandb: | Waiting for wandb.init()...
[36m(train_algo pid=288464)[0m 2023-12-06 22:45:12,653	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future![32m [repeated 27x across cluster][0m
[36m(train_algo pid=288482)[0m 2023-12-06 22:45:16,989	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.train_one_step` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=288482)[0m 2023-12-06 22:45:16,990	WARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=288464)[0m wandb: Currently logged in as: theputernerdai (tpn). Use `wandb login --relogin` to force relogin[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288475)[0m wandb: - Waiting for wandb.init()...[32m [repeated 6x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: wandb version 0.16.1 is available!  To upgrade, please run:[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb:  $ pip install wandb --upgrade[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: Tracking run with wandb version 0.16.0[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: Run data is saved locally in /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/wandb/run-20231206_224512-wd9ye4f9[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: Run `wandb offline` to turn off syncing.[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: Syncing run df1701947321[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: â­ï¸ View project at https://wandb.ai/tpn/rllib5[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: ðŸš€ View run at https://wandb.ai/tpn/rllib5/runs/wd9ye4f9[32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m wandb: \ Waiting for wandb.init()...[32m [repeated 6x across cluster][0m
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Configuration for experiment     train_algo_2023-12-06_22-44-36   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Search algorithm                 BasicVariantGenerator            â”‚
â”‚ Scheduler                        FIFOScheduler                    â”‚
â”‚ Number of trials                 92160                            â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

View detailed results here: /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/experiments/train_algo_2023-12-06_22-44-36
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-44-36`

Trial status: 30 PENDING
Current time: 2023-12-06 22:44:52. Total running time: 11s
Logical resource usage: 0/28 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:V100)
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ train_algo_d78e9_00000   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10 â”‚
â”‚ train_algo_d78e9_00001   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10 â”‚
â”‚ train_algo_d78e9_00002   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10 â”‚
â”‚ train_algo_d78e9_00003   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10 â”‚
â”‚ train_algo_d78e9_00004   PENDING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
25 more PENDING

Trial train_algo_d78e9_00023 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00023 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00013 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00013 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00010 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00010 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00006 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00006 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00022 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00022 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00008 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00008 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00004 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00004 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00012 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00012 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00014 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00014 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00001 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00001 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00002 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00002 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00025 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00025 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00021 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00021 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00003 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00003 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00020 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00020 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00015 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00015 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00016 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00016 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00005 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00005 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00000 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00000 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00024 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00024 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00011 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00011 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00027 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00027 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00019 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00019 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00026 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00026 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00017 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00017 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00009 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00009 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [3, 3], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [512, 512] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00018 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00018 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          relu â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         relu â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             64 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Trial train_algo_d78e9_00007 started with configuration:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Trial train_algo_d78e9_00007 config                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ algorithm_class                                          ppo â”‚
â”‚ algorithm_type                                   independent â”‚
â”‚ analysis/analysis                                      False â”‚
â”‚ analysis/ccm_E                                             4 â”‚
â”‚ analysis/ccm_tau                                           1 â”‚
â”‚ analysis/dimensions                     ...'PCA_1', 'PCA_2'] â”‚
â”‚ analysis/length_fac                                      500 â”‚
â”‚ analysis/num_trials                                        5 â”‚
â”‚ analysis/policy_set                     ...ginal', '_fixed'] â”‚
â”‚ analysis/pref_ccm_analysis                              True â”‚
â”‚ analysis/pref_granger_analysis                         False â”‚
â”‚ analysis/pref_graph_analysis                           False â”‚
â”‚ analysis/pref_spatial_ccm_analysis                     False â”‚
â”‚ env_config/map_size                                       15 â”‚
â”‚ env_config/max_cycles                                    100 â”‚
â”‚ env_config/npred                                           2 â”‚
â”‚ env_config/nprey                                           6 â”‚
â”‚ env_config/pred_vision                                     2 â”‚
â”‚ env_config/prey_type                                  static â”‚
â”‚ env_config/reward_type                                type_1 â”‚
â”‚ env_name                                      discrete_pp_v1 â”‚
â”‚ evaluate/eval_episodes                                   500 â”‚
â”‚ framework                                              torch â”‚
â”‚ ray/init_dashboard                                     False â”‚
â”‚ rollouts/batch_mode                        complete_episodes â”‚
â”‚ rollouts/num_rollout_workers                               0 â”‚
â”‚ stop_fn                                 ...t 0x1498db526dd0> â”‚
â”‚ training/lr                                           0.0001 â”‚
â”‚ training/model/conv_activation                          tanh â”‚
â”‚ training/model/conv_filters                [[16, [2, 2], 1]] â”‚
â”‚ training/model/fcnet_activation                         tanh â”‚
â”‚ training/model/fcnet_hiddens                      [256, 256] â”‚
â”‚ training/model/lstm_cell_size                             32 â”‚
â”‚ training/model/lstm_use_prev_action                     True â”‚
â”‚ training/model/lstm_use_prev_reward                     True â”‚
â”‚ training/model/max_seq_len                                10 â”‚
â”‚ training/model/use_lstm                                 True â”‚
â”‚ training/num_sgd_iter                                      5 â”‚
â”‚ training/sgd_minibatch_size                               64 â”‚
â”‚ training/train_batch_size                                256 â”‚
â”‚ training/use_critic                                     True â”‚
â”‚ training/use_kl_loss                                    True â”‚
â”‚ tune/max_concurrent_trials                                32 â”‚
â”‚ tune/max_episodes                                      25000 â”‚
â”‚ tune/num_samples                                           5 â”‚
â”‚ tune/tune                                               True â”‚
â”‚ wandb/wandb_dir_path                    ...edator-prey/wandb â”‚
â”‚ wandb/wandb_entity                                       tpn â”‚
â”‚ wandb/wandb_init                                        True â”‚
â”‚ wandb/wandb_log_freq                                      50 â”‚
â”‚ wandb/wandb_notes                              testing setup â”‚
â”‚ wandb/wandb_project                                   rllib5 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1272, in _on_result
    on_result(trial, *args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1571, in _on_training_result
    self._process_trial_results(trial, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1584, in _process_trial_results
    decision = self._process_trial_result(trial, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1641, in _process_trial_result
    self._callbacks.on_trial_result(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/callback.py", line 412, in on_trial_result
    callback.on_trial_result(**info)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/logger.py", line 142, in on_trial_result
    self.log_trial_result(iteration, trial, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 108, in log_trial_result
    self._trial_files[trial].flush()
OSError: [Errno 116] Stale file handle

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 364, in fit
    return self._local_tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 526, in fit
    analysis = self._fit_internal(trainable, param_space)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 645, in _fit_internal
    analysis = run(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tune.py", line 1007, in run
    runner.step()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 731, in step
    if not self._actor_manager.next(timeout=0.1):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 224, in next
    self._actor_task_events.resolve_future(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 118, in resolve_future
    on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 765, in on_result
    self._actor_task_resolved(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 300, in _actor_task_resolved
    tracked_actor_task._on_result(tracked_actor, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1281, in _on_result
    raise TuneError(traceback.format_exc())
ray.tune.error.TuneError: Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1272, in _on_result
    on_result(trial, *args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1571, in _on_training_result
    self._process_trial_results(trial, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1584, in _process_trial_results
    decision = self._process_trial_result(trial, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1641, in _process_trial_result
    self._callbacks.on_trial_result(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/callback.py", line 412, in on_trial_result
    callback.on_trial_result(**info)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/logger.py", line 142, in on_trial_result
    self.log_trial_result(iteration, trial, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 108, in log_trial_result
    self._trial_files[trial].flush()
OSError: [Errno 116] Stale file handle


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 396, in <module>
    main()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 363, in main
    results = tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 366, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore("/home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-44-36", trainable=...)`.
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c227d8af0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c23243880>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c227d8790>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c227d8160>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f73ac0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c09d0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f73760>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f73130>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f72b00>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c2440>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f72830>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f72170>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f71b40>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c23243be0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f717e0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f711b0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f70c10>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c3293cd30>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f70820>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c22f701f0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c1510>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c13f0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c3b50>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c15a0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c2c20>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c08b0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c1870>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x148c232c01f0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
[36m(train_algo pid=288495)[0m 2023-12-06 22:45:19,933	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.train_one_step` has been deprecated. This will raise an error in the future![32m [repeated 27x across cluster][0m
[36m(train_algo pid=288495)[0m 2023-12-06 22:45:19,934	WARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future![32m [repeated 27x across cluster][0m
Job ID           : 54156206
Cluster          : spartan
User/Project     : dalmiapriyam/punim1355
Nodes            : 1
Wall-clock time  : 00:01:08 / 1-00:00:00

Displaying overall resources usage from 2023-12-06 22:44:17 to 2023-12-06 22:45:25:

NODE            CPU#        TOT%   ( USR   / SYS   / WIO   / IDLE  ) 

spartan-gpgpu079 : 
                CPU# 1    : 11.5   (   6.5 /   5.1 /   0.0 /  79.9 ) 
                CPU# 2    : 9.4    (   5.0 /   4.5 /   0.0 /  81.8 ) 
                CPU# 3    : 7.5    (   3.6 /   3.9 /   0.0 /  83.8 ) 
                CPU# 4    : 6.9    (   3.6 /   3.4 /   0.0 /  84.2 ) 
                CPU# 5    : 9.3    (   4.9 /   4.4 /   0.0 /  82.3 ) 
                CPU# 6    : 7.2    (   3.5 /   3.7 /   0.0 /  84.0 ) 
                CPU# 7    : 9.0    (   5.1 /   3.9 /   0.0 /  82.4 ) 
                CPU# 8    : 6.8    (   3.5 /   3.3 /   0.0 /  84.4 ) 
                CPU# 9    : 7.7    (   3.6 /   4.1 /   0.0 /  83.9 ) 
                CPU# 10   : 8.0    (   3.6 /   4.4 /   0.0 /  84.1 ) 
                CPU# 11   : 8.3    (   3.9 /   4.4 /   0.0 /  83.4 ) 
                CPU# 12   : 40.0   (  33.5 /   6.5 /   0.0 /  51.5 ) 

                GPU# 1    : 0.0   


Allocated CPUs            : 12   
  CPUs with usage <25%    : 11   
  CPUs with usage <50%    : 1    
  CPUs with usage >50%    : 0    


Allocated GPUs            : 1    
  GPUs with usage <25%    : 1    
  GPUs with usage <50%    : 0    
  GPUs with usage >50%    : 0    

Memory used (RAM)         : 37.3%  [18757MB of 50332MB]

--------------------------------------------

