
Name of the cluster on which the job is executing:
	 spartan
Number of CPUs on the allocated node: 
	 6
Number of CPUs requested per task: 
	 6
Numer of GPUs requested: 
	 
Requested GPU count per allocated node: 
	 
Requested GPU count per allocated task:
	  
The ID of the job allocation:
	  53748013
Count of processors available to the job on this node:
	  6
Name of the job:
	  tst.slurm
List of nodes allocated to the job:
	  spartan-gpgpu091
Total number of nodes in the job’s resource allocation:
	  1
Name of the partition in which the job is running:
	  deeplearn
Minimum memory required per allocated CPU:
	  4000
Requested memory per allocated GPU:
	  
Total amount of memory per node that the job needs:
	  
List of nodes allocated to the job:
	  spartan-gpgpu091
Total number of CPUs allocated:
	  1
Maximum number of MPI tasks (that’s processes): 
	 1
Number of tasks requested per core: 
	 
Number of tasks requested per GPU: 
	 
Number of tasks requested per node:
	  1
The scheduling priority (nice value) at the time of job submission. This value is propagated to the spawned processes: 
	 0
The MPI rank (or relative process ID) of the current process: 
	 0
The directory from which SBATCH was invoked: 
	 /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey
The Hostname of the computer from which SBATCH was invoked: 
	 spartan-login1.hpc.unimelb.edu.au
The process ID of the corresponding task: 
	 186605



 LOADING MODULES: 




 PYTHON SCRIPT OUTPUT: 

2023-11-24 01:36:27,558	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2023-11-24 01:36:29,195	INFO worker.py:1673 -- Started a local Ray instance.
2023-11-24 01:36:31,173	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2023-11-24 01:36:31,174	INFO tune.py:595 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
[36m(pid=188144)[0m 2023-11-24 01:36:33,911	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2023-11-24 01:36:34,191	INFO wandb.py:307 -- Already logged into W&B.
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id fye3a144.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m `UnifiedLogger` will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   return UnifiedLogger(config, logdir, loggers=None)
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 02:32:51,235	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ██████████▇█▇▇▇▅▇▅▄▃▅▄▅▂▅▅▄▂▂▃▄▂▂▃▂▁▂▁▂▂
wandb:   episode_reward_mean ▁▁▂▁▂▃▂▃▄▄▄▅▆▅▆▆▆▇▇▇▇▇▇█▇▇▇█████████████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 90.75
wandb:   episode_reward_mean 4.76
wandb:        episodes_total 9996
wandb: num_env_steps_sampled 959141
wandb: num_env_steps_trained 0
wandb:          time_total_s 3200.83243
wandb:    training_iteration 4428
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_013634-fye3a144
wandb: Find logs at: ./wandb/offline-run-20231124_013634-fye3a144/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id fye3a144.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m `UnifiedLogger` will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   return UnifiedLogger(config, logdir, loggers=None)
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=188144)[0m /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
[36m(train_algo pid=188144)[0m The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
[36m(train_algo pid=188144)[0m   self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 03:07:29,833	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ██████████▇█▇▆▇▆▇▇▅▆▆▄▅▃▂▃▃▄▃▂▂▂▂▁▂▁▃▁▂▁
wandb:   episode_reward_mean ▁▁▂▂▂▃▃▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇███▇▇████████▇███
wandb:        episodes_total ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 69.2
wandb:   episode_reward_mean 5.62
wandb:        episodes_total 9994
wandb: num_env_steps_sampled 835736
wandb: num_env_steps_trained 0
wandb:          time_total_s 1958.66432
wandb:    training_iteration 3699
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_023251-fye3a144
wandb: Find logs at: ./wandb/offline-run-20231124_023251-fye3a144/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id s5qvonti.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 04:03:20,877	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████████▇▇▆▆▆▇▇▅▅▅▆▅▃▆▂▂▃▅▃▃▃▃▃▅▂▄▁▂▂
wandb:   episode_reward_mean ▁▁▂▂▂▃▃▃▄▄▅▆▆▆▆▆▆▆▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 91.18
wandb:   episode_reward_mean 4.8
wandb:        episodes_total 9993
wandb: num_env_steps_sampled 959775
wandb: num_env_steps_trained 0
wandb:          time_total_s 3170.37194
wandb:    training_iteration 4425
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_030729-s5qvonti
wandb: Find logs at: ./wandb/offline-run-20231124_030729-s5qvonti/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id h51p0dbf.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 04:37:38,477	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████▇█▇▇▇▇▇▇▇▇▆▆▅▅▄▄▄▃▃▂▁▃▂▂▂▂▂▂▁▁▂▂▂
wandb:   episode_reward_mean ▁▁▂▂▂▃▄▄▄▅▅▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇██████████████
wandb:        episodes_total ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 70.8
wandb:   episode_reward_mean 5.775
wandb:        episodes_total 9997
wandb: num_env_steps_sampled 825474
wandb: num_env_steps_trained 0
wandb:          time_total_s 1937.91452
wandb:    training_iteration 3654
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_040320-h51p0dbf
wandb: Find logs at: ./wandb/offline-run-20231124_040320-h51p0dbf/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id rwppac80.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 05:33:53,164	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████████▇█▇▇▇▇▇▇▅▄▅▆▅▅▅▄▅▃▅▄▃▃▄▅▂▃▄▃▁
wandb:   episode_reward_mean ▁▁▁▂▂▂▂▂▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇██▇▇▇
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 88.53
wandb:   episode_reward_mean 4.96
wandb:        episodes_total 9995
wandb: num_env_steps_sampled 965560
wandb: num_env_steps_trained 0
wandb:          time_total_s 3189.77111
wandb:    training_iteration 4491
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_043738-rwppac80
wandb: Find logs at: ./wandb/offline-run-20231124_043738-rwppac80/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id xo5nxrif.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 06:10:14,832	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean ██████████▇▇▇▆▇▆▇▇▆▇▅▇▆▆▆▆▅▅▃▄▂▃▃▂▂▃▁▁▁▁
wandb:   episode_reward_mean ▁▁▂▂▂▃▄▄▄▄▅▄▅▅▆▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇██▇▇█████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇██
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 71.08
wandb:   episode_reward_mean 6.41
wandb:        episodes_total 9996
wandb: num_env_steps_sampled 874229
wandb: num_env_steps_trained 0
wandb:          time_total_s 2052.3427
wandb:    training_iteration 3894
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_053353-xo5nxrif
wandb: Find logs at: ./wandb/offline-run-20231124_053353-xo5nxrif/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id qu191cdl.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 07:04:11,356	INFO wandb.py:307 -- Already logged into W&B.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:      episode_len_mean █████████▇█▇██▇▇▇▇▇▅▆▅▆▅▅▅▄▄▄▃▃▃▃▃▂▁▁▂▁▂
wandb:   episode_reward_mean ▁▁▁▂▂▂▂▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇██▇██▇████
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 82.38
wandb:   episode_reward_mean 5.41
wandb:        episodes_total 9997
wandb: num_env_steps_sampled 925460
wandb: num_env_steps_trained 0
wandb:          time_total_s 3066.12441
wandb:    training_iteration 4182
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_061014-qu191cdl
wandb: Find logs at: ./wandb/offline-run-20231124_061014-qu191cdl/logs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id aiuvtg2b.
wandb: Tracking run with wandb version 0.16.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[36m(train_algo pid=188144)[0m Install gputil for GPU system monitoring.
2023-11-24 07:11:47,119	WARNING tune_controller.py:746 -- Trial controller checkpointing failed: [Errno 122] Disk quota exceeded
╭───────────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_algo_2023-11-24_01-36-27   │
├───────────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator            │
│ Scheduler                        FIFOScheduler                    │
│ Number of trials                 30                               │
╰───────────────────────────────────────────────────────────────────╯

View detailed results here: /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/experiments/train_algo_2023-11-24_01-36-27
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/dalmiapriyam/ray_results/train_algo_2023-11-24_01-36-27`

Trial status: 1 PENDING
Current time: 2023-11-24 01:36:31. Total running time: 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
╭───────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type   │
├───────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   PENDING    independent        type_1                 │
╰───────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00000 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00000 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 1 RUNNING
Current time: 2023-11-24 01:37:01. Total running time: 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7faf228c0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                       36            24.1632   7272    1.73611                      5                      0                  101                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:37:31. Total running time: 1min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9563f40>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                       78            52.5522   15756       1.77                      4                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:38:01. Total running time: 1min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9563d90>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      120            80.8261   24240       1.76                      4                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:38:31. Total running time: 2min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9563b50>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      162            109.181   32724       1.67                      4                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:39:01. Total running time: 2min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9561c60>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      204             137.48   41208       1.76                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:39:31. Total running time: 3min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7faf7e050>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      246            165.763   49692       1.78                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:40:01. Total running time: 3min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9054040>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      288            194.112   58176       1.76                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:40:31. Total running time: 4min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90548b0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      330            222.356   66660       1.95                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:41:01. Total running time: 4min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.84 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f95632e0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      372             250.98   75229       1.79                      6                      0               100.84                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:41:31. Total running time: 5min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f95632e0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      414            279.239   83713       1.79                      5                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:42:01. Total running time: 5min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7faf7e950>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      456            307.525   92197       1.94                      4                      0                  101                      2 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:42:31. Total running time: 6min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90c83a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      498            336.023   100681       1.97                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:43:01. Total running time: 6min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.88 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f95632e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      539            363.873   109052       2.16                      6                      0               100.88                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:43:31. Total running time: 7min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9057760>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      581            392.717   117718       2.29                      6                      0                100.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:44:02. Total running time: 7min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.37 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb130>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      622            420.841   126139       2.15                      6                      0               100.37                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:44:32. Total running time: 8min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f2ad40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      664            449.321   134710       2.12                      6                      0                100.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:45:02. Total running time: 8min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90c9870>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      706            477.722   143194       2.21                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:45:32. Total running time: 9min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.57 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f2bac0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      748            506.172   151736       2.36                      6                      0               100.57                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:46:02. Total running time: 9min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cbd00>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      790            534.425   160220       2.35                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:46:32. Total running time: 10min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f95632e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      832            562.912   168704        2.5                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:47:02. Total running time: 10min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7faf7e170>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      873            590.781   177080       2.39                      6                      0               100.93                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:47:32. Total running time: 11min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.62 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f2a5f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      915            619.281   185634       3.04                      6                      0               100.62                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:48:02. Total running time: 11min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f95632e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      957            647.692   194118       2.56                      5                      0                  101                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:48:32. Total running time: 12min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.74 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb6d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                      999            676.177   202677       2.98                      6                      0               100.74                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:49:02. Total running time: 12min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.65 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f59630>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1040            703.973   211025       2.97                      6                      0               100.65                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:49:32. Total running time: 13min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.21 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9055bd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1081            732.642   219632       3.08                      6                      0               100.21                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:50:02. Total running time: 13min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.67 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f95616c0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1122             760.71   228044       3.02                      6                      0                99.67                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:50:32. Total running time: 14min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.09 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9b6ac20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1163            789.521   236656       3.17                      6                      0                99.09                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:51:02. Total running time: 14min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.29 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb2e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1204            817.839   245164       3.29                      6                      0                99.29                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:51:32. Total running time: 15min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.68 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f2a950>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1246            846.438   253740       3.31                      6                      1               100.68                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:52:02. Total running time: 15min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.61 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb2e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1287            874.708   262185       3.19                      6                      0               100.61                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:52:32. Total running time: 16min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=98.85 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f9055bd0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1327            902.867   270656       3.66                      6                      1                98.85                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:53:02. Total running time: 16min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.2 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb2e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1367            931.415   279198       3.69                      6                      0                 99.2                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:53:32. Total running time: 17min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.09 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb2e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1408            959.679   287695        3.7                      6                      0                99.09                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:54:03. Total running time: 17min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.09 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f58700>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1450            988.668   296405       3.72                      6                      1                99.09                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:54:33. Total running time: 18min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.54 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f90cb2e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1491            1016.81   304844       3.57                      6                      0                99.54                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:55:03. Total running time: 18min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=100.46 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0121cf0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1533            1045.21   313375       3.35                      6                      0               100.46                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:55:33. Total running time: 19min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=99.34 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8fcb5b0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1573            1073.75   321895       3.78                      6                      0                99.34                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:56:03. Total running time: 19min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.76 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f9c9d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1611            1101.98   330358       3.73                      6                      1                97.76                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:56:33. Total running time: 20min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.07 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0122440>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1651            1131.06   339065       4.15                      6                      0                97.07                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:57:03. Total running time: 20min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=98.59 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0123520>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1691            1159.21   347504       3.93                      6                      0                98.59                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:57:33. Total running time: 21min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.17 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0122f80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1731             1187.9   356111       4.02                      6                      1                96.17                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:58:03. Total running time: 21min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.91 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0180670>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1772            1216.54   364686       4.12                      6                      1                97.91                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:58:33. Total running time: 22min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=98.85 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f5be20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1812            1245.09   373258       3.92                      6                      0                98.85                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:59:03. Total running time: 22min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.1 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f5be20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1851            1273.29   381706       3.96                      6                      2                 97.1                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 01:59:33. Total running time: 23min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.88 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f9f370>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1890            1301.41   390137       3.92                      6                      0                97.88                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:00:03. Total running time: 23min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0182680>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1930            1329.88   398670       4.15                      6                      0                 96.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:00:33. Total running time: 24min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.64 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0183be0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     1969            1358.21   407121       4.08                      6                      0                97.64                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:01:03. Total running time: 24min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.08 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0183eb0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2008            1386.85   415721       4.26                      6                      1                94.08                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:01:33. Total running time: 25min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.05 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0193760>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2047            1415.68   424358       4.15                      6                      1                96.05                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:02:03. Total running time: 25min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.49 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f9ce50>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2085            1444.26   432897       4.23                      6                      1                95.49                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:02:33. Total running time: 26min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.54 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0191360>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2125             1472.9   441479        4.2                      6                      0                96.54                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:03:03. Total running time: 26min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.94 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f9e290>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2162            1500.95   449864        4.2                      6                      0                92.94                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:03:33. Total running time: 27min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.18 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f9c280>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2199            1529.26   458371       4.47                      6                      2                93.18                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:04:03. Total running time: 27min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.24 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0191090>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2239            1558.07   466984       4.33                      6                      1                97.24                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:04:33. Total running time: 28min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=97.19 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f7910>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2278            1586.61   475537       4.42                      6                      2                97.19                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:05:03. Total running time: 28min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.82 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8fcb880>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2316             1615.2   484143       4.33                      6                      1                93.82                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:05:34. Total running time: 29min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.73 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f4d30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2355            1644.16   492775       4.42                      6                      1                92.73                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:06:04. Total running time: 29min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.89 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0123640>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2392            1672.55   501294       4.37                      6                      1                92.89                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:06:34. Total running time: 30min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.7 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e7f8f5be20>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2429            1701.25   509872       4.48                      6                      1                 95.7                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:07:04. Total running time: 30min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=98.75 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f5d80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2469            1729.59   518394       4.11                      6                      0                98.75                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:07:34. Total running time: 31min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.19 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895267a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2508            1758.75   527143       4.57                      6                      1                94.19                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:08:04. Total running time: 31min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.01 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889526290>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2548            1787.16   535629       4.27                      6                      1                96.01                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:08:34. Total running time: 32min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.48 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889525240>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2586            1815.55   544170       4.56                      6                      1                92.48                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:09:04. Total running time: 32min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.18 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0191fc0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2625            1844.12   552730       4.27                      6                      2                96.18                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:09:34. Total running time: 33min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.5 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f4d30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2663            1872.36   561203       4.47                      6                      1                 95.5                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:10:04. Total running time: 33min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.04 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0191fc0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2701            1900.76   569737       4.38                      6                      1                95.04                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:10:34. Total running time: 34min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0191fc0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2740            1930.16   578509       4.22                      6                      1                 95.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:11:04. Total running time: 34min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=89.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889586cb0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2777            1958.89   587122       4.42                      6                      0                89.93                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:11:34. Total running time: 35min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.43 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b0191fc0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2815            1987.09   595546       4.34                      6                      0                94.43                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:12:04. Total running time: 35min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.23 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889526cb0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2854            2015.54   604081       4.32                      6                      1                96.23                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:12:34. Total running time: 36min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.28 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889587760>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2892            2044.26   612677       4.33                      6                      1                93.28                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:13:04. Total running time: 36min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.51 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889587760>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2930            2072.66   621171       4.35                      6                      2                95.51                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:13:35. Total running time: 37min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.17 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f7a30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     2970            2101.34   629782       4.52                      6                      2                92.17                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:14:05. Total running time: 37min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=91.09 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895b77f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3009            2130.15   638386        4.5                      6                      1                91.09                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:14:35. Total running time: 38min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.37 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889526e60>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3047            2158.57   646914       4.42                      6                      2                94.37                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:15:05. Total running time: 38min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=91.59 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895f3a30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3085            2187.16   655486        4.6                      6                      1                91.59                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:15:35. Total running time: 39min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.06 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895f29e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3122             2215.4   663933       4.59                      6                      2                93.06                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:16:05. Total running time: 39min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.34 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895f2ef0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3161            2244.32   672608        4.5                      6                      1                93.34                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:16:35. Total running time: 40min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f7a30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3200            2273.04   681181       4.49                      6                      2                 92.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:17:05. Total running time: 40min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.22 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895265f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3236             2301.4   689714       4.63                      6                      1                92.22                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:17:35. Total running time: 41min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.91 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8b01f7a30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3273            2330.14   698334       4.62                      6                      1                93.91                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:18:05. Total running time: 41min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.59 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88943ab00>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3311            2358.86   706899       4.45                      6                      0                94.59                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:18:35. Total running time: 42min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=96.8 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889525ea0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3349            2387.11   715379       4.34                      6                      0                 96.8                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:19:05. Total running time: 42min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.86 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889586d40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3388            2415.69   723919       4.46                      6                      1                94.86                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:19:35. Total running time: 43min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=95.94 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889586d40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3426            2444.73   732639       4.61                      6                      1                95.94                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:20:05. Total running time: 43min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.95 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944a5f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3466            2473.18   741170       4.31                      6                      2                93.95                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:20:35. Total running time: 44min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.03 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944beb0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3504            2501.93   749767       4.59                      6                      2                92.03                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:21:05. Total running time: 44min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.24 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889449ea0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3541            2530.64   758385        4.6                      6                      2                92.24                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:21:35. Total running time: 45min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.44 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8895265f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3580            2558.78   766798       4.43                      6                      1                93.44                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:22:05. Total running time: 45min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.85 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88943a440>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3618            2588.02   775580        4.5                      6                      1                90.85                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:22:36. Total running time: 46min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=89.85 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889586d40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3655            2616.19   784060       4.74                      6                      1                89.85                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:23:06. Total running time: 46min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.58 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88943a5f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3694            2644.81   792633       4.48                      6                      2                94.58                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:23:36. Total running time: 47min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=93.77 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8894a6f80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3733            2673.38   801202       4.64                      6                      2                93.77                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:24:06. Total running time: 47min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.4 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8894a71c0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3770            2701.94   809735       4.61                      6                      0                 92.4                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:24:36. Total running time: 48min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.02 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944a7a0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3807            2730.77   818370       4.63                      6                      2                92.02                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:25:06. Total running time: 48min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.36 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944a9e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3846            2759.45   826973       4.51                      6                      1                92.36                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:25:36. Total running time: 49min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=89.39 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889316f80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3883            2788.08   835525       4.56                      6                      1                89.39                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:26:06. Total running time: 49min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.97 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8894a7370>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3921            2816.87   844207       4.39                      6                      1                92.97                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:26:36. Total running time: 50min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.5 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889317f40>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3958            2844.96   852596       4.76                      6                      1                 90.5                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:27:06. Total running time: 50min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=88.39 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889316680>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     3996               2874   861296       4.78                      6                      1                88.39                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:27:36. Total running time: 51min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.47 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8893681f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4035            2902.54   869863       4.62                      6                      1                92.47                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:28:06. Total running time: 51min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.18 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8893692d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4071            2930.93   878350       4.64                      6                      1                92.18                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:28:36. Total running time: 52min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=91.38 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8893692d0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4109            2959.84   887002       4.59                      6                      1                91.38                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:29:06. Total running time: 52min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.82 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889317490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4147            2988.55   895581       4.74                      6                      2                90.82                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:29:36. Total running time: 53min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.51 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889314af0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4184             3016.8   904054       4.51                      6                      1                90.51                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:30:06. Total running time: 53min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.2 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889317490>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4222            3045.39   912611       4.52                      6                      1                 92.2                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:30:36. Total running time: 54min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.17 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4260            3073.92   921137       4.46                      6                      1                92.17                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:31:06. Total running time: 54min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=91.97 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88936af80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4298            3102.65   929766       4.54                      6                      1                91.97                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:31:36. Total running time: 55min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=92.01 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88943a5f0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4336            3131.37   938340       4.59                      6                      1                92.01                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:32:06. Total running time: 55min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=94.99 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88934caf0>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4376            3160.17   946981       4.45                      6                      1                94.99                      2 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2023-11-24 02:32:37. Total running time: 56min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=91.37 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8893e8d30>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00000   RUNNING    independent        type_1                     4412            3188.38   955444       4.78                      6                      2                91.37                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00000 completed after 4429 iterations at 2023-11-24 02:32:51. Total running time: 56min 19s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00000 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                        9999 │
│ time_this_iter_s                                                                   0.82033 │
│ time_total_s                                                                    3201.65276 │
│ timesteps_total                                                                     959383 │
│ training_iteration                                                                    4429 │
│ agent_timesteps_total                                                              1918766 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                        0.0034297704696655273 │
│ connector_metrics/StateBufferConnector_ms                            0.0026186704635620117 │
│ connector_metrics/ViewRequirementAgentConnector_ms                     0.15637600421905518 │
│ counters/num_agent_steps_sampled                                                   1918766 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      959383 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               0 │
│ custom_metrics/assists_mean                                                            0.0 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             4.77 │
│ custom_metrics/kills_min                                                                 2 │
│ custom_metrics/predator_0_assists_max                                                    0 │
│ custom_metrics/predator_0_assists_mean                                                 0.0 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      6 │
│ custom_metrics/predator_0_kills_mean                                                   2.5 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    0 │
│ custom_metrics/predator_1_assists_mean                                                 0.0 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      5 │
│ custom_metrics/predator_1_kills_mean                                                  2.27 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     90.93 │
│ episode_reward_max                                                                      6. │
│ episode_reward_mean                                                                   4.77 │
│ episode_reward_min                                                                      2. │
│ episodes_this_iter                                                                       3 │
│ hist_stats/episode_lengths                                            ... 79, 75, 101, 66] │
│ hist_stats/episode_reward                                             ...0, 6.0, 5.0, 6.0] │
│ hist_stats/policy_predator_0_reward                                   ...0, 2.0, 2.0, 1.0] │
│ hist_stats/policy_predator_1_reward                                   ...0, 4.0, 3.0, 5.0] │
│ info/learner/__all__/num_agent_steps_trained                                         256.0 │
│ info/learner/__all__/num_env_steps_trained                                           242.0 │
│ info/learner/__all__/total_loss                                         0.9397138208150864 │
│ info/learner/predator_0/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_0/curr_lr                                                     0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_0/entropy                                         1.2925897240638733 │
│ info/learner/predator_0/mean_kl_loss                                 1.058227165984249e-05 │
│ info/learner/predator_0/policy_loss                                  -0.007264479249715805 │
│ info/learner/predator_0/total_loss                                      0.9397138208150864 │
│ info/learner/predator_0/vf_explained_var                               0.22586044669151306 │
│ info/learner/predator_0/vf_loss                                         0.2574439443647861 │
│ info/learner/predator_0/vf_loss_unclipped                               0.2574439443647861 │
│ info/learner/predator_1/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_1/curr_lr                                                     0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_1/entropy                                         1.2166010975837707 │
│ info/learner/predator_1/mean_kl_loss                                 2.427480417281913e-05 │
│ info/learner/predator_1/policy_loss                                  -0.024482143670320512 │
│ info/learner/predator_1/total_loss                                      0.6895343571901321 │
│ info/learner/predator_1/vf_explained_var                               0.15390580296516418 │
│ info/learner/predator_1/vf_loss                                         0.7140165090560913 │
│ info/learner/predator_1/vf_loss_unclipped                                0.725910484790802 │
│ info/num_agent_steps_sampled                                                       1918766 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          959383 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1918766 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               959383 │
│ num_env_steps_sampled_this_iter                                                        242 │
│ num_env_steps_sampled_throughput_per_sec                                         296.36315 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                  3.5 │
│ perf/ram_util_percent                                                                 24.2 │
│ policy_reward_max/predator_0                                                           6.0 │
│ policy_reward_max/predator_1                                                           5.0 │
│ policy_reward_mean/predator_0                                                          2.5 │
│ policy_reward_mean/predator_1                                                         2.27 │
│ policy_reward_min/predator_0                                                           0.0 │
│ policy_reward_min/predator_1                                                           0.0 │
│ sampler_perf/mean_action_processing_ms                                 0.14548150673341373 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.10880214560589466 │
│ sampler_perf/mean_inference_ms                                           2.196462797814797 │
│ sampler_perf/mean_raw_obs_processing_ms                                  0.575290016554262 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms        0.0034297704696655273 │
│ sampler_results/connector_metrics/StateBufferConnector_ms            0.0026186704635620117 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms     0.15637600421905518 │
│ sampler_results/custom_metrics/assists_max                                               0 │
│ sampler_results/custom_metrics/assists_mean                                            0.0 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             4.77 │
│ sampler_results/custom_metrics/kills_min                                                 2 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    0 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                 0.0 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.5 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    0 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                 0.0 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      5 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                  2.27 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     90.93 │
│ sampler_results/episode_reward_max                                                     6.0 │
│ sampler_results/episode_reward_mean                                                   4.77 │
│ sampler_results/episode_reward_min                                                     2.0 │
│ sampler_results/episodes_this_iter                                                       3 │
│ sampler_results/hist_stats/episode_lengths                            ... 79, 75, 101, 66] │
│ sampler_results/hist_stats/episode_reward                             ...0, 6.0, 5.0, 6.0] │
│ sampler_results/hist_stats/policy_predator_0_reward                   ...0, 2.0, 2.0, 1.0] │
│ sampler_results/hist_stats/policy_predator_1_reward                   ...0, 4.0, 3.0, 5.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/predator_0                                           6.0 │
│ sampler_results/policy_reward_max/predator_1                                           5.0 │
│ sampler_results/policy_reward_mean/predator_0                                          2.5 │
│ sampler_results/policy_reward_mean/predator_1                                         2.27 │
│ sampler_results/policy_reward_min/predator_0                                           0.0 │
│ sampler_results/policy_reward_min/predator_1                                           0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                 0.14548150673341373 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.10880214560589466 │
│ sampler_results/sampler_perf/mean_inference_ms                           2.196462797814797 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                  0.575290016554262 │
│ timers/sample_time_ms                                                              772.168 │
│ timers/synch_weights_time_ms                                                         0.906 │
│ timers/training_iteration_time_ms                                                  842.383 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00001 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00001 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:33:07. Total running time: 56min 35s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                       27             12.825     5454    1.51852                      4                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383    4.77                         6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:33:37. Total running time: 57min 5s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                       85            40.6366    17170       1.52                      4                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:34:07. Total running time: 57min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      144            68.8367    29088       1.85                      4                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:34:37. Total running time: 58min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      202            96.7382    40804       1.91                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:35:07. Total running time: 58min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      261            124.991    52722       1.98                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:35:37. Total running time: 59min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      319            152.879    64438       1.96                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:36:07. Total running time: 59min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      378            181.022    76356       2.33                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:36:37. Total running time: 1hr 0min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      436            208.963    88150       2.43                      6                      0               100.77                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:37:07. Total running time: 1hr 0min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      496            237.413   100270       2.55                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:37:37. Total running time: 1hr 1min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      555            265.303   112187       3.03                      6                      0               100.99                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:38:07. Total running time: 1hr 1min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      613            293.214   124087       3.08                      6                      0               100.24                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:38:37. Total running time: 1hr 2min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      672            321.623   136247       3.34                      6                      0               100.54                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:39:07. Total running time: 1hr 2min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      729             349.72   148291       3.42                      6                      0                99.03                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:39:37. Total running time: 1hr 3min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      787            378.014   160375       3.75                      6                      0                99.8                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:40:07. Total running time: 1hr 3min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      844            406.257   172454       3.82                      6                      1                98.29                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:40:37. Total running time: 1hr 4min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      900            434.453   184517       3.78                      6                      0                97.88                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:41:07. Total running time: 1hr 4min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                      957            462.618   196581       4.02                      6                      0                96.54                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:41:37. Total running time: 1hr 5min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1013            490.882   208677       4.19                      6                      1                96.74                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:42:07. Total running time: 1hr 5min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1067            518.891   220602       3.85                      6                      0                97.32                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:42:37. Total running time: 1hr 6min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1123             547.36   232804       3.94                      6                      1                97.27                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:43:08. Total running time: 1hr 6min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1178            575.486   244865       4.21                      6                      0                96                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:43:38. Total running time: 1hr 7min 6s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1233            603.576   256842       4.43                      6                      1                94.81                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:44:08. Total running time: 1hr 7min 36s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1289            632.162   269102       4.31                      6                      1                95.16                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:44:38. Total running time: 1hr 8min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1343            660.075   281031       4.41                      6                      0                95.74                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:45:08. Total running time: 1hr 8min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1396            688.534   293245       4.46                      6                      0                93.9                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:45:38. Total running time: 1hr 9min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1450            717.177   305525       4.4                       6                      1                94.95                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:46:08. Total running time: 1hr 9min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1504            745.152   317458       4.46                      6                      0                94.45                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:46:38. Total running time: 1hr 10min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1558            773.954   329775       4.45                      6                      1                95.73                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:47:08. Total running time: 1hr 10min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1612            802.191   341874       4.49                      6                      2                93.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:47:38. Total running time: 1hr 11min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1667            830.651   354083       4.48                      6                      2                92.59                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:48:08. Total running time: 1hr 11min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=89.35 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889225bd0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1720            859.222   366266       4.81                      6                      2                89.35                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:48:38. Total running time: 1hr 12min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1775             887.43   378365       4.31                      6                      0                94.61                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:49:08. Total running time: 1hr 12min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00000 with episode_len_mean=90.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88944b2e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1828            915.558   390441       4.37                      6                      1                92.13                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:49:38. Total running time: 1hr 13min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=87.63 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d42b90>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1879            944.406   402790       5.16                      6                      2                87.63                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:50:08. Total running time: 1hr 13min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=86.39 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889226320>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1930             972.73   414917       5.2                       6                      1                86.39                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:50:38. Total running time: 1hr 14min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=81.38 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d42ef0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     1982            1001.25   427079       5.41                      6                      3                81.38                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:51:09. Total running time: 1hr 14min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=82.86 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8892a64d0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2032            1029.48   439195       5.37                      6                      2                82.86                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:51:39. Total running time: 1hr 15min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=76.72 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8892257e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2082            1057.98   451398       5.55                      6                      3                76.72                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:52:09. Total running time: 1hr 15min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=78.53 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8892a64d0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2132            1086.92   463712       5.46                      6                      3                78.53                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:52:39. Total running time: 1hr 16min 7s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=79.52 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8892a64d0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2183            1115.28   475833       5.46                      6                      2                79.52                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:53:09. Total running time: 1hr 16min 37s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=72.12 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d43f40>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2233            1143.76   487970       5.74                      6                      3                72.12                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:53:39. Total running time: 1hr 17min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=75.46 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88924f880>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2284            1171.99   500031       5.53                      6                      3                75.46                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:54:09. Total running time: 1hr 17min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=78.59 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d6e9e0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2336            1200.75   512319       5.56                      6                      3                78.59                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:54:39. Total running time: 1hr 18min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=75.37 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d6d990>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2386            1229.26   524460       5.63                      6                      3                75.37                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:55:09. Total running time: 1hr 18min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=76.18 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e930140c10>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2437            1257.92   536705       5.58                      6                      3                76.18                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:55:39. Total running time: 1hr 19min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=72.97 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d6ea70>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2487            1285.98   548682       5.69                      6                      3                72.97                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:56:09. Total running time: 1hr 19min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=78.33 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c03910>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2539            1314.93   561028       5.51                      6                      3                78.33                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:56:39. Total running time: 1hr 20min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=76.9 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c01000>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2589            1343.25   573085       5.62                      6                      3                76.9                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:57:09. Total running time: 1hr 20min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=76.57 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14e930140af0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2640            1371.95   585377       5.59                      6                      4                76.57                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:57:39. Total running time: 1hr 21min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=78.05 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888db36d0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2691            1399.94   597370       5.49                      6                      2                78.05                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:58:09. Total running time: 1hr 21min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=73.07 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c03520>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2741            1428.33   609461       5.59                      6                      3                73.07                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:58:39. Total running time: 1hr 22min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=67.44 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888d6feb0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2793            1457.07   621736       5.71                      6                      3                67.44                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:59:09. Total running time: 1hr 22min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=73.15 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c03c70>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2845            1485.22   633727       5.66                      6                      4                73.15                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 02:59:39. Total running time: 1hr 23min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=77.72 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d889226050>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2895            1514.05   646057       5.44                      6                      3                77.72                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:00:09. Total running time: 1hr 23min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=71.76 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c004c0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2947            1542.5    658218       5.67                      6                      2                71.76                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:00:39. Total running time: 1hr 24min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=71.68 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c25870>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     2998            1570.96   670329       5.69                      6                      4                71.68                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:01:09. Total running time: 1hr 24min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=67.88 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c03640>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3050            1599.77   682647       5.77                      6                      3                67.88                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:01:40. Total running time: 1hr 25min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=71.0 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a200>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3101            1627.81   694623       5.64                      6                      3                71                         4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:02:10. Total running time: 1hr 25min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=73.11 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c27400>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3153            1656.44   706801       5.67                      6                      3                73.11                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:02:40. Total running time: 1hr 26min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=73.3 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a200>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3204            1684.64   718854       5.67                      6                      4                73.3                       4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:03:10. Total running time: 1hr 26min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=69.49 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c69ab0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3256            1713.46   731140       5.69                      6                      3                69.49                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:03:40. Total running time: 1hr 27min 8s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.55 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6add0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3308            1741.87   743272       5.83                      6                      5                68.55                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:04:10. Total running time: 1hr 27min 38s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=74.74 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c27ac0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3360            1770.37   755454       5.55                      6                      3                74.74                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:04:40. Total running time: 1hr 28min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=74.05 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c94700>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3412            1798.72   767551       5.48                      6                      3                74.05                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:05:10. Total running time: 1hr 28min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=66.67 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c95b40>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3464            1827.16   779681       5.73                      6                      4                66.67                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:05:40. Total running time: 1hr 29min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=70.38 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888cd0040>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3515            1855.41   791750       5.67                      6                      4                70.38                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:06:10. Total running time: 1hr 29min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=69.83 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888cd2200>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3566            1884.26   804010       5.61                      6                      3                69.83                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:06:40. Total running time: 1hr 30min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=71.14 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c00ee0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3617            1912.37   815973       5.6                       6                      3                71.14                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:07:10. Total running time: 1hr 30min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=71.79 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6add0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00001   RUNNING      shared             type_1                     3668            1941.27   828333       5.59                      6                      3                71.79                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00001 completed after 3700 iterations at 2023-11-24 03:07:29. Total running time: 1hr 30min 58s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00001 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                        9998 │
│ time_this_iter_s                                                                   0.51491 │
│ time_total_s                                                                    1959.17923 │
│ timesteps_total                                                                     835955 │
│ training_iteration                                                                    3700 │
│ agent_timesteps_total                                                              1671910 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                        0.0047223567962646484 │
│ connector_metrics/StateBufferConnector_ms                            0.0036280155181884766 │
│ connector_metrics/ViewRequirementAgentConnector_ms                      0.3078196048736572 │
│ counters/num_agent_steps_sampled                                                   1671910 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      835955 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               0 │
│ custom_metrics/assists_mean                                                            0.0 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             5.63 │
│ custom_metrics/kills_min                                                                 3 │
│ custom_metrics/predator_0_assists_max                                                    0 │
│ custom_metrics/predator_0_assists_mean                                                 0.0 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      6 │
│ custom_metrics/predator_0_kills_mean                                                   2.6 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    0 │
│ custom_metrics/predator_1_assists_mean                                                 0.0 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      6 │
│ custom_metrics/predator_1_kills_mean                                                  3.03 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     68.66 │
│ episode_reward_max                                                                      6. │
│ episode_reward_mean                                                                   5.63 │
│ episode_reward_min                                                                      3. │
│ episodes_this_iter                                                                       4 │
│ hist_stats/episode_lengths                                            ..., 68, 53, 57, 41] │
│ hist_stats/episode_reward                                             ...0, 6.0, 6.0, 6.0] │
│ hist_stats/policy_shared_policy_reward                                ...0, 3.0, 3.0, 3.0] │
│ info/learner/__all__/num_agent_steps_trained                                         128.0 │
│ info/learner/__all__/num_env_steps_trained                                           438.0 │
│ info/learner/__all__/total_loss                                         0.5134129884342352 │
│ info/learner/shared_policy/curr_entropy_coeff                                          0.0 │
│ info/learner/shared_policy/curr_kl_coeff                                               0.0 │
│ info/learner/shared_policy/curr_lr                                                  0.0001 │
│ info/learner/shared_policy/default_optimizer_lr                                     0.0001 │
│ info/learner/shared_policy/entropy                                       0.462433656056722 │
│ info/learner/shared_policy/mean_kl_loss                              9.508998330274051e-06 │
│ info/learner/shared_policy/policy_loss                                0.005151518103149202 │
│ info/learner/shared_policy/total_loss                                   0.5134129884342352 │
│ info/learner/shared_policy/vf_explained_var                            0.07228611244095696 │
│ info/learner/shared_policy/vf_loss                                       0.508261458741294 │
│ info/learner/shared_policy/vf_loss_unclipped                             0.508261458741294 │
│ info/num_agent_steps_sampled                                                       1671910 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          835955 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1671910 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               835955 │
│ num_env_steps_sampled_this_iter                                                        219 │
│ num_env_steps_sampled_throughput_per_sec                                         428.26218 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                  4.1 │
│ perf/ram_util_percent                                                                 24.1 │
│ policy_reward_max/shared_policy                                                        6.0 │
│ policy_reward_mean/shared_policy                                                     2.815 │
│ policy_reward_min/shared_policy                                                        0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.1235109031945856 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                           0.1029848175306085 │
│ sampler_perf/mean_inference_ms                                          1.2443088424219964 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5566476485833922 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms        0.0047223567962646484 │
│ sampler_results/connector_metrics/StateBufferConnector_ms            0.0036280155181884766 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms      0.3078196048736572 │
│ sampler_results/custom_metrics/assists_max                                               0 │
│ sampler_results/custom_metrics/assists_mean                                            0.0 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             5.63 │
│ sampler_results/custom_metrics/kills_min                                                 3 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    0 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                 0.0 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.6 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    0 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                 0.0 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                  3.03 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     68.66 │
│ sampler_results/episode_reward_max                                                     6.0 │
│ sampler_results/episode_reward_mean                                                   5.63 │
│ sampler_results/episode_reward_min                                                     3.0 │
│ sampler_results/episodes_this_iter                                                       4 │
│ sampler_results/hist_stats/episode_lengths                            ..., 68, 53, 57, 41] │
│ sampler_results/hist_stats/episode_reward                             ...0, 6.0, 6.0, 6.0] │
│ sampler_results/hist_stats/policy_shared_policy_reward                ...0, 3.0, 3.0, 3.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/shared_policy                                        6.0 │
│ sampler_results/policy_reward_mean/shared_policy                                     2.815 │
│ sampler_results/policy_reward_min/shared_policy                                        0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.1235109031945856 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                           0.1029848175306085 │
│ sampler_results/sampler_perf/mean_inference_ms                          1.2443088424219964 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5566476485833922 │
│ timers/sample_time_ms                                                              447.875 │
│ timers/synch_weights_time_ms                                                         0.513 │
│ timers/training_iteration_time_ms                                                  511.679 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00002 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00002 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_2 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:07:40. Total running time: 1hr 31min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                       12            7.95058     2424    1.60417                      4                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429         3201.65      959383    4.77                         6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700         1959.18      835955    5.63                         6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:08:10. Total running time: 1hr 31min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                       54            35.9378    10908      1.675                    4.5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:08:40. Total running time: 1hr 32min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                       96             64.213    19460      1.945                      6                      0               100.67                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:09:10. Total running time: 1hr 32min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      138            92.2953    27944       1.87                      6                      0               100.67                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:09:40. Total running time: 1hr 33min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      181             121.09    36630       1.79                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:10:10. Total running time: 1hr 33min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      223             149.08    45114       1.83                    4.5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:10:40. Total running time: 1hr 34min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      266            177.824    53800      1.865                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:11:10. Total running time: 1hr 34min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      308            205.784    62284      1.945                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:11:40. Total running time: 1hr 35min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      350            234.058    70842       1.94                      6                      0               100.73                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:12:10. Total running time: 1hr 35min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      392            262.451    79420      2.085                      6                      0               100.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:12:40. Total running time: 1hr 36min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      434            290.526    87904       2.11                      6                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:13:10. Total running time: 1hr 36min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      477            319.181    96590      1.905                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:13:40. Total running time: 1hr 37min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      519            347.088   105074      2.105                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:14:10. Total running time: 1hr 37min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      562            375.821   113760      2.215                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:14:41. Total running time: 1hr 38min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      604            403.924   122283       2.33                      6                      0               100.38                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:15:11. Total running time: 1hr 38min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      646            431.902   130767       2.38                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:15:41. Total running time: 1hr 39min 9s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      689            460.607   139453       2.31                    5.5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:16:11. Total running time: 1hr 39min 39s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      731            488.814   148003      2.515                    6.5                      0               100.65                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:16:41. Total running time: 1hr 40min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      773            516.971   156487      2.695                      6                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:17:11. Total running time: 1hr 40min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      815            545.044   165036      2.755                      6                      0               100.64                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:17:41. Total running time: 1hr 41min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      858             573.65   173722      2.595                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:18:11. Total running time: 1hr 41min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      899             601.67   182175      2.895                      6                      0               100.69                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:18:41. Total running time: 1hr 42min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      942            630.262   190860       2.77                      6                      0               100.82                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:19:11. Total running time: 1hr 42min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                      984            658.368   199344      2.905                      6                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:19:41. Total running time: 1hr 43min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1026            686.909   207984       3.01                      6                      0               100.54                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:20:11. Total running time: 1hr 43min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1068            715.099   216552      3.165                      6                      0               100.83                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:20:41. Total running time: 1hr 44min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1110            743.204   225036       3.34                      6                      1               100.83                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:21:11. Total running time: 1hr 44min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1152             772.26   233845       3.54                    6.5                      0               100.21                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:21:41. Total running time: 1hr 45min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1192            800.509   242378       3.52                      6                      0                99.44                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:22:11. Total running time: 1hr 45min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1233            828.936   251028       3.59                    6.5                      0               100.64                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:22:41. Total running time: 1hr 46min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1273            857.042   259580      3.735                    6.5                      0                98.65                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:23:11. Total running time: 1hr 46min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1314            885.299   268133      3.765                      6                      0                98.25                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:23:41. Total running time: 1hr 47min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1355            913.621   276741       3.68                    6.5                      0                98.63                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:24:11. Total running time: 1hr 47min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1396            942.349   285445       3.79                    6.5                      0                99.16                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:24:41. Total running time: 1hr 48min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1436            970.691   294030      3.865                      7                      0                99.34                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:25:12. Total running time: 1hr 48min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1476            998.924   302598       3.99                    6.5                      1                98.62                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:25:42. Total running time: 1hr 49min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1516            1027.52   311220       3.98                    6.5                      1                97.08                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:26:12. Total running time: 1hr 49min 40s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1557            1055.94   319825       3.7                     6.5                      0                97.43                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:26:42. Total running time: 1hr 50min 10s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1598            1084.34   328403       3.85                    6.5                      1                98.4                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:27:12. Total running time: 1hr 50min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1638            1112.78   337013       4.1                       7                      1                98.22                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:27:42. Total running time: 1hr 51min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1679            1141.46   345720      3.865                      6                      1                99.19                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:28:12. Total running time: 1hr 51min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1719            1169.41   354184      3.975                    6.5                      1                98.78                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:28:42. Total running time: 1hr 52min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1759            1198.02   362885       4.15                    6.5                      1                95.09                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:29:12. Total running time: 1hr 52min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1800            1226.95   371622       4.03                      7                      0                97.7                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:29:42. Total running time: 1hr 53min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1839            1254.73   380069       3.9                       8                      0                98.61                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:30:12. Total running time: 1hr 53min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1880            1283.77   388883      4.105                    6.5                      1                99.21                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:30:42. Total running time: 1hr 54min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1921            1312.38   397522       4.01                      7                      1                99.52                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:31:12. Total running time: 1hr 54min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     1960            1340.74   406123       4.39                      7                      1                98.03                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:31:42. Total running time: 1hr 55min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2001            1369.3    414767       4.26                    6.5                      1                98.31                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:32:12. Total running time: 1hr 55min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2040            1397.55   423360      4.345                      7                    1.5                97.75                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                    2                  90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                    3                  68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:32:42. Total running time: 1hr 56min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2080            1426.43   432132       4.38                    6.5                      1                95.53                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:33:12. Total running time: 1hr 56min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2118            1454.94   440751       4.55                    7.5                      2                96.98                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:33:42. Total running time: 1hr 57min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2158            1483.38   449360       4.43                    7.5                      1                95.77                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:34:12. Total running time: 1hr 57min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2196            1511.84   457942       4.41                    7.5                      1                96.81                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:34:42. Total running time: 1hr 58min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2236            1540.4    466627      4.265                      7                      1                97.96                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:35:12. Total running time: 1hr 58min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2277            1569.24   475391       4.23                    6.5                      0                96.27                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:35:42. Total running time: 1hr 59min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2316            1597.62   483993      4.285                    6.5                      1                94.54                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:36:13. Total running time: 1hr 59min 41s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2354            1625.56   492460       4.34                    6.5                      1                95.88                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:36:43. Total running time: 2hr 0min 11s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2394            1654.33   501136       4.32                    6.5                      0                97.08                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:37:13. Total running time: 2hr 0min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2432            1682.88   509810      4.085                    6.5                      0                96.84                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:37:43. Total running time: 2hr 1min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2471            1711.28   518401      4.405                    6.5                      0                94.88                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:38:13. Total running time: 2hr 1min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2509            1739.56   526944      4.545                    7.5                      0                96.28                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:38:43. Total running time: 2hr 2min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2548            1768.09   535587       4.51                      7                      0                95.04                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:39:13. Total running time: 2hr 2min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2587            1797.04   544307       4.59                    6.5                      1                93.91                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:39:43. Total running time: 2hr 3min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2626            1825.72   552972       4.42                      7                      0                94.36                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:40:13. Total running time: 2hr 3min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2663            1853.7    561447       4.41                      6                      1                95.18                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:40:43. Total running time: 2hr 4min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2703            1882.8    570228       4.31                    6.5                      1                94.66                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:41:13. Total running time: 2hr 4min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2742            1911.08   578815       4.36                    6.5                      1                96.53                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:41:43. Total running time: 2hr 5min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2780            1939.54   587434      4.445                      6                      1                96.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:42:13. Total running time: 2hr 5min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2818            1968.03   596021      4.255                      7                      1                93.95                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:42:43. Total running time: 2hr 6min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2857            1996.6    604654      4.395                      7                      0                93.25                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:43:13. Total running time: 2hr 6min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2896            2025      613209       4.36                    6.5                      1                94.22                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:43:43. Total running time: 2hr 7min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2934            2053.39   621818       4.63                      6                      1                91.14                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:44:14. Total running time: 2hr 7min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     2972            2082.6    630669      4.745                    7.5                      1                93.68                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:44:44. Total running time: 2hr 8min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3010            2110.66   639163      4.755                      7                      1                92.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:45:14. Total running time: 2hr 8min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3047            2139.67   647944       4.57                      7                      1                89.83                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:45:44. Total running time: 2hr 9min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3085            2168.33   656571       4.8                       7                      2                92.02                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:46:14. Total running time: 2hr 9min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3122            2196.95   665252       4.74                      7                      1                94.06                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:46:44. Total running time: 2hr 10min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3159            2225.54   673871      4.545                    7.5                      1                95.24                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:47:14. Total running time: 2hr 10min 42s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3197            2254.15   682534      4.705                    7.5                      2                93.16                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:47:44. Total running time: 2hr 11min 12s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3235            2282.33   691050       4.56                    7.5                      1                94.05                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:48:14. Total running time: 2hr 11min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3274            2311.45   699830       4.46                      7                      0                92.85                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:48:44. Total running time: 2hr 12min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3311            2339.65   708373      4.795                    7.5                      0                92.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:49:14. Total running time: 2hr 12min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3350            2367.88   716928      4.625                    6.5                      0                94.26                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:49:44. Total running time: 2hr 13min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3388            2396.42   725564      4.695                    6.5                      1                93.1                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:50:14. Total running time: 2hr 13min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3425            2424.71   734127      4.705                    6.5                      1                91.69                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:50:44. Total running time: 2hr 14min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3465            2453.82   742910      4.535                    7.5                      2                92.88                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:51:14. Total running time: 2hr 14min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3504            2482.36   751550       4.44                      7                      1                92.96                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:51:44. Total running time: 2hr 15min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3543            2511.21   760267      4.575                      7                      1                90.71                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:52:14. Total running time: 2hr 15min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3580            2539.06   768720       4.49                      7                      1                91.49                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:52:44. Total running time: 2hr 16min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3619            2568.13   777516      4.425                      7                      0                93.78                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:53:14. Total running time: 2hr 16min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3658            2596.28   785995      4.545                    7.5                      0                92.87                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:53:44. Total running time: 2hr 17min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3698            2624.63   794594      4.335                      7                      0                94.61                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:54:14. Total running time: 2hr 17min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3737            2653.15   803207       4.42                      7                      1                95.22                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:54:44. Total running time: 2hr 18min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3775            2681.54   811815      4.565                    6.5                      2                91.95                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:55:14. Total running time: 2hr 18min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3813            2710.83   820683       4.63                      8                      1                92.55                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:55:44. Total running time: 2hr 19min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3852            2739.31   829302       4.61                      8                      2                94.37                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:56:14. Total running time: 2hr 19min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3889            2767.42   837826      4.915                      8                      1                93.81                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:56:45. Total running time: 2hr 20min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3928            2796.1    846488       4.59                      7                      1                92.66                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:57:15. Total running time: 2hr 20min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     3966            2824.44   855082      4.515                      7                      0                88.97                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:57:45. Total running time: 2hr 21min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4005            2853.09   863755       4.5                     6.5                      1                93.41                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:58:15. Total running time: 2hr 21min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4042            2881.7    872387      4.585                      7                      0                91.91                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:58:45. Total running time: 2hr 22min 13s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4081            2910      880972      4.685                    6.5                      0                93.42                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:59:15. Total running time: 2hr 22min 43s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4119            2938.97   889697      4.695                    6.5                      0                89.85                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 03:59:45. Total running time: 2hr 23min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4157            2967.56   898322      5.025                    6.5                      2                88.59                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:00:15. Total running time: 2hr 23min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4195            2995.47   906774       4.77                      7                      1                90.17                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:00:45. Total running time: 2hr 24min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4233            3024.72   915618      4.915                      7                      2                89.45                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:01:15. Total running time: 2hr 24min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4270            3053.32   924279       4.86                    6.5                      1                90.62                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:01:45. Total running time: 2hr 25min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4306            3081.5    932802       4.7                     6.5                      0                87.25                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:02:15. Total running time: 2hr 25min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4346            3110.29   941558       4.61                    6.5                      2                92.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                    6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                    6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:02:45. Total running time: 2hr 26min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4382            3138.86   950196      4.805                    6.5                      1                90.68                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:03:15. Total running time: 2hr 26min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00002   RUNNING      independent        type_2                     4421            3167.31   958847       4.84                      7                      2                91.31                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383       4.77                      6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955       5.63                      6                      3                68.66                      4 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00002 completed after 4427 iterations at 2023-11-24 04:03:20. Total running time: 2hr 26min 49s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00002 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                        9998 │
│ time_this_iter_s                                                                   0.89413 │
│ time_total_s                                                                    3171.93477 │
│ timesteps_total                                                                     960249 │
│ training_iteration                                                                    4427 │
│ agent_timesteps_total                                                              1920498 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                        0.0031201839447021484 │
│ connector_metrics/StateBufferConnector_ms                             0.002572298049926758 │
│ connector_metrics/ViewRequirementAgentConnector_ms                      0.1550121307373047 │
│ counters/num_agent_steps_sampled                                                   1920498 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      960249 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               3 │
│ custom_metrics/assists_mean                                                           0.23 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             4.72 │
│ custom_metrics/kills_min                                                                 2 │
│ custom_metrics/predator_0_assists_max                                                    2 │
│ custom_metrics/predator_0_assists_mean                                                0.09 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      5 │
│ custom_metrics/predator_0_kills_mean                                                   2.2 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    3 │
│ custom_metrics/predator_1_assists_mean                                                0.14 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      6 │
│ custom_metrics/predator_1_kills_mean                                                  2.52 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     90.87 │
│ episode_reward_max                                                                      7. │
│ episode_reward_mean                                                                  4.835 │
│ episode_reward_min                                                                      2. │
│ episodes_this_iter                                                                       3 │
│ hist_stats/episode_lengths                                            ...01, 101, 70, 101] │
│ hist_stats/episode_reward                                             ...0, 5.0, 6.5, 5.0] │
│ hist_stats/policy_predator_0_reward                                   ..., 4.0, 1.75, 1.0] │
│ hist_stats/policy_predator_1_reward                                   ..., 1.0, 4.75, 4.0] │
│ info/learner/__all__/num_agent_steps_trained                                         256.0 │
│ info/learner/__all__/num_env_steps_trained                                           272.0 │
│ info/learner/__all__/total_loss                                         2.3139189698479394 │
│ info/learner/predator_0/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_0/curr_lr                                                     0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_0/entropy                                          1.232020074670965 │
│ info/learner/predator_0/mean_kl_loss                                 4.604095448001999e-05 │
│ info/learner/predator_0/policy_loss                                   -0.03942670673131943 │
│ info/learner/predator_0/total_loss                                      2.3139189698479394 │
│ info/learner/predator_0/vf_explained_var                               0.10093298825350674 │
│ info/learner/predator_0/vf_loss                                         0.7858597338199615 │
│ info/learner/predator_0/vf_loss_unclipped                                0.789870021018115 │
│ info/learner/predator_1/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_1/curr_lr                                                     0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_1/entropy                                         1.2309636961330066 │
│ info/learner/predator_1/mean_kl_loss                                 4.575833646795631e-05 │
│ info/learner/predator_1/policy_loss                                   0.026277016509662975 │
│ info/learner/predator_1/total_loss                                      1.5674859176982532 │
│ info/learner/predator_1/vf_explained_var                              -0.04577649181539362 │
│ info/learner/predator_1/vf_loss                                         1.5412088889967313 │
│ info/learner/predator_1/vf_loss_unclipped                               1.5412088889967313 │
│ info/num_agent_steps_sampled                                                       1920498 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          960249 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1920498 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               960249 │
│ num_env_steps_sampled_this_iter                                                        272 │
│ num_env_steps_sampled_throughput_per_sec                                         305.48267 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                  3.4 │
│ perf/ram_util_percent                                                                 24.1 │
│ policy_reward_max/predator_0                                                           5.0 │
│ policy_reward_max/predator_1                                                           6.0 │
│ policy_reward_mean/predator_0                                                       2.2325 │
│ policy_reward_mean/predator_1                                                       2.6025 │
│ policy_reward_min/predator_0                                                           0.0 │
│ policy_reward_min/predator_1                                                           0.0 │
│ sampler_perf/mean_action_processing_ms                                 0.14339598058553796 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.10812187407393369 │
│ sampler_perf/mean_inference_ms                                          2.1696170097392633 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5725951259293531 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms        0.0031201839447021484 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.002572298049926758 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms      0.1550121307373047 │
│ sampler_results/custom_metrics/assists_max                                               3 │
│ sampler_results/custom_metrics/assists_mean                                           0.23 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             4.72 │
│ sampler_results/custom_metrics/kills_min                                                 2 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    2 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                0.09 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      5 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.2 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    3 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                0.14 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                  2.52 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     90.87 │
│ sampler_results/episode_reward_max                                                     7.0 │
│ sampler_results/episode_reward_mean                                                  4.835 │
│ sampler_results/episode_reward_min                                                     2.0 │
│ sampler_results/episodes_this_iter                                                       3 │
│ sampler_results/hist_stats/episode_lengths                            ...01, 101, 70, 101] │
│ sampler_results/hist_stats/episode_reward                             ...0, 5.0, 6.5, 5.0] │
│ sampler_results/hist_stats/policy_predator_0_reward                   ..., 4.0, 1.75, 1.0] │
│ sampler_results/hist_stats/policy_predator_1_reward                   ..., 1.0, 4.75, 4.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/predator_0                                           5.0 │
│ sampler_results/policy_reward_max/predator_1                                           6.0 │
│ sampler_results/policy_reward_mean/predator_0                                       2.2325 │
│ sampler_results/policy_reward_mean/predator_1                                       2.6025 │
│ sampler_results/policy_reward_min/predator_0                                           0.0 │
│ sampler_results/policy_reward_min/predator_1                                           0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                 0.14339598058553796 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.10812187407393369 │
│ sampler_results/sampler_perf/mean_inference_ms                          2.1696170097392633 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5725951259293531 │
│ timers/sample_time_ms                                                              705.427 │
│ timers/synch_weights_time_ms                                                         0.897 │
│ timers/training_iteration_time_ms                                                  769.832 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00003 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00003 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_2 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:03:45. Total running time: 2hr 27min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                       44            20.7361     8888    1.67614                      4                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383    4.77                         6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955    5.63                         6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249    4.835                        7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:04:15. Total running time: 2hr 27min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      103            48.7113    20806      1.635                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:04:45. Total running time: 2hr 28min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      163            77.0291    32926      2.135                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:05:15. Total running time: 2hr 28min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      222            104.847    44844      2.255                      6                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:05:45. Total running time: 2hr 29min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      281            132.841    56762      2.175                      5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:06:15. Total running time: 2hr 29min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      341            161.193    68882      2.33                       5                      0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:06:45. Total running time: 2hr 30min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      400            189.385    80877      2.825                      6                      0               100.76                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:07:16. Total running time: 2hr 30min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      459             217.48    92893      2.68                       6                      0               100.97                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:07:46. Total running time: 2hr 31min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      516             245.32   104787      3.38                       7                      0                99.75                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:08:16. Total running time: 2hr 31min 44s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      575            273.641   116857      3.39                     6.5                      0               100.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:08:46. Total running time: 2hr 32min 14s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      631            301.383   128683      3.45                       6                      0                99.07                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:09:16. Total running time: 2hr 32min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      689            329.972   140851      3.58                     6.5                      0                97.75                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:09:46. Total running time: 2hr 33min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      745            357.922   152781      3.695                    6.5                      0                99.56                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:10:16. Total running time: 2hr 33min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      802            386.006   164775      3.925                    6.5                      1                99.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:10:46. Total running time: 2hr 34min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      858            414.333   176848      4                        6.5                      0                96.9                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:11:16. Total running time: 2hr 34min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      915            442.556   188888      3.895                    6.5                      0                99.3                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:11:46. Total running time: 2hr 35min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                      969            470.712   200907      4.205                      7                      1                97.26                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:12:16. Total running time: 2hr 35min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1023            499.063   212953      4.175                    6.5                      0                96.71                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:12:46. Total running time: 2hr 36min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1078            527.189   224939      4.14                     6.5                      1                96.61                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:13:16. Total running time: 2hr 36min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1134            555.459   237024      4.305                    7.5                      1                97.23                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:13:46. Total running time: 2hr 37min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1189            583.836   249181      4.38                       7                      1                95.8                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:14:16. Total running time: 2hr 37min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1245            612.444   261413      4.465                      7                      1                96.42                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:14:46. Total running time: 2hr 38min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1300            640.421   273329      4.36                     7.5                      1                92.9                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:15:16. Total running time: 2hr 38min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1356            669.056   285555      4.205                    7.5                      1                95.09                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:15:46. Total running time: 2hr 39min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1409            697.444   297698      4.815                    7.5                      1                90.86                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:16:17. Total running time: 2hr 39min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1464            725.829   309778      4.495                      7                      0                95.48                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:16:47. Total running time: 2hr 40min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1517            753.804   321672      4.515                    6.5                      1                91.83                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:17:17. Total running time: 2hr 40min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1573            782.449   333879      4.62                       7                      1                90.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:17:47. Total running time: 2hr 41min 15s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1625            810.765   345931      4.795                    6.5                      1                92.93                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:18:17. Total running time: 2hr 41min 45s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1677             839.27   358076      4.835                      8                      1                92.08                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:18:47. Total running time: 2hr 42min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1730            867.587   370184      4.845                      7                      1                87.2                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:19:17. Total running time: 2hr 42min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1781            895.965   382280      4.85                     7.5                      0                88.68                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:19:47. Total running time: 2hr 43min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1834            924.283   394344      5.16                       8                      2                86.54                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:20:17. Total running time: 2hr 43min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1886             952.5    406380      5.41                     7.5                      2                83.95                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:20:47. Total running time: 2hr 44min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1936            981.064   418559      5.465                      7                      2                85.44                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:21:17. Total running time: 2hr 44min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     1986            1009.37   430639      5.435                      7                      3                83.44                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:21:47. Total running time: 2hr 45min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2038            1037.99   442813      5.72                     7.5                      3                76.7                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:22:17. Total running time: 2hr 45min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2089            1066.57   454985      5.52                     7.5                      3                83.6                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:22:47. Total running time: 2hr 46min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2139            1094.53   466914      5.565                    8.5                      3                81.09                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:23:17. Total running time: 2hr 46min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2190            1123.32   479155      5.575                      8                      2                80.85                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:23:47. Total running time: 2hr 47min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2241            1151.89   491366      5.54                     7.5                      2                79.77                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:24:17. Total running time: 2hr 47min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2292            1180.39   503509      5.79                     7.5                      4                77.28                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:24:47. Total running time: 2hr 48min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2342            1208.48   515434      5.855                      8                      4                75.77                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:25:17. Total running time: 2hr 48min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2394            1237.38   527773      5.895                    7.5                      3                72.29                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:25:47. Total running time: 2hr 49min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2444            1265.56   539799      5.71                       7                      4                75.3                       4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:26:17. Total running time: 2hr 49min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=68.3 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888436560>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2495            1294.04   551889      5.92                       8                      4                68.3                       4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:26:47. Total running time: 2hr 50min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2546            1322.32   563878      5.71                       8                    3.5                78.97                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                    2                  90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                    3                  68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                    2                  90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:27:18. Total running time: 2hr 50min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2598            1350.8    576017      5.84                       8                      3                75.79                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:27:48. Total running time: 2hr 51min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2650            1379.43   588202      5.795                      8                      2                73.57                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:28:18. Total running time: 2hr 51min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2700            1407.88   600274      5.825                      8                      1                70.5                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:28:48. Total running time: 2hr 52min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2751            1436.56   612509      5.93                     7.5                      3                70.34                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:29:18. Total running time: 2hr 52min 46s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2801            1464.53   624374      5.82                     7.5                      3                70.06                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:29:48. Total running time: 2hr 53min 16s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2852            1492.96   636467      5.795                    7.5                      3                70.01                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:30:18. Total running time: 2hr 53min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2903            1521.68   648673      5.855                    7.5                      4                73.57                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:30:48. Total running time: 2hr 54min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     2954            1550.14   660740      5.955                      9                      4                70.25                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:31:18. Total running time: 2hr 54min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3005            1578.46   672772      5.81                     7.5                      2                71.53                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:31:48. Total running time: 2hr 55min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=67.08 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88849bac0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3056            1606.98   684846      5.96                     8.5                      3                67.08                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:32:18. Total running time: 2hr 55min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3108            1635.44   696936      5.81                       7                      4                69.13                      5 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:32:48. Total running time: 2hr 56min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=68.22 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8885ec8b0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3159            1664.03   709081      5.9                        8                      3                68.22                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:33:18. Total running time: 2hr 56min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3210            1692.17   721025      5.86                       8                      4                70.62                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:33:48. Total running time: 2hr 57min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=66.62 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8885eeef0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3261            1721.23   733373      6.025                      8                    3.5                66.62                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                    2                  90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                    3                  68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                    2                  90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:34:18. Total running time: 2hr 57min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=65.11 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888333520>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3312            1749.34   745335      6.01                     8.5                      4                65.11                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:34:48. Total running time: 2hr 58min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=65.84 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88849bac0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3364            1778      757491      5.985                    8.5                      4                65.84                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:35:18. Total running time: 2hr 58min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=64.31 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d8883323b0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3414            1806.24   769512      6                          8                    4.5                64.31                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                    2                  90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                    3                  68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                    2                  90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:35:48. Total running time: 2hr 59min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=68.22 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888331510>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3466            1834.67   781545      5.925                    7.5                      4                68.22                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:36:18. Total running time: 2hr 59min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00003 with episode_len_mean=66.87 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_2'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d88849bac0>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3518            1863.22   793697      6.025                      8                      5                66.87                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:36:48. Total running time: 3hr 0min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3570            1891.95   805908      5.89                       8                      4                68.99                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                       6                      2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                       6                      3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                      7                      2                90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:37:18. Total running time: 3hr 0min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00003   RUNNING      shared             type_2                     3622            1920.16   817922      5.81                     7.5                    3.5                71.72                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                      2                  90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                      3                  68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                      2                  90.87                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00003 completed after 3655 iterations at 2023-11-24 04:37:38. Total running time: 3hr 1min 7s
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00003 result                                                         │
├─────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                         │
│ episodes_total                                                                        10000 │
│ time_this_iter_s                                                                    0.48461 │
│ time_total_s                                                                     1938.39912 │
│ timesteps_total                                                                      825679 │
│ training_iteration                                                                     3655 │
│ agent_timesteps_total                                                               1651358 │
│ callback_ok                                                                            True │
│ connector_metrics/ObsPreprocessorConnector_ms                          0.004553794860839844 │
│ connector_metrics/StateBufferConnector_ms                             0.0036373138427734375 │
│ connector_metrics/ViewRequirementAgentConnector_ms                      0.30869579315185547 │
│ counters/num_agent_steps_sampled                                                    1651358 │
│ counters/num_agent_steps_trained                                                          0 │
│ counters/num_env_steps_sampled                                                       825679 │
│ counters/num_env_steps_trained                                                            0 │
│ custom_metrics/assists_max                                                                5 │
│ custom_metrics/assists_mean                                                            0.45 │
│ custom_metrics/assists_min                                                                0 │
│ custom_metrics/kills_max                                                                  6 │
│ custom_metrics/kills_mean                                                              5.55 │
│ custom_metrics/kills_min                                                                  3 │
│ custom_metrics/predator_0_assists_max                                                     2 │
│ custom_metrics/predator_0_assists_mean                                                 0.21 │
│ custom_metrics/predator_0_assists_min                                                     0 │
│ custom_metrics/predator_0_kills_max                                                       6 │
│ custom_metrics/predator_0_kills_mean                                                   2.68 │
│ custom_metrics/predator_0_kills_min                                                       0 │
│ custom_metrics/predator_1_assists_max                                                     3 │
│ custom_metrics/predator_1_assists_mean                                                 0.24 │
│ custom_metrics/predator_1_assists_min                                                     0 │
│ custom_metrics/predator_1_kills_max                                                       6 │
│ custom_metrics/predator_1_kills_mean                                                   2.87 │
│ custom_metrics/predator_1_kills_min                                                       0 │
│ episode_len_mean                                                                      70.79 │
│ episode_reward_max                                                                      8.5 │
│ episode_reward_mean                                                                   5.775 │
│ episode_reward_min                                                                       3. │
│ episodes_this_iter                                                                        3 │
│ hist_stats/episode_lengths                                             ...101, 49, 101, 55] │
│ hist_stats/episode_reward                                              ...0, 7.0, 4.0, 6.0] │
│ hist_stats/policy_shared_policy_reward                                 ...0, 2.0, 2.0, 4.0] │
│ info/learner/__all__/num_agent_steps_trained                                          128.0 │
│ info/learner/__all__/num_env_steps_trained                                            410.0 │
│ info/learner/__all__/total_loss                                          0.6814426586908453 │
│ info/learner/shared_policy/curr_entropy_coeff                                           0.0 │
│ info/learner/shared_policy/curr_kl_coeff                                                0.0 │
│ info/learner/shared_policy/curr_lr                                                   0.0001 │
│ info/learner/shared_policy/default_optimizer_lr                                      0.0001 │
│ info/learner/shared_policy/entropy                                       0.6233506220228532 │
│ info/learner/shared_policy/mean_kl_loss                              1.0149980145048603e-05 │
│ info/learner/shared_policy/policy_loss                                 -0.03729311201502295 │
│ info/learner/shared_policy/total_loss                                    0.6814426586908453 │
│ info/learner/shared_policy/vf_explained_var                              0.0664965825922349 │
│ info/learner/shared_policy/vf_loss                                       0.7187357790329877 │
│ info/learner/shared_policy/vf_loss_unclipped                             0.7187357790329877 │
│ info/num_agent_steps_sampled                                                        1651358 │
│ info/num_agent_steps_trained                                                              0 │
│ info/num_env_steps_sampled                                                           825679 │
│ info/num_env_steps_trained                                                                0 │
│ num_agent_steps_sampled                                                             1651358 │
│ num_agent_steps_trained                                                                   0 │
│ num_env_steps_sampled                                                                825679 │
│ num_env_steps_sampled_this_iter                                                         205 │
│ num_env_steps_sampled_throughput_per_sec                                          426.16463 │
│ num_env_steps_trained                                                                     0 │
│ num_env_steps_trained_this_iter                                                           0 │
│ num_env_steps_trained_throughput_per_sec                                                 0. │
│ num_faulty_episodes                                                                       0 │
│ num_healthy_workers                                                                       0 │
│ num_in_flight_async_reqs                                                                  0 │
│ num_remote_worker_restarts                                                                0 │
│ num_steps_trained_this_iter                                                               0 │
│ perf/cpu_util_percent                                                                   3.4 │
│ perf/ram_util_percent                                                                  24.1 │
│ policy_reward_max/shared_policy                                                         6.0 │
│ policy_reward_mean/shared_policy                                                     2.8875 │
│ policy_reward_min/shared_policy                                                         0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.12363994805441317 │
│ sampler_perf/mean_env_render_ms                                                         0.0 │
│ sampler_perf/mean_env_wait_ms                                           0.10381466577849797 │
│ sampler_perf/mean_inference_ms                                           1.2453745488972459 │
│ sampler_perf/mean_raw_obs_processing_ms                                  0.5577979832079883 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms          0.004553794860839844 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.0036373138427734375 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms      0.30869579315185547 │
│ sampler_results/custom_metrics/assists_max                                                5 │
│ sampler_results/custom_metrics/assists_mean                                            0.45 │
│ sampler_results/custom_metrics/assists_min                                                0 │
│ sampler_results/custom_metrics/kills_max                                                  6 │
│ sampler_results/custom_metrics/kills_mean                                              5.55 │
│ sampler_results/custom_metrics/kills_min                                                  3 │
│ sampler_results/custom_metrics/predator_0_assists_max                                     2 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                 0.21 │
│ sampler_results/custom_metrics/predator_0_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   2.68 │
│ sampler_results/custom_metrics/predator_0_kills_min                                       0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                     3 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                 0.24 │
│ sampler_results/custom_metrics/predator_1_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   2.87 │
│ sampler_results/custom_metrics/predator_1_kills_min                                       0 │
│ sampler_results/episode_len_mean                                                      70.79 │
│ sampler_results/episode_reward_max                                                      8.5 │
│ sampler_results/episode_reward_mean                                                   5.775 │
│ sampler_results/episode_reward_min                                                      3.0 │
│ sampler_results/episodes_this_iter                                                        3 │
│ sampler_results/hist_stats/episode_lengths                             ...101, 49, 101, 55] │
│ sampler_results/hist_stats/episode_reward                              ...0, 7.0, 4.0, 6.0] │
│ sampler_results/hist_stats/policy_shared_policy_reward                 ...0, 2.0, 2.0, 4.0] │
│ sampler_results/num_faulty_episodes                                                       0 │
│ sampler_results/policy_reward_max/shared_policy                                         6.0 │
│ sampler_results/policy_reward_mean/shared_policy                                     2.8875 │
│ sampler_results/policy_reward_min/shared_policy                                         0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.12363994805441317 │
│ sampler_results/sampler_perf/mean_env_render_ms                                         0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                           0.10381466577849797 │
│ sampler_results/sampler_perf/mean_inference_ms                           1.2453745488972459 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                  0.5577979832079883 │
│ timers/sample_time_ms                                                               484.677 │
│ timers/synch_weights_time_ms                                                          0.514 │
│ timers/training_iteration_time_ms                                                   552.928 │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00004 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00004 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_3 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:37:48. Total running time: 3hr 1min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                       11            7.35385     2222      2                        7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429         3201.65      959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700         1959.18      835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427         3171.93      960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655         1938.4       825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:38:18. Total running time: 3hr 1min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                       54            35.8576    10908      1.91                     7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:38:48. Total running time: 3hr 2min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                       96            63.7189    19392      1.76                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:39:18. Total running time: 3hr 2min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      139            92.4143    28078      1.79                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:39:49. Total running time: 3hr 3min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      181            120.629    36646      1.92                     6                        0               100.83                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:40:19. Total running time: 3hr 3min 47s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      223            148.668    45130      1.95                     6                        0               100.83                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:40:49. Total running time: 3hr 4min 17s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      266            177.379    53816      2.04                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:41:19. Total running time: 3hr 4min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      308            205.385    62300      2.18                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:41:49. Total running time: 3hr 5min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      351            234.141    70986      2.02                     7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:42:19. Total running time: 3hr 5min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      393            262.298    79470      2.35                    11                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:42:49. Total running time: 3hr 6min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      435            290.387    87954      2.17                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:43:19. Total running time: 3hr 6min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      477            318.325    96438      2.16                     9                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:43:49. Total running time: 3hr 7min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      520            347.247   105204      1.98                     6                        0               100.79                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:44:19. Total running time: 3hr 7min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      562            375.267   113688      2.32                     8                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:44:49. Total running time: 3hr 8min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      604            403.535   122254      1.99                     7                        0               100.81                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:45:19. Total running time: 3hr 8min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      646             431.46   130738      2.19                     7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:45:49. Total running time: 3hr 9min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      689            460.269   139424      2.2                      6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:46:19. Total running time: 3hr 9min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      731            488.646   148004      2.35                     7                        0               100.95                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:46:49. Total running time: 3hr 10min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      773            516.915   156547      2.65                    11                        0               100.58                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:47:19. Total running time: 3hr 10min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      815            544.773   165031      2.38                     7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:47:49. Total running time: 3hr 11min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      858             573.46   173717      2.6                      8                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:48:19. Total running time: 3hr 11min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      900            601.682   182274      3.04                     9                        0               100.72                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:48:50. Total running time: 3hr 12min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      943            630.276   190960      2.62                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:49:20. Total running time: 3hr 12min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                      984            658.294   199401      2.7                      7                        0               100.57                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:49:50. Total running time: 3hr 13min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1025             686.46   207944      3.43                     8                        0               100.46                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:50:20. Total running time: 3hr 13min 48s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1067             714.89   216523      3.27                     9                        1               100.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:50:50. Total running time: 3hr 14min 18s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1109            743.155   225083      3.48                     9                        0               100.69                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:51:20. Total running time: 3hr 14min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1151            771.471   233653      3.06                     8                        0               100.85                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:51:50. Total running time: 3hr 15min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1193            799.857   242230      3.63                     8                        0               100.77                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:52:20. Total running time: 3hr 15min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1234            828.077   250797      3.37                     8                        0               100.82                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:52:50. Total running time: 3hr 16min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1276            856.598   259440      3.5                     10                        0                99.46                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:53:20. Total running time: 3hr 16min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1318            885.195   268068      3.36                     8                        0               100.42                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:53:50. Total running time: 3hr 17min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1358            913.629   276692      3.76                    11                        0                99.28                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:54:20. Total running time: 3hr 17min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1398            941.432   285096      3.63                     9                        0                99.91                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:54:50. Total running time: 3hr 18min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1439            969.801   293703      4.06                     9                        1                99.76                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:55:20. Total running time: 3hr 18min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1481            998.752   302456      3.78                    10                        0                99.58                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:55:50. Total running time: 3hr 19min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1520            1026.73   310891      3.63                    10                        0                98.8                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:56:20. Total running time: 3hr 19min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1562            1055.18   319508      3.88                     9                        0                99.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:56:51. Total running time: 3hr 20min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1604            1083.89   328169      3.75                    12                        0               100.75                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:57:21. Total running time: 3hr 20min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1644            1112.2    336736      4                       11                        0                97.79                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:57:51. Total running time: 3hr 21min 19s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1684            1140.2    345207      3.92                    11                        1                97.1                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:58:21. Total running time: 3hr 21min 49s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1726            1169.15   353990      3.86                     9                        0                99.95                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:58:51. Total running time: 3hr 22min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1766            1197.16   362497      4.12                     9                        1                99.21                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:59:21. Total running time: 3hr 22min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1808            1225.82   371146      4.17                     8                        1                99.62                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 04:59:51. Total running time: 3hr 23min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1850            1254.19   379755      3.83                     7                        1               100.23                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:00:21. Total running time: 3hr 23min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1891            1283.1    388500      4.14                    10                        1                98.56                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:00:51. Total running time: 3hr 24min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1932            1311.54   397122      4.12                    10                        1                98.21                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:01:21. Total running time: 3hr 24min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     1971            1339.45   405604      4.29                    10                        1                98.41                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:01:51. Total running time: 3hr 25min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2011            1368.02   414238      4.31                    10                        1                98.08                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:02:21. Total running time: 3hr 25min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2051            1396.54   422870      4.32                     8                        1                98.65                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:02:51. Total running time: 3hr 26min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2090            1425.46   431616      4.28                     8                        0                97.56                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:03:21. Total running time: 3hr 26min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2129            1453.48   440106      4.53                    12                        0                96.86                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:03:51. Total running time: 3hr 27min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2169            1482.21   448826      4.4                      9                        1                95.58                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:04:21. Total running time: 3hr 27min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2208            1510.27   457330      4.35                     8                        0                97.16                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:04:51. Total running time: 3hr 28min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2249            1539.13   466104      4.3                      9                        1                97.65                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:05:21. Total running time: 3hr 28min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2289            1567.65   474727      4.12                    10                        1                95.92                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:05:51. Total running time: 3hr 29min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2329            1596.11   483347      4.37                    15                        0                96.05                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:06:22. Total running time: 3hr 29min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2368            1624.3    491889      4.44                    15                        0                97.1                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:06:52. Total running time: 3hr 30min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2407            1652.32   500332      4.41                     9                        1                95.39                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:07:22. Total running time: 3hr 30min 50s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2445            1681.85   509266      4.51                     9                        1                93.38                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:07:52. Total running time: 3hr 31min 20s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2485            1710.37   517871      4.38                     9                        1                97.72                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:08:22. Total running time: 3hr 31min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2525            1738.67   526460      4.48                    10                        1                95.99                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:08:52. Total running time: 3hr 32min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2564            1766.98   535030      4.68                     8                        1                96.63                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:09:22. Total running time: 3hr 32min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2603            1795.27   543587      4.66                     9                        1                94.88                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:09:52. Total running time: 3hr 33min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2642            1823.61   552182      4.5                      7                        0                95.91                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:10:22. Total running time: 3hr 33min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2682            1852.87   561032      4.68                    10                        1                95.37                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:10:52. Total running time: 3hr 34min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2720            1881.14   569612      4.79                    10                        2                94.34                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:11:22. Total running time: 3hr 34min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2760            1909.56   578236      4.65                    10                        1                94.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:11:52. Total running time: 3hr 35min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2800            1938.24   586883      4.46                    10                        1                95.33                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:12:22. Total running time: 3hr 35min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2840            1966.54   595447      4.5                     10                        0                96.38                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:12:52. Total running time: 3hr 36min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2878            1994.47   603869      4.48                    13                        1                98                         3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:13:22. Total running time: 3hr 36min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2917            2023.57   612678      4.6                      8                        1                95.1                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:13:52. Total running time: 3hr 37min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2957            2052.26   621390      4.63                    11                        1                96.14                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:14:22. Total running time: 3hr 37min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     2995            2080.45   629913      4.75                    12                        1                94.32                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:14:52. Total running time: 3hr 38min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3035            2109.24   638621      4.74                    10                        1                95.61                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:15:22. Total running time: 3hr 38min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3073            2137.96   647281      4.72                    10                        0                95.36                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:15:52. Total running time: 3hr 39min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3111            2165.94   655741      4.92                    11                        1                93.89                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:16:22. Total running time: 3hr 39min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3149            2194.67   664466      4.7                      9                        1                92.3                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:16:52. Total running time: 3hr 40min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3187            2222.83   672956      4.77                     9                        0                94.65                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:17:23. Total running time: 3hr 40min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3226            2251.87   681729      4.91                    10                        1                93.37                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:17:53. Total running time: 3hr 41min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3266            2280.51   690363      4.78                    10                        0                96.36                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:18:23. Total running time: 3hr 41min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3306            2308.64   698884      4.78                    10                        1                95.64                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:18:53. Total running time: 3hr 42min 21s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3346            2337.01   707491      4.48                     9                        1                96.76                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:19:23. Total running time: 3hr 42min 51s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3385            2366.08   716258      4.87                    10                        0                92.17                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:19:53. Total running time: 3hr 43min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3423            2394.12   724761      4.76                    12                        2                94.86                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:20:23. Total running time: 3hr 43min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3461            2422.45   733333      4.64                    10                        1                93.55                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:20:53. Total running time: 3hr 44min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3501            2451.49   742169      4.78                    12                        2                95.1                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:21:23. Total running time: 3hr 44min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3540            2480.24   750906      5.06                    12                        1                92.42                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:21:53. Total running time: 3hr 45min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3578            2508.48   759446      5                        9                        0                92.65                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:22:23. Total running time: 3hr 45min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3615            2537.05   768106      5.05                    11                        1                89.63                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:22:53. Total running time: 3hr 46min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3654            2565.79   776791      4.73                     8                        0                92.13                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:23:23. Total running time: 3hr 46min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3693            2594.21   785398      4.81                    11                        1                92.29                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:23:53. Total running time: 3hr 47min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3732            2622.93   794102      4.63                    11                        1                94.07                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:24:23. Total running time: 3hr 47min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3770            2650.81   802541      5.04                    16                        2                95.29                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:24:53. Total running time: 3hr 48min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3809            2679.7    811283      4.85                    10                        2                92.19                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:25:23. Total running time: 3hr 48min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3848            2708.38   819931      4.71                     8                        1                92.79                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:25:53. Total running time: 3hr 49min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3886            2736.44   828426      4.85                    11                        0                95.29                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:26:23. Total running time: 3hr 49min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3925            2765.6    837284      5                       10                        1                89.74                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:26:54. Total running time: 3hr 50min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     3963            2793.94   845796      5.07                    13                        2                90.56                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:27:24. Total running time: 3hr 50min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4001            2822.27   854384      4.96                    10                        0                91.86                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:27:54. Total running time: 3hr 51min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4039            2851.23   863146      5.05                    11                        2                92.98                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:28:24. Total running time: 3hr 51min 52s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4077            2879.55   871722      5.14                    13                        1                91.73                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:28:54. Total running time: 3hr 52min 22s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4115            2907.75   880295      4.95                    10                        1                92.14                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:29:24. Total running time: 3hr 52min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4154            2936.59   889020      4.89                    10                        0                91.08                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:29:54. Total running time: 3hr 53min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4191            2964.47   897473      4.97                    12                        1                92.31                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:30:24. Total running time: 3hr 53min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4230            2993.13   906123      4.9                     10                        0                94.56                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:30:54. Total running time: 3hr 54min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4269            3022.3    914961      5.14                    10                        0                93.38                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:31:24. Total running time: 3hr 54min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4307            3050.26   923412      5.11                    12                        1                91.43                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:31:54. Total running time: 3hr 55min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4345            3078.63   931951      4.72                    10                        0                91.72                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:32:24. Total running time: 3hr 55min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4383            3107.63   940713      5.06                    10                        1                92.04                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:32:54. Total running time: 3hr 56min 23s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4420            3135.84   949233      5.2                     11                        1                92.16                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:33:24. Total running time: 3hr 56min 53s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00004   RUNNING      independent        type_3                     4459            3164.56   957921      4.74                    10                        1                89.91                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00004 completed after 4493 iterations at 2023-11-24 05:33:53. Total running time: 3hr 57min 21s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00004 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                       10000 │
│ time_this_iter_s                                                                   0.66367 │
│ time_total_s                                                                    3191.30171 │
│ timesteps_total                                                                     966027 │
│ training_iteration                                                                    4493 │
│ agent_timesteps_total                                                              1932054 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                        0.0031387805938720703 │
│ connector_metrics/StateBufferConnector_ms                            0.0025829076766967773 │
│ connector_metrics/ViewRequirementAgentConnector_ms                     0.15512120723724365 │
│ counters/num_agent_steps_sampled                                                   1932054 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      966027 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               2 │
│ custom_metrics/assists_mean                                                           0.11 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             4.71 │
│ custom_metrics/kills_min                                                                 1 │
│ custom_metrics/predator_0_assists_max                                                    1 │
│ custom_metrics/predator_0_assists_mean                                                0.06 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      6 │
│ custom_metrics/predator_0_kills_mean                                                  2.51 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    1 │
│ custom_metrics/predator_1_assists_mean                                                0.05 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      5 │
│ custom_metrics/predator_1_kills_mean                                                   2.2 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     88.56 │
│ episode_reward_max                                                                      9. │
│ episode_reward_mean                                                                   4.93 │
│ episode_reward_min                                                                      1. │
│ episodes_this_iter                                                                       2 │
│ hist_stats/episode_lengths                                            ...1, 101, 101, 101] │
│ hist_stats/episode_reward                                             ...0, 4.0, 3.0, 1.0] │
│ hist_stats/policy_predator_0_reward                                   ...0, 3.0, 2.0, 1.0] │
│ hist_stats/policy_predator_1_reward                                   ...0, 1.0, 1.0, 0.0] │
│ info/learner/__all__/num_agent_steps_trained                                         256.0 │
│ info/learner/__all__/num_env_steps_trained                                           202.0 │
│ info/learner/__all__/total_loss                                         0.3712368216365576 │
│ info/learner/predator_0/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_0/curr_lr                                                     0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_0/entropy                                         1.2393761724233627 │
│ info/learner/predator_0/mean_kl_loss                                 5.157035428027257e-06 │
│ info/learner/predator_0/policy_loss                                   -0.02279591007390991 │
│ info/learner/predator_0/total_loss                                      0.3712368216365576 │
│ info/learner/predator_0/vf_explained_var                               0.18662195652723312 │
│ info/learner/predator_0/vf_loss                                         0.2472225558012724 │
│ info/learner/predator_0/vf_loss_unclipped                               0.2472225558012724 │
│ info/learner/predator_1/curr_entropy_coeff                                             0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                  0.0 │
│ info/learner/predator_1/curr_lr                                                     0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                        0.0001 │
│ info/learner/predator_1/entropy                                         1.3048780858516693 │
│ info/learner/predator_1/mean_kl_loss                                 5.216885926984105e-05 │
│ info/learner/predator_1/policy_loss                                  -0.014801121782511473 │
│ info/learner/predator_1/total_loss                                     0.14681017701514065 │
│ info/learner/predator_1/vf_explained_var                               -0.1305222362279892 │
│ info/learner/predator_1/vf_loss                                         0.1616113092750311 │
│ info/learner/predator_1/vf_loss_unclipped                               0.1616113092750311 │
│ info/num_agent_steps_sampled                                                       1932054 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          966027 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1932054 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               966027 │
│ num_env_steps_sampled_this_iter                                                        202 │
│ num_env_steps_sampled_throughput_per_sec                                         306.11685 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ perf/cpu_util_percent                                                                  3.7 │
│ perf/ram_util_percent                                                                 24.0 │
│ policy_reward_max/predator_0                                                           6.0 │
│ policy_reward_max/predator_1                                                           5.0 │
│ policy_reward_mean/predator_0                                                        2.625 │
│ policy_reward_mean/predator_1                                                        2.305 │
│ policy_reward_min/predator_0                                                           0.0 │
│ policy_reward_min/predator_1                                                           0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.1434968112917071 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.10765372324088643 │
│ sampler_perf/mean_inference_ms                                          2.1717194715119943 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5716238408677965 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms        0.0031387805938720703 │
│ sampler_results/connector_metrics/StateBufferConnector_ms            0.0025829076766967773 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms     0.15512120723724365 │
│ sampler_results/custom_metrics/assists_max                                               2 │
│ sampler_results/custom_metrics/assists_mean                                           0.11 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             4.71 │
│ sampler_results/custom_metrics/kills_min                                                 1 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    1 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                0.06 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                  2.51 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    1 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                0.05 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      5 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   2.2 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     88.56 │
│ sampler_results/episode_reward_max                                                     9.0 │
│ sampler_results/episode_reward_mean                                                   4.93 │
│ sampler_results/episode_reward_min                                                     1.0 │
│ sampler_results/episodes_this_iter                                                       2 │
│ sampler_results/hist_stats/episode_lengths                            ...1, 101, 101, 101] │
│ sampler_results/hist_stats/episode_reward                             ...0, 4.0, 3.0, 1.0] │
│ sampler_results/hist_stats/policy_predator_0_reward                   ...0, 3.0, 2.0, 1.0] │
│ sampler_results/hist_stats/policy_predator_1_reward                   ...0, 1.0, 1.0, 0.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/predator_0                                           6.0 │
│ sampler_results/policy_reward_max/predator_1                                           5.0 │
│ sampler_results/policy_reward_mean/predator_0                                        2.625 │
│ sampler_results/policy_reward_mean/predator_1                                        2.305 │
│ sampler_results/policy_reward_min/predator_0                                           0.0 │
│ sampler_results/policy_reward_min/predator_1                                           0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.1434968112917071 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.10765372324088643 │
│ sampler_results/sampler_perf/mean_inference_ms                          2.1717194715119943 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5716238408677965 │
│ timers/sample_time_ms                                                              752.764 │
│ timers/synch_weights_time_ms                                                         0.904 │
│ timers/training_iteration_time_ms                                                  821.326 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00005 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00005 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_3 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:33:55. Total running time: 3hr 57min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                                                                                                                                                           │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:34:25. Total running time: 3hr 57min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                       59            27.8743    11918      1.82                     6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:34:55. Total running time: 3hr 58min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      118            55.7642    23836      1.9                      5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:35:25. Total running time: 3hr 58min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      177            83.8237    35754      1.87                     7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:35:55. Total running time: 3hr 59min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      237            112.196    47874      2.36                     7                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:36:25. Total running time: 3hr 59min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      296            140.106    59792      2.4                      8                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:36:55. Total running time: 4hr 0min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      355             168.15    71710      2.5                      6                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:37:25. Total running time: 4hr 0min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      414            196.209    83713      2.87                    11                        0               100.84                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:37:55. Total running time: 4hr 1min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      473            224.401    95698      2.67                     7                        0               100.66                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:38:25. Total running time: 4hr 1min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      531            252.445   107672      3.35                     7                        0               100.55                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:38:55. Total running time: 4hr 2min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      589             280.51   119628      3.57                     9                        0               100.37                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:39:25. Total running time: 4hr 2min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      646            308.425   131493      3.78                     9                        1               100.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:39:55. Total running time: 4hr 3min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      704            336.504   143469      3.61                     8                        0                99.56                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:40:25. Total running time: 4hr 3min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      762            364.696   155509      3.79                     7                        0                99.42                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:40:55. Total running time: 4hr 4min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      818            392.495   167330      4.19                    10                        0                99.02                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:41:25. Total running time: 4hr 4min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      875            420.868   179474      4.25                    11                        0                98.34                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:41:55. Total running time: 4hr 5min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      931            448.924   191429      4.33                    11                        0                98.66                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:42:26. Total running time: 4hr 5min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                      986            477.406   203568      4.36                     9                        0                95.75                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:42:56. Total running time: 4hr 6min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1042            505.365   215514      4.41                     9                        1                96.55                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:43:26. Total running time: 4hr 6min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1098            533.668   227558      4.19                    10                        0                97.27                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:43:56. Total running time: 4hr 7min 24s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1153            561.906   239616      4.73                    10                        1                96.37                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:44:26. Total running time: 4hr 7min 54s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1207             590.46   251826      4.55                     9                        1                96.13                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:44:56. Total running time: 4hr 8min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1262            618.723   263842      4.34                     9                        1                96.3                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:45:26. Total running time: 4hr 8min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1316            646.745   275812      4.54                    11                        0                94.56                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:45:56. Total running time: 4hr 9min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1369            675.173   287921      5.16                    13                        0                93.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:46:26. Total running time: 4hr 9min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1424            703.396   299974      4.77                    11                        1                94.27                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:46:56. Total running time: 4hr 10min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1479            731.899   312082      4.55                    12                        1                94.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:47:26. Total running time: 4hr 10min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1531            760.086   324125      4.8                     13                        0                91.84                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:47:56. Total running time: 4hr 11min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1585            788.283   336122      4.7                     10                        1                94.43                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:48:26. Total running time: 4hr 11min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1641             816.66   348192      4.72                    11                        0                95.74                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:48:56. Total running time: 4hr 12min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1696            844.806   360190      4.69                    14                        0                96.36                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:49:26. Total running time: 4hr 12min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1751            873.206   372275      4.62                    10                        1                94.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:49:56. Total running time: 4hr 13min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1805            901.594   384401      4.67                    13                        1                94.1                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:50:26. Total running time: 4hr 13min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1858            929.714   396407      4.79                    10                        1                97.46                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:50:57. Total running time: 4hr 14min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1911             958.23   408515      4.9                     10                        1                89.97                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:51:27. Total running time: 4hr 14min 55s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     1963            986.173   420434      5.05                    10                        0                92.35                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:51:57. Total running time: 4hr 15min 25s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2015            1014.88   432637      4.84                     9                        0                88.6                       4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:52:27. Total running time: 4hr 15min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2069            1043.07   444674      5.21                    11                        1                91.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:52:57. Total running time: 4hr 16min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2125            1071.5    456801      4.29                     9                        0                97.06                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:53:27. Total running time: 4hr 16min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2177            1099.81   468850      4.91                    10                        2                90.64                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:53:57. Total running time: 4hr 17min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2230            1128.07   480923      4.86                    10                        0                94.78                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:54:27. Total running time: 4hr 17min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2282            1156.52   493105      4.96                    10                        1                92.63                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:54:57. Total running time: 4hr 18min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2336            1184.92   505178      5.19                    12                        1                90.45                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:55:27. Total running time: 4hr 18min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2388            1212.81   517075      4.77                     9                        1                92.69                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:55:57. Total running time: 4hr 19min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2441            1241.61   529313      4.85                    10                        1                93.44                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:56:27. Total running time: 4hr 19min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2494            1270.01   541453      5.2                     12                        0                93.16                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:56:57. Total running time: 4hr 20min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2545            1298.28   553463      5.19                    14                        1                89.96                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:57:27. Total running time: 4hr 20min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2597            1326.72   565606      5.39                     9                        1                87.14                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:57:57. Total running time: 4hr 21min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2650            1355.08   577658      5.09                    11                        2                89.56                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:58:27. Total running time: 4hr 21min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2701            1383.74   589907      5.52                    14                        3                84.42                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:58:57. Total running time: 4hr 22min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2753            1412.05   601982      5.78                    13                        2                84.21                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:59:27. Total running time: 4hr 22min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2804            1440.46   614055      6.16                    12                        1                78.94                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 05:59:57. Total running time: 4hr 23min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2857            1469.07   626236      5.77                    12                        2                83.9                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:00:28. Total running time: 4hr 23min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2907            1497.47   638314      6                       16                        2                80.43                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:00:58. Total running time: 4hr 24min 26s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     2956            1525.74   650356      6                       14                        3                80.79                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:01:28. Total running time: 4hr 24min 56s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3008            1554.38   662569      6.08                    10                        2                76.75                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:01:58. Total running time: 4hr 25min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3058            1582.72   674600      6.24                    14                        3                76.99                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:02:28. Total running time: 4hr 25min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3107            1611.29   686796      6.35                    14                        3                76.99                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:02:58. Total running time: 4hr 26min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3158            1640.12   699053      6.43                    12                        3                76.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:03:28. Total running time: 4hr 26min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3207            1668.24   711002      6.37                    14                        4                75.8                       5 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:03:58. Total running time: 4hr 27min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3258            1696.79   723176      6.1                     12                        2                74.96                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:04:28. Total running time: 4hr 27min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3308            1725.46   735375      6.2                     12                        4                75.24                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:04:58. Total running time: 4hr 28min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3359            1753.75   747420      6.27                    12                        4                73.38                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:05:28. Total running time: 4hr 28min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3411            1782.39   759621      6.6                     14                        4                73.51                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:05:58. Total running time: 4hr 29min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3462            1810.44   771511      6.38                    14                        3                79.15                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:06:28. Total running time: 4hr 29min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3512            1838.95   783628      6.2                     10                        4                69.89                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:06:58. Total running time: 4hr 30min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3564            1867.84   795824      6.72                    12                        4                69.73                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:07:28. Total running time: 4hr 30min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3615            1895.84   807741      6.35                    12                        3                69.59                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:07:58. Total running time: 4hr 31min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3666            1924.73   819996      6.76                    18                        4                70.61                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:08:28. Total running time: 4hr 31min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3717            1953.23   832123      6.59                    14                        4                70.14                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:08:59. Total running time: 4hr 32min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3768            1981.51   844148      6.59                    12                        4                69.19                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:09:29. Total running time: 4hr 32min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3817            2009.81   856126      6.46                    14                        2                74.51                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:09:59. Total running time: 4hr 33min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00005   RUNNING      shared             type_3                     3868            2038.23   868200      6.46                    12                        3                69.68                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00005 completed after 3895 iterations at 2023-11-24 06:10:14. Total running time: 4hr 33min 43s
╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00005 result                                                        │
├────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                        │
│ episodes_total                                                                        9999 │
│ time_this_iter_s                                                                   0.49817 │
│ time_total_s                                                                    2052.84087 │
│ timesteps_total                                                                     874442 │
│ training_iteration                                                                    3895 │
│ agent_timesteps_total                                                              1748884 │
│ callback_ok                                                                           True │
│ connector_metrics/ObsPreprocessorConnector_ms                         0.004625082015991211 │
│ connector_metrics/StateBufferConnector_ms                             0.003638744354248047 │
│ connector_metrics/ViewRequirementAgentConnector_ms                     0.30780482292175293 │
│ counters/num_agent_steps_sampled                                                   1748884 │
│ counters/num_agent_steps_trained                                                         0 │
│ counters/num_env_steps_sampled                                                      874442 │
│ counters/num_env_steps_trained                                                           0 │
│ custom_metrics/assists_max                                                               4 │
│ custom_metrics/assists_mean                                                           0.38 │
│ custom_metrics/assists_min                                                               0 │
│ custom_metrics/kills_max                                                                 6 │
│ custom_metrics/kills_mean                                                             5.63 │
│ custom_metrics/kills_min                                                                 3 │
│ custom_metrics/predator_0_assists_max                                                    2 │
│ custom_metrics/predator_0_assists_mean                                                0.19 │
│ custom_metrics/predator_0_assists_min                                                    0 │
│ custom_metrics/predator_0_kills_max                                                      6 │
│ custom_metrics/predator_0_kills_mean                                                  2.88 │
│ custom_metrics/predator_0_kills_min                                                      0 │
│ custom_metrics/predator_1_assists_max                                                    2 │
│ custom_metrics/predator_1_assists_mean                                                0.19 │
│ custom_metrics/predator_1_assists_min                                                    0 │
│ custom_metrics/predator_1_kills_max                                                      6 │
│ custom_metrics/predator_1_kills_mean                                                  2.75 │
│ custom_metrics/predator_1_kills_min                                                      0 │
│ episode_len_mean                                                                     70.53 │
│ episode_reward_max                                                                     14. │
│ episode_reward_mean                                                                   6.39 │
│ episode_reward_min                                                                      3. │
│ episodes_this_iter                                                                       3 │
│ hist_stats/episode_lengths                                            ...101, 101, 49, 63] │
│ hist_stats/episode_reward                                             ...0, 7.0, 6.0, 6.0] │
│ hist_stats/policy_shared_policy_reward                                ...0, 3.0, 3.0, 3.0] │
│ info/learner/__all__/num_agent_steps_trained                                         128.0 │
│ info/learner/__all__/num_env_steps_trained                                           426.0 │
│ info/learner/__all__/total_loss                                         0.6133455365129253 │
│ info/learner/shared_policy/curr_entropy_coeff                                          0.0 │
│ info/learner/shared_policy/curr_kl_coeff                                               0.0 │
│ info/learner/shared_policy/curr_lr                                                  0.0001 │
│ info/learner/shared_policy/default_optimizer_lr                                     0.0001 │
│ info/learner/shared_policy/entropy                                      0.5932247919194839 │
│ info/learner/shared_policy/mean_kl_loss                              1.980010978620746e-05 │
│ info/learner/shared_policy/policy_loss                               -0.006242883556029376 │
│ info/learner/shared_policy/total_loss                                   0.6133455365129253 │
│ info/learner/shared_policy/vf_explained_var                            0.20049336377312155 │
│ info/learner/shared_policy/vf_loss                                      0.6195884206715752 │
│ info/learner/shared_policy/vf_loss_unclipped                            0.6195884206715752 │
│ info/num_agent_steps_sampled                                                       1748884 │
│ info/num_agent_steps_trained                                                             0 │
│ info/num_env_steps_sampled                                                          874442 │
│ info/num_env_steps_trained                                                               0 │
│ num_agent_steps_sampled                                                            1748884 │
│ num_agent_steps_trained                                                                  0 │
│ num_env_steps_sampled                                                               874442 │
│ num_env_steps_sampled_this_iter                                                        213 │
│ num_env_steps_sampled_throughput_per_sec                                          430.6242 │
│ num_env_steps_trained                                                                    0 │
│ num_env_steps_trained_this_iter                                                          0 │
│ num_env_steps_trained_throughput_per_sec                                                0. │
│ num_faulty_episodes                                                                      0 │
│ num_healthy_workers                                                                      0 │
│ num_in_flight_async_reqs                                                                 0 │
│ num_remote_worker_restarts                                                               0 │
│ num_steps_trained_this_iter                                                              0 │
│ policy_reward_max/shared_policy                                                        7.0 │
│ policy_reward_mean/shared_policy                                                     3.195 │
│ policy_reward_min/shared_policy                                                        0.0 │
│ sampler_perf/mean_action_processing_ms                                 0.12367446754212086 │
│ sampler_perf/mean_env_render_ms                                                        0.0 │
│ sampler_perf/mean_env_wait_ms                                          0.10342753927041266 │
│ sampler_perf/mean_inference_ms                                          1.2479684286540427 │
│ sampler_perf/mean_raw_obs_processing_ms                                 0.5565522348726542 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms         0.004625082015991211 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.003638744354248047 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms     0.30780482292175293 │
│ sampler_results/custom_metrics/assists_max                                               4 │
│ sampler_results/custom_metrics/assists_mean                                           0.38 │
│ sampler_results/custom_metrics/assists_min                                               0 │
│ sampler_results/custom_metrics/kills_max                                                 6 │
│ sampler_results/custom_metrics/kills_mean                                             5.63 │
│ sampler_results/custom_metrics/kills_min                                                 3 │
│ sampler_results/custom_metrics/predator_0_assists_max                                    2 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                0.19 │
│ sampler_results/custom_metrics/predator_0_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                  2.88 │
│ sampler_results/custom_metrics/predator_0_kills_min                                      0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                    2 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                0.19 │
│ sampler_results/custom_metrics/predator_1_assists_min                                    0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                      6 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                  2.75 │
│ sampler_results/custom_metrics/predator_1_kills_min                                      0 │
│ sampler_results/episode_len_mean                                                     70.53 │
│ sampler_results/episode_reward_max                                                    14.0 │
│ sampler_results/episode_reward_mean                                                   6.39 │
│ sampler_results/episode_reward_min                                                     3.0 │
│ sampler_results/episodes_this_iter                                                       3 │
│ sampler_results/hist_stats/episode_lengths                            ...101, 101, 49, 63] │
│ sampler_results/hist_stats/episode_reward                             ...0, 7.0, 6.0, 6.0] │
│ sampler_results/hist_stats/policy_shared_policy_reward                ...0, 3.0, 3.0, 3.0] │
│ sampler_results/num_faulty_episodes                                                      0 │
│ sampler_results/policy_reward_max/shared_policy                                        7.0 │
│ sampler_results/policy_reward_mean/shared_policy                                     3.195 │
│ sampler_results/policy_reward_min/shared_policy                                        0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                 0.12367446754212086 │
│ sampler_results/sampler_perf/mean_env_render_ms                                        0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                          0.10342753927041266 │
│ sampler_results/sampler_perf/mean_inference_ms                          1.2479684286540427 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                 0.5565522348726542 │
│ timers/sample_time_ms                                                              483.463 │
│ timers/synch_weights_time_ms                                                         0.508 │
│ timers/training_iteration_time_ms                                                  551.107 │
╰────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00006 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00006 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:10:29. Total running time: 4hr 33min 57s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                       17            11.3407     3434    1.70588                    4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383    4.77                       6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955    5.63                       6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249    4.835                      7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679    5.775                      8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027    4.93                       9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895          2052.84     874442    6.39                      14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:10:59. Total running time: 4hr 34min 27s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                       59            39.3355    11918      1.69                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895          2052.84     874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:11:29. Total running time: 4hr 34min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      102            68.0686    20604      1.7                      5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895          2052.84     874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:11:59. Total running time: 4hr 35min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      144            96.2995    29088      1.47                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895          2052.84     874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:12:29. Total running time: 4hr 35min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      186            124.514    37572      1.68                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:12:59. Total running time: 4hr 36min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      228            152.716    46056      1.61                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:13:29. Total running time: 4hr 36min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      270            180.712    54540      1.43                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:13:59. Total running time: 4hr 37min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      313            209.413    63226      1.84                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:14:29. Total running time: 4hr 37min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      355            237.569    71710      1.93                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:14:59. Total running time: 4hr 38min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      397            265.659    80194      1.97                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:15:29. Total running time: 4hr 38min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      439            294.027    88732      1.92                     6                        0               100.53                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:15:59. Total running time: 4hr 39min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      482            322.649    97418      2.01                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:16:29. Total running time: 4hr 39min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      524            351.095   106000      2                        6                        0               100.97                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:16:59. Total running time: 4hr 40min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      565            378.837   114372      1.88                     6                        0               100.89                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:17:29. Total running time: 4hr 40min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      608            407.524   123057      2.32                     6                        0               100.99                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:17:59. Total running time: 4hr 41min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      650             435.63   131541      2.09                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:18:30. Total running time: 4hr 41min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      693            464.354   140227      2.28                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:19:00. Total running time: 4hr 42min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      735            492.433   148711      2.38                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:19:30. Total running time: 4hr 42min 58s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      777            520.641   157195      2.42                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:20:00. Total running time: 4hr 43min 28s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      819            548.691   165679      2.51                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:20:30. Total running time: 4hr 43min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      861            577.045   174224      2.8                      6                        0               100.6                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:21:00. Total running time: 4hr 44min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      903            605.364   182790      2.62                     6                        0               100.81                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:21:30. Total running time: 4hr 44min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      945            633.766   191391      2.92                     6                        0               100.15                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:22:00. Total running time: 4hr 45min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                      986            662.031   199914      3.12                     6                        0                99.37                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:22:30. Total running time: 4hr 45min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1027            690.455   208526      3.16                     6                        0                99.93                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:23:00. Total running time: 4hr 46min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1069             719.17   217183      3.23                     6                        0               100.68                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:23:30. Total running time: 4hr 46min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1111            747.287   225667      3.26                     6                        1               100.96                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:24:00. Total running time: 4hr 47min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1152            775.139   234095      3.27                     6                        0               100.44                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:24:30. Total running time: 4hr 47min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1194            803.612   242705      3.42                     6                        1                99.23                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:25:00. Total running time: 4hr 48min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1236            832.181   251344      3.24                     6                        1               100.53                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:25:30. Total running time: 4hr 48min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1278            860.718   259958      3.33                     6                        1               100.28                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:26:00. Total running time: 4hr 49min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1318            889.083   268565      3.43                     6                        0                99.87                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:26:30. Total running time: 4hr 49min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1359             917.62   277211      3.64                     6                        0                99.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:27:00. Total running time: 4hr 50min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1401            946.278   285878      3.54                     6                        1                99.8                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:27:30. Total running time: 4hr 50min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1441            974.708   294494      3.7                      6                        1                98.28                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:28:01. Total running time: 4hr 51min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1482            1002.72   302937      3.84                     6                        0                98.25                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:28:31. Total running time: 4hr 51min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1522            1031.34   311578      3.81                     6                        0                98.53                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:29:01. Total running time: 4hr 52min 29s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1562            1059.37   320040      3.83                     6                        0                98.63                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:29:31. Total running time: 4hr 52min 59s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1604            1087.95   328665      3.75                     6                        0               100.01                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:30:01. Total running time: 4hr 53min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1643            1116.49   337307      3.86                     6                        1                98.54                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:30:31. Total running time: 4hr 54min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1681            1144.83   345870      3.82                     6                        1                95.62                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:31:01. Total running time: 4hr 54min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1721            1173.87   354661      4.13                     6                        0                97.69                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:31:31. Total running time: 4hr 55min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1761            1202.06   363190      4.03                     6                        0                96.28                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:32:01. Total running time: 4hr 55min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1800            1230.36   371718      4.22                     6                        1                96.22                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:32:31. Total running time: 4hr 56min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1840            1258.52   380236      4.04                     6                        0                97.69                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:33:01. Total running time: 4hr 56min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1878            1287.05   388842      4.15                     6                        1                98.13                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:33:31. Total running time: 4hr 57min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1918            1315.6    397462      4.14                     6                        1                97.31                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:34:01. Total running time: 4hr 57min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1957            1344.3    406119      4.34                     6                        1                96.23                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:34:31. Total running time: 4hr 58min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     1996            1373.04   414780      4.23                     6                        0                94.02                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:35:01. Total running time: 4hr 58min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2035            1401.49   423379      4.3                      6                        2                92.71                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:35:31. Total running time: 4hr 59min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2074            1429.9    431949      4.41                     6                        1                95.27                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:36:01. Total running time: 4hr 59min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2113            1458.61   440612      4.33                     6                        2                96.73                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:36:31. Total running time: 5hr 0min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2151            1486.21   448942      4.37                     6                        1                96.23                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:37:01. Total running time: 5hr 0min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2189            1515.27   457673      4.48                     6                        2                93.82                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:37:31. Total running time: 5hr 1min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2228            1543.25   466140      4.2                      6                        0                96.01                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:38:01. Total running time: 5hr 1min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2267            1572.48   474933      4.4                      6                        0                92.52                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:38:31. Total running time: 5hr 2min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2305            1600.71   483467      4.45                     6                        0                95.17                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:39:02. Total running time: 5hr 2min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2342            1629.26   492086      4.35                     6                        1                97.26                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:39:32. Total running time: 5hr 3min 0s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2380            1658.38   500863      4.66                     6                        1                92.45                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:40:02. Total running time: 5hr 3min 30s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2416            1686.44   509358      4.69                     6                        0                92.98                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:40:32. Total running time: 5hr 4min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2455            1715.37   518083      4.43                     6                        0                94.18                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:41:02. Total running time: 5hr 4min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2494            1743.49   526590      4.4                      6                        0                96.36                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:41:32. Total running time: 5hr 5min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2533            1772.34   535325      4.62                     6                        1                93.41                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:42:02. Total running time: 5hr 5min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2570            1800.89   543916      4.68                     6                        2                92.06                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:42:32. Total running time: 5hr 6min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2608            1829.39   552479      4.78                     6                        1                91.5                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:43:02. Total running time: 5hr 6min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2646            1857.81   561061      4.78                     6                        0                90.86                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:43:32. Total running time: 5hr 7min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2684            1886.07   569633      4.63                     6                        0                91.94                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:44:02. Total running time: 5hr 7min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2720            1915.1    578398      4.98                     6                        1                91.68                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:44:32. Total running time: 5hr 8min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2757            1943.71   587053      4.82                     6                        2                90.59                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:45:02. Total running time: 5hr 8min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2793            1972.1    595632      4.64                     6                        1                89.55                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:45:32. Total running time: 5hr 9min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2831            2001      604319      4.9                      6                        2                90.91                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:46:02. Total running time: 5hr 9min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2870            2029.57   612985      4.79                     6                        2                89.07                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:46:32. Total running time: 5hr 10min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2906            2057.95   621517      4.94                     6                        2                89.93                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:47:02. Total running time: 5hr 10min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2944            2086.54   630149      4.66                     6                        2                94.53                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:47:33. Total running time: 5hr 11min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     2981            2115.39   638855      4.87                     6                        1                90.09                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:48:03. Total running time: 5hr 11min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3017            2144.05   647466      4.9                      6                        2                89.14                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:48:33. Total running time: 5hr 12min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3053            2172.41   656032      5.09                     6                        3                85.66                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:49:03. Total running time: 5hr 12min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3090            2201.01   664628      4.95                     6                        0                87.15                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:49:33. Total running time: 5hr 13min 1s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3125            2229.57   673270      4.95                     6                        2                91.4                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:50:03. Total running time: 5hr 13min 31s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3162            2258.1    681895      5.15                     6                        2                86.25                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:50:33. Total running time: 5hr 14min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3199            2287.02   690618      5.07                     6                        3                86.22                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:51:03. Total running time: 5hr 14min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3237            2315.97   699392      5.34                     6                        1                81.04                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:51:33. Total running time: 5hr 15min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3272            2344.45   707967      5.33                     6                        2                81.75                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:52:03. Total running time: 5hr 15min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3310            2372.94   716591      5.09                     6                        3                87.25                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:52:33. Total running time: 5hr 16min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3346            2401.41   725213      5.13                     6                        1                84.2                       4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:53:03. Total running time: 5hr 16min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3383            2430.19   733882      5.09                     6                        2                86.69                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:53:33. Total running time: 5hr 17min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3420            2458.75   742512      5.16                     6                        3                86.3                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:54:03. Total running time: 5hr 17min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3457            2487.19   751068      4.94                     6                        1                85.56                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:54:33. Total running time: 5hr 18min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3494            2516.08   759803      5.3                      6                        2                84.58                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:55:03. Total running time: 5hr 18min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3531            2545.15   768573      5.16                     6                        1                83.59                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:55:33. Total running time: 5hr 19min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3565            2573.44   777076      5.2                      6                        3                86.04                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:56:03. Total running time: 5hr 19min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3603            2602.24   785773      5.15                     6                        2                83.27                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:56:34. Total running time: 5hr 20min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3638            2630.78   794345      5.27                     6                        2                85.72                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:57:04. Total running time: 5hr 20min 32s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3674            2659.59   803035      5.28                     6                        2                83.26                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:57:34. Total running time: 5hr 21min 2s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3710            2688.56   811776      5.03                     6                        1                84.42                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:58:04. Total running time: 5hr 21min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3746            2716.93   820308      5.11                     6                        1                83.43                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:58:34. Total running time: 5hr 22min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3781            2745.56   828958      5.33                     6                        2                81.58                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:59:04. Total running time: 5hr 22min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3818            2774.94   837778      5.34                     6                        3                81.74                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 06:59:34. Total running time: 5hr 23min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3854            2803.2    846291      5.36                     6                        3                81.76                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:00:04. Total running time: 5hr 23min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3889            2832.01   854968      5.37                     6                        3                79.14                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:00:34. Total running time: 5hr 24min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3925            2860.85   863646      5.28                     6                        3                81.82                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:01:04. Total running time: 5hr 24min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3961            2889.45   872275      5.27                     6                        3                84.5                       3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:01:34. Total running time: 5hr 25min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     3996            2918.12   880888      5.35                     6                        2                83.04                      4 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:02:04. Total running time: 5hr 25min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     4032            2946.48   889439      5.36                     6                        2                81.82                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:02:34. Total running time: 5hr 26min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     4068            2975.38   898144      5.41                     6                        2                81.03                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:03:04. Total running time: 5hr 26min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     4104            3004      906764      5.48                     6                        2                80.94                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:03:34. Total running time: 5hr 27min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     4140            3032.93   915496      5.47                     6                        2                78.03                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 6 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:04:04. Total running time: 5hr 27min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00006   RUNNING      independent        type_1                     4175            3061.22   923983      5.4                      6                        2                83.19                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00006 completed after 4183 iterations at 2023-11-24 07:04:11. Total running time: 5hr 27min 40s
╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00006 result                                                         │
├─────────────────────────────────────────────────────────────────────────────────────────────┤
│ checkpoint_dir_name                                                                         │
│ episodes_total                                                                        10000 │
│ time_this_iter_s                                                                    0.97247 │
│ time_total_s                                                                     3067.09688 │
│ timesteps_total                                                                      925755 │
│ training_iteration                                                                     4183 │
│ agent_timesteps_total                                                               1851510 │
│ callback_ok                                                                            True │
│ connector_metrics/ObsPreprocessorConnector_ms                         0.0035914182662963867 │
│ connector_metrics/StateBufferConnector_ms                             0.0025829076766967773 │
│ connector_metrics/ViewRequirementAgentConnector_ms                      0.15537285804748535 │
│ counters/num_agent_steps_sampled                                                    1851510 │
│ counters/num_agent_steps_trained                                                          0 │
│ counters/num_env_steps_sampled                                                       925755 │
│ counters/num_env_steps_trained                                                            0 │
│ custom_metrics/assists_max                                                                0 │
│ custom_metrics/assists_mean                                                             0.0 │
│ custom_metrics/assists_min                                                                0 │
│ custom_metrics/kills_max                                                                  6 │
│ custom_metrics/kills_mean                                                               5.4 │
│ custom_metrics/kills_min                                                                  2 │
│ custom_metrics/predator_0_assists_max                                                     0 │
│ custom_metrics/predator_0_assists_mean                                                  0.0 │
│ custom_metrics/predator_0_assists_min                                                     0 │
│ custom_metrics/predator_0_kills_max                                                       6 │
│ custom_metrics/predator_0_kills_mean                                                   3.34 │
│ custom_metrics/predator_0_kills_min                                                       0 │
│ custom_metrics/predator_1_assists_max                                                     0 │
│ custom_metrics/predator_1_assists_mean                                                  0.0 │
│ custom_metrics/predator_1_assists_min                                                     0 │
│ custom_metrics/predator_1_kills_max                                                       5 │
│ custom_metrics/predator_1_kills_mean                                                   2.06 │
│ custom_metrics/predator_1_kills_min                                                       0 │
│ episode_len_mean                                                                      82.57 │
│ episode_reward_max                                                                       6. │
│ episode_reward_mean                                                                     5.4 │
│ episode_reward_min                                                                       2. │
│ episodes_this_iter                                                                        3 │
│ hist_stats/episode_lengths                                             ...42, 93, 101, 101] │
│ hist_stats/episode_reward                                              ...0, 6.0, 4.0, 5.0] │
│ hist_stats/policy_predator_0_reward                                    ...0, 5.0, 4.0, 4.0] │
│ hist_stats/policy_predator_1_reward                                    ...0, 1.0, 0.0, 1.0] │
│ info/learner/__all__/num_agent_steps_trained                                          256.0 │
│ info/learner/__all__/num_env_steps_trained                                            295.0 │
│ info/learner/__all__/total_loss                                          0.8520167494813601 │
│ info/learner/predator_0/curr_entropy_coeff                                              0.0 │
│ info/learner/predator_0/curr_kl_coeff                                                   0.0 │
│ info/learner/predator_0/curr_lr                                                      0.0001 │
│ info/learner/predator_0/default_optimizer_lr                                         0.0001 │
│ info/learner/predator_0/entropy                                          0.8775841395060221 │
│ info/learner/predator_0/mean_kl_loss                                 2.8832948280192266e-05 │
│ info/learner/predator_0/policy_loss                                    -0.04132643652458986 │
│ info/learner/predator_0/total_loss                                       0.8520167494813601 │
│ info/learner/predator_0/vf_explained_var                                 0.1458746393521627 │
│ info/learner/predator_0/vf_loss                                          0.6698421264688174 │
│ info/learner/predator_0/vf_loss_unclipped                                0.6698421264688174 │
│ info/learner/predator_1/curr_entropy_coeff                                              0.0 │
│ info/learner/predator_1/curr_kl_coeff                                                   0.0 │
│ info/learner/predator_1/curr_lr                                                      0.0001 │
│ info/learner/predator_1/default_optimizer_lr                                         0.0001 │
│ info/learner/predator_1/entropy                                          1.3241101106007893 │
│ info/learner/predator_1/mean_kl_loss                                 2.8584270983363542e-05 │
│ info/learner/predator_1/policy_loss                                    0.019756610194842022 │
│ info/learner/predator_1/total_loss                                      0.22350107443829378 │
│ info/learner/predator_1/vf_explained_var                               -0.46953855951627094 │
│ info/learner/predator_1/vf_loss                                         0.20374445989727974 │
│ info/learner/predator_1/vf_loss_unclipped                               0.20374445989727974 │
│ info/num_agent_steps_sampled                                                        1851510 │
│ info/num_agent_steps_trained                                                              0 │
│ info/num_env_steps_sampled                                                           925755 │
│ info/num_env_steps_trained                                                                0 │
│ num_agent_steps_sampled                                                             1851510 │
│ num_agent_steps_trained                                                                   0 │
│ num_env_steps_sampled                                                                925755 │
│ num_env_steps_sampled_this_iter                                                         295 │
│ num_env_steps_sampled_throughput_per_sec                                          304.54101 │
│ num_env_steps_trained                                                                     0 │
│ num_env_steps_trained_this_iter                                                           0 │
│ num_env_steps_trained_throughput_per_sec                                                 0. │
│ num_faulty_episodes                                                                       0 │
│ num_healthy_workers                                                                       0 │
│ num_in_flight_async_reqs                                                                  0 │
│ num_remote_worker_restarts                                                                0 │
│ num_steps_trained_this_iter                                                               0 │
│ perf/cpu_util_percent                                                                   3.4 │
│ perf/ram_util_percent                                                                  24.0 │
│ policy_reward_max/predator_0                                                            6.0 │
│ policy_reward_max/predator_1                                                            5.0 │
│ policy_reward_mean/predator_0                                                          3.34 │
│ policy_reward_mean/predator_1                                                          2.06 │
│ policy_reward_min/predator_0                                                            0.0 │
│ policy_reward_min/predator_1                                                            0.0 │
│ sampler_perf/mean_action_processing_ms                                  0.14408934431909337 │
│ sampler_perf/mean_env_render_ms                                                         0.0 │
│ sampler_perf/mean_env_wait_ms                                           0.10741311454249798 │
│ sampler_perf/mean_inference_ms                                           2.1780113564510635 │
│ sampler_perf/mean_raw_obs_processing_ms                                  0.5737224378424055 │
│ sampler_results/connector_metrics/ObsPreprocessorConnector_ms         0.0035914182662963867 │
│ sampler_results/connector_metrics/StateBufferConnector_ms             0.0025829076766967773 │
│ sampler_results/connector_metrics/ViewRequirementAgentConnector_ms      0.15537285804748535 │
│ sampler_results/custom_metrics/assists_max                                                0 │
│ sampler_results/custom_metrics/assists_mean                                             0.0 │
│ sampler_results/custom_metrics/assists_min                                                0 │
│ sampler_results/custom_metrics/kills_max                                                  6 │
│ sampler_results/custom_metrics/kills_mean                                               5.4 │
│ sampler_results/custom_metrics/kills_min                                                  2 │
│ sampler_results/custom_metrics/predator_0_assists_max                                     0 │
│ sampler_results/custom_metrics/predator_0_assists_mean                                  0.0 │
│ sampler_results/custom_metrics/predator_0_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_0_kills_max                                       6 │
│ sampler_results/custom_metrics/predator_0_kills_mean                                   3.34 │
│ sampler_results/custom_metrics/predator_0_kills_min                                       0 │
│ sampler_results/custom_metrics/predator_1_assists_max                                     0 │
│ sampler_results/custom_metrics/predator_1_assists_mean                                  0.0 │
│ sampler_results/custom_metrics/predator_1_assists_min                                     0 │
│ sampler_results/custom_metrics/predator_1_kills_max                                       5 │
│ sampler_results/custom_metrics/predator_1_kills_mean                                   2.06 │
│ sampler_results/custom_metrics/predator_1_kills_min                                       0 │
│ sampler_results/episode_len_mean                                                      82.57 │
│ sampler_results/episode_reward_max                                                      6.0 │
│ sampler_results/episode_reward_mean                                                     5.4 │
│ sampler_results/episode_reward_min                                                      2.0 │
│ sampler_results/episodes_this_iter                                                        3 │
│ sampler_results/hist_stats/episode_lengths                             ...42, 93, 101, 101] │
│ sampler_results/hist_stats/episode_reward                              ...0, 6.0, 4.0, 5.0] │
│ sampler_results/hist_stats/policy_predator_0_reward                    ...0, 5.0, 4.0, 4.0] │
│ sampler_results/hist_stats/policy_predator_1_reward                    ...0, 1.0, 0.0, 1.0] │
│ sampler_results/num_faulty_episodes                                                       0 │
│ sampler_results/policy_reward_max/predator_0                                            6.0 │
│ sampler_results/policy_reward_max/predator_1                                            5.0 │
│ sampler_results/policy_reward_mean/predator_0                                          3.34 │
│ sampler_results/policy_reward_mean/predator_1                                          2.06 │
│ sampler_results/policy_reward_min/predator_0                                            0.0 │
│ sampler_results/policy_reward_min/predator_1                                            0.0 │
│ sampler_results/sampler_perf/mean_action_processing_ms                  0.14408934431909337 │
│ sampler_results/sampler_perf/mean_env_render_ms                                         0.0 │
│ sampler_results/sampler_perf/mean_env_wait_ms                           0.10741311454249798 │
│ sampler_results/sampler_perf/mean_inference_ms                           2.1780113564510635 │
│ sampler_results/sampler_perf/mean_raw_obs_processing_ms                  0.5737224378424055 │
│ timers/sample_time_ms                                                               675.979 │
│ timers/synch_weights_time_ms                                                          0.905 │
│ timers/training_iteration_time_ms                                                   738.983 │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_algo_b179f_00007 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_b179f_00007 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                        shared │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   100 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14e86ab82cb0> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 2]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                              128 │
│ training/train_batch_size                                200 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                 1 │
│ tune/max_episodes                                      10000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib4 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:04:34. Total running time: 5hr 28min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                       42             19.751     8484    1.84524                    5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383    4.77                       6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955    5.63                       6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249    4.835                      7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679    5.775                      8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027    4.93                       9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442    6.39                      14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755    5.4                        6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:05:04. Total running time: 5hr 28min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      101            47.5697    20402      1.81                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895          2052.84     874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183          3067.1      925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:05:34. Total running time: 5hr 29min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      160            75.6483    32320      1.91                     4                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429          3201.65     959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700          1959.18     835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427          3171.93     960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655          1938.4      825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493          3191.3      966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895          2052.84     874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183          3067.1      925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:06:05. Total running time: 5hr 29min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      220            104.097    44440      1.99                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:06:35. Total running time: 5hr 30min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      279            132.161    56358      2.09                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:07:05. Total running time: 5hr 30min 33s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      338             160.12    68276      2.26                     5                        0               101                         2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183            3067.1    925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:07:35. Total running time: 5hr 31min 3s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      397            188.258    80269      2.89                     6                        0               100.74                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:08:05. Total running time: 5hr 31min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      455             215.99    92060      2.71                     6                        0               100.74                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429            3201.65   959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700            1959.18   835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427            3171.93   960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655            1938.4    825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493            3191.3    966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895            2052.84   874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183            3067.1    925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:08:35. Total running time: 5hr 32min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      514            244.233   104139      3                        6                        0               100.59                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:09:05. Total running time: 5hr 32min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      571            272.052   115983      3.05                     6                        0                99.25                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:09:35. Total running time: 5hr 33min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      628            300.147   127930      3.53                     6                        0                99.6                       2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:10:05. Total running time: 5hr 33min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      686            328.407   140008      3.59                     6                        1                99.57                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:10:35. Total running time: 5hr 34min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      741            356.714   152050      3.74                     6                        1                96.22                      3 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:11:05. Total running time: 5hr 34min 34s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      798            384.918   164072      3.77                     6                        0                97.49                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 7 TERMINATED | 1 RUNNING
Current time: 2023-11-24 07:11:35. Total running time: 5hr 35min 4s
Logical resource usage: 1.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: b179f_00001 with episode_len_mean=68.66 and params={'algorithm_type': 'shared', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 10000, 'max_concurrent_trials': 1}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 128, 'num_sgd_iter': 5, 'train_batch_size': 200, 'model': {'conv_filters': [[16, [3, 3], 2]], 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_activation': 'relu'}}, 'evaluate': {'eval_episodes': 100}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib4', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x14d888c6a710>}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status       algorithm_type     ...onfig/reward_type       iter     total time (s)       ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_b179f_00007   RUNNING      shared             type_1                      852            413.099   176074      4.07                     6                        0                96.73                      2 │
│ train_algo_b179f_00000   TERMINATED   independent        type_1                     4429           3201.65    959383      4.77                     6                        2                90.93                      3 │
│ train_algo_b179f_00001   TERMINATED   shared             type_1                     3700           1959.18    835955      5.63                     6                        3                68.66                      4 │
│ train_algo_b179f_00002   TERMINATED   independent        type_2                     4427           3171.93    960249      4.835                    7                        2                90.87                      3 │
│ train_algo_b179f_00003   TERMINATED   shared             type_2                     3655           1938.4     825679      5.775                    8.5                      3                70.79                      3 │
│ train_algo_b179f_00004   TERMINATED   independent        type_3                     4493           3191.3     966027      4.93                     9                        1                88.56                      2 │
│ train_algo_b179f_00005   TERMINATED   shared             type_3                     3895           2052.84    874442      6.39                    14                        3                70.53                      3 │
│ train_algo_b179f_00006   TERMINATED   independent        type_1                     4183           3067.1     925755      5.4                      6                        2                82.57                      3 │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 254, in <module>
    main()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 248, in main
    results = tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 364, in fit
    return self._local_tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 526, in fit
    analysis = self._fit_internal(trainable, param_space)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 645, in _fit_internal
    analysis = run(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tune.py", line 1007, in run
    runner.step()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 747, in step
    raise e
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 744, in step
    self.checkpoint()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 481, in checkpoint
    self._checkpoint_manager.checkpoint(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/experiment_state.py", line 228, in checkpoint
    save_fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 376, in save_to_dir
    with open(tmp_file_name, "w") as f:
OSError: [Errno 122] Disk quota exceeded
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 254, in <module>
    main()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 248, in main
    results = tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 364, in fit
    return self._local_tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 526, in fit
    analysis = self._fit_internal(trainable, param_space)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 645, in _fit_internal
    analysis = run(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tune.py", line 1007, in run
    runner.step()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 747, in step
    raise e
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 744, in step
    self.checkpoint()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 481, in checkpoint
    self._checkpoint_manager.checkpoint(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/experiment_state.py", line 228, in checkpoint
    save_fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 376, in save_to_dir
    with open(tmp_file_name, "w") as f:
OSError: [Errno 122] Disk quota exceeded
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x14d88758c550>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 122] Disk quota exceeded
wandb: 
wandb: Run history:
wandb:      episode_len_mean ███████████████████████▇▇█▅▄▅▇▇▆▄▄▁▁▃▁▂▂
wandb:   episode_reward_mean ▁▁▁▂▁▁▁▂▂▁▂▂▂▃▂▃▄▄▅▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███
wandb:        episodes_total ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_sampled ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb: num_env_steps_trained ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          time_total_s ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:    training_iteration ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:      episode_len_mean 96.85
wandb:   episode_reward_mean 3.98
wandb:        episodes_total 1811
wandb: num_env_steps_sampled 180723
wandb: num_env_steps_trained 0
wandb:          time_total_s 424.01481
wandb:    training_iteration 873
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/offline-run-20231124_070411-aiuvtg2b
wandb: Find logs at: ./wandb/offline-run-20231124_070411-aiuvtg2b/logs
Job ID           : 53748013
Cluster          : spartan
User/Project     : dalmiapriyam/punim1355
Nodes            : 1
Wall-clock time  : 05:35:30 / 20:00:00

Displaying overall resources usage from 2023-11-24 01:36:22 to 2023-11-24 07:11:52:

NODE            CPU#        TOT%   ( USR   / SYS   / WIO   / IDLE  ) 

spartan-gpgpu091 : 
                CPU# 1    : 1.8    (   0.9 /   0.9 /   0.0 /  81.4 ) 
                CPU# 2    : 1.8    (   0.9 /   0.9 /   0.0 /  82.2 ) 
                CPU# 3    : 1.8    (   0.9 /   0.9 /   0.0 /  82.3 ) 
                CPU# 4    : 1.8    (   0.9 /   0.9 /   0.0 /  81.5 ) 
                CPU# 5    : 1.8    (   0.9 /   0.9 /   0.0 /  82.3 ) 
                CPU# 6    : 1.7    (   0.9 /   0.8 /   0.0 /  81.4 ) 

                GPU# 1    : 0.0   


Allocated CPUs            : 6    
  CPUs with usage <25%    : 6    
  CPUs with usage <50%    : 0    
  CPUs with usage >50%    : 0    


Allocated GPUs            : 1    
  GPUs with usage <25%    : 1    
  GPUs with usage <50%    : 0    
  GPUs with usage >50%    : 0    

Memory used (RAM)         : 15.5%  [3901MB of 25166MB]

--------------------------------------------

