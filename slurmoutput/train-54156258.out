
Name of the cluster on which the job is executing:	 spartan
Number of CPUs on the allocated node: 	 32
Number of CPUs requested per task: 	 32
Numer of GPUs requested: 	 
Requested GPU count per allocated node: 	 
Requested GPU count per allocated task:	  
The ID of the job allocation:	  54156258
Count of processors available to the job on this node:	  32
Name of the job:	  tst.slurm
List of nodes allocated to the job:	  spartan-gpgpu095
Total number of nodes in the job’s resource allocation:	  1
Name of the partition in which the job is running:	  deeplearn
Minimum memory required per allocated CPU:	  4000
Requested memory per allocated GPU:	  
Total amount of memory per node that the job needs:	  
List of nodes allocated to the job:	  spartan-gpgpu095
Total number of CPUs allocated:	  1
Maximum number of MPI tasks (that’s processes): 	 1
Number of tasks requested per core: 	 
Number of tasks requested per GPU: 	 
Number of tasks requested per node:	  1
The scheduling priority (nice value) at the time of job submission. This value is propagated to the spawned processes: 	 0
The MPI rank (or relative process ID) of the current process: 	 0

The directory from which SBATCH was invoked: 	 /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey
The Hostname of the computer from which SBATCH was invoked: 	 spartan-login3.hpc.unimelb.edu.au
The process ID of the corresponding task: 	 111038



 LOADING MODULES: 




 PYTHON SCRIPT OUTPUT: 

rm: cannot remove '/home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-44-36': Directory not empty
2023-12-06 22:45:31,802	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
2023-12-06 22:45:34,034	INFO worker.py:1673 -- Started a local Ray instance.
2023-12-06 22:45:34,678	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.
2023-12-06 22:45:34,680	INFO tune.py:595 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
[36m(pid=113165)[0m 2023-12-06 22:45:50,118	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.
[36m(train_algo pid=113175)[0m 2023-12-06 22:45:51,081	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=113175)[0m 2023-12-06 22:45:51,081	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=113168)[0m 2023-12-06 22:45:51,648	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=113168)[0m wandb: Currently logged in as: theputernerdai (tpn). Use `wandb login --relogin` to force relogin
[36m(train_algo pid=113169)[0m wandb: wandb version 0.16.1 is available!  To upgrade, please run:
[36m(train_algo pid=113169)[0m wandb:  $ pip install wandb --upgrade
[36m(train_algo pid=113169)[0m wandb: Tracking run with wandb version 0.16.0
[36m(train_algo pid=113169)[0m wandb: Run data is saved locally in /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/wandb/run-20231206_224553-xl3ok34e
[36m(train_algo pid=113169)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(train_algo pid=113169)[0m wandb: Syncing run df1701914092
[36m(train_algo pid=113169)[0m wandb: ⭐️ View project at https://wandb.ai/tpn/rllib5
[36m(train_algo pid=113169)[0m wandb: 🚀 View run at https://wandb.ai/tpn/rllib5/runs/xl3ok34e
[36m(train_algo pid=113169)[0m 2023-12-06 22:45:55,231	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.train_one_step` has been deprecated. This will raise an error in the future!
[36m(train_algo pid=113169)[0m 2023-12-06 22:45:55,232	WARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!
[36m(pid=113193)[0m 2023-12-06 22:45:51,854	WARNING __init__.py:10 -- PG has/have been moved to `rllib_contrib` and will no longer be maintained by the RLlib team. You can still use it/them normally inside RLlib util Ray 2.8, but from Ray 2.9 on, all `rllib_contrib` algorithms will no longer be part of the core repo, and will therefore have to be installed separately with pinned dependencies for e.g. ray[rllib] and other packages! See https://github.com/ray-project/ray/tree/master/rllib_contrib#rllib-contrib for more information on the RLlib contrib effort.[32m [repeated 31x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(train_algo pid=113193)[0m 2023-12-06 22:45:52,779	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.tf.recurrent_net.LSTMWrapper` has been deprecated. This will raise an error in the future![32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m 2023-12-06 22:45:52,779	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.visionnet.VisionNetwork` has been deprecated. This will raise an error in the future![32m [repeated 31x across cluster][0m
2023-12-06 22:48:20,422	ERROR tune_controller.py:1383 -- Trial task failed for trial train_algo_f7801_00012
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=113181, ip=172.26.92.196, actor_id=8de5d2bfd582fa166639317c01000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 115, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 226, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 116] Stale file handle
╭───────────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_algo_2023-12-06_22-45-31   │
├───────────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator            │
│ Scheduler                        FIFOScheduler                    │
│ Number of trials                 92160                            │
╰───────────────────────────────────────────────────────────────────╯

View detailed results here: /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/experiments/train_algo_2023-12-06_22-45-31
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-45-31`

Trial status: 32 PENDING
Current time: 2023-12-06 22:45:43. Total running time: 8s
Logical resource usage: 32.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_f7801_00000   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10 │
│ train_algo_f7801_00001   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10 │
│ train_algo_f7801_00002   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10 │
│ train_algo_f7801_00003   PENDING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10 │
│ train_algo_f7801_00004   PENDING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
27 more PENDING

Trial train_algo_f7801_00016 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00016 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00008 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00008 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00020 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00020 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00012 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00012 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00029 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00029 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00026 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00026 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00000 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00000 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00027 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00027 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00022 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00022 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00009 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00009 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00015 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00015 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00003 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00003 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00019 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00019 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00013 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00013 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00001 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00001 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00031 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00031 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00018 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00018 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00010 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00010 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00030 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00030 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00006 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00006 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00017 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00017 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00023 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00023 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00002 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00002 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00024 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00024 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00021 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00021 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00025 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00025 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00004 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00004 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00007 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00007 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00011 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00011 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         relu │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00005 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00005 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          tanh │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [256, 256] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00028 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00028 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [3, 3], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             64 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial train_algo_f7801_00014 started with configuration:
╭──────────────────────────────────────────────────────────────╮
│ Trial train_algo_f7801_00014 config                          │
├──────────────────────────────────────────────────────────────┤
│ algorithm_class                                          ppo │
│ algorithm_type                                   independent │
│ analysis/analysis                                      False │
│ analysis/ccm_E                                             4 │
│ analysis/ccm_tau                                           1 │
│ analysis/dimensions                     ...'PCA_1', 'PCA_2'] │
│ analysis/length_fac                                      500 │
│ analysis/num_trials                                        5 │
│ analysis/policy_set                     ...ginal', '_fixed'] │
│ analysis/pref_ccm_analysis                              True │
│ analysis/pref_granger_analysis                         False │
│ analysis/pref_graph_analysis                           False │
│ analysis/pref_spatial_ccm_analysis                     False │
│ env_config/map_size                                       15 │
│ env_config/max_cycles                                    100 │
│ env_config/npred                                           2 │
│ env_config/nprey                                           6 │
│ env_config/pred_vision                                     2 │
│ env_config/prey_type                                  static │
│ env_config/reward_type                                type_1 │
│ env_name                                      discrete_pp_v1 │
│ evaluate/eval_episodes                                   500 │
│ framework                                              torch │
│ ray/init_dashboard                                     False │
│ rollouts/batch_mode                        complete_episodes │
│ rollouts/num_rollout_workers                               0 │
│ stop_fn                                 ...t 0x14801d9b2e60> │
│ training/lr                                           0.0001 │
│ training/model/conv_activation                          relu │
│ training/model/conv_filters                [[16, [2, 2], 1]] │
│ training/model/fcnet_activation                         tanh │
│ training/model/fcnet_hiddens                      [512, 512] │
│ training/model/lstm_cell_size                             32 │
│ training/model/lstm_use_prev_action                     True │
│ training/model/lstm_use_prev_reward                     True │
│ training/model/max_seq_len                                10 │
│ training/model/use_lstm                                 True │
│ training/num_sgd_iter                                      5 │
│ training/sgd_minibatch_size                               64 │
│ training/train_batch_size                                256 │
│ training/use_critic                                     True │
│ training/use_kl_loss                                    True │
│ tune/max_concurrent_trials                                32 │
│ tune/max_episodes                                      25000 │
│ tune/num_samples                                           5 │
│ tune/tune                                               True │
│ wandb/wandb_dir_path                    ...edator-prey/wandb │
│ wandb/wandb_entity                                       tpn │
│ wandb/wandb_init                                        True │
│ wandb/wandb_log_freq                                      50 │
│ wandb/wandb_notes                              testing setup │
│ wandb/wandb_project                                   rllib5 │
╰──────────────────────────────────────────────────────────────╯

Trial status: 32 RUNNING
Current time: 2023-12-06 22:46:13. Total running time: 38s
Logical resource usage: 32.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: f7801_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 25000, 'max_concurrent_trials': 32}, 'analysis': {'num_trials': 5, 'analysis': False, 'policy_set': ['original', '_fixed'], 'dimensions': ['dx', 'dy', 'PCA_1', 'PCA_2'], 'length_fac': 500, 'ccm_tau': 1, 'ccm_E': 4, 'pref_ccm_analysis': True, 'pref_granger_analysis': False, 'pref_graph_analysis': False, 'pref_spatial_ccm_analysis': False}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'train_batch_size': 256, 'model': {'use_lstm': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_filters': [[16, [3, 3], 1]], 'lstm_use_prev_reward': True, 'lstm_use_prev_action': True, 'conv_activation': 'relu', 'lstm_cell_size': 32, 'max_seq_len': 10}}, 'evaluate': {'eval_episodes': 500}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib5', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup', 'wandb_log_freq': 50, 'wandb_dir_path': '/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x146f40fc0ca0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len     iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_f7801_00000   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       12            16.5969   3636    1.16667                      4                      0                  101                      3 │
│ train_algo_f7801_00001   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10       12            16.7057   3636    1.11111                      4                      0                  101                      3 │
│ train_algo_f7801_00002   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10       12            17.3891   3636    1.16667                      4                      0                  101                      3 │
│ train_algo_f7801_00003   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10       12            16.5338   3636    1.41667                      4                      0                  101                      3 │
│ train_algo_f7801_00004   RUNNING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       12            16.4697   3636    1.47222                      4                      0                  101                      3 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
27 more RUNNING
Trial status: 32 RUNNING
Current time: 2023-12-06 22:46:43. Total running time: 1min 8s
Logical resource usage: 32.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: f7801_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 25000, 'max_concurrent_trials': 32}, 'analysis': {'num_trials': 5, 'analysis': False, 'policy_set': ['original', '_fixed'], 'dimensions': ['dx', 'dy', 'PCA_1', 'PCA_2'], 'length_fac': 500, 'ccm_tau': 1, 'ccm_E': 4, 'pref_ccm_analysis': True, 'pref_granger_analysis': False, 'pref_graph_analysis': False, 'pref_spatial_ccm_analysis': False}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'train_batch_size': 256, 'model': {'use_lstm': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_filters': [[16, [3, 3], 1]], 'lstm_use_prev_reward': True, 'lstm_use_prev_action': True, 'conv_activation': 'relu', 'lstm_cell_size': 32, 'max_seq_len': 10}}, 'evaluate': {'eval_episodes': 500}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib5', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup', 'wandb_log_freq': 50, 'wandb_dir_path': '/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x146f40b47be0>}
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len     iter     total time (s)     ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_f7801_00000   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       32            44.6606   9696    1.33333                      4                      0                  101                      3 │
│ train_algo_f7801_00001   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10       32            44.9692   9696    1.19792                      4                      0                  101                      3 │
│ train_algo_f7801_00002   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10       30            42.9756   9090    1.35556                      4                      0                  101                      3 │
│ train_algo_f7801_00003   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10       32            44.4936   9696    1.39583                      4                      0                  101                      3 │
│ train_algo_f7801_00004   RUNNING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       32            44.1449   9696    1.375                        4                      0                  101                      3 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
27 more RUNNING
Trial status: 32 RUNNING
Current time: 2023-12-06 22:47:13. Total running time: 1min 38s
Logical resource usage: 32.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: f7801_00000 with episode_len_mean=101.0 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 25000, 'max_concurrent_trials': 32}, 'analysis': {'num_trials': 5, 'analysis': False, 'policy_set': ['original', '_fixed'], 'dimensions': ['dx', 'dy', 'PCA_1', 'PCA_2'], 'length_fac': 500, 'ccm_tau': 1, 'ccm_E': 4, 'pref_ccm_analysis': True, 'pref_granger_analysis': False, 'pref_graph_analysis': False, 'pref_spatial_ccm_analysis': False}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'train_batch_size': 256, 'model': {'use_lstm': True, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'conv_filters': [[16, [3, 3], 1]], 'lstm_use_prev_reward': True, 'lstm_use_prev_action': True, 'conv_activation': 'relu', 'lstm_cell_size': 32, 'max_seq_len': 10}}, 'evaluate': {'eval_episodes': 500}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib5', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup', 'wandb_log_freq': 50, 'wandb_dir_path': '/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x1481a32f8b80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len     iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_f7801_00000   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       51            71.7209   15453       1.32                      4                      0                  101                      3 │
│ train_algo_f7801_00001   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10       51            72.2683   15453       1.18                      3                      0                  101                      3 │
│ train_algo_f7801_00002   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10       50            71.553    15150       1.48                      4                      0                  101                      3 │
│ train_algo_f7801_00003   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10       51            71.2402   15453       1.38                      3                      0                  101                      3 │
│ train_algo_f7801_00004   RUNNING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       52            71.9159   15756       1.5                       4                      0                  101                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
27 more RUNNING
Trial status: 32 RUNNING
Current time: 2023-12-06 22:47:43. Total running time: 2min 8s
Logical resource usage: 32.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: f7801_00030 with episode_len_mean=100.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 25000, 'max_concurrent_trials': 32}, 'analysis': {'num_trials': 5, 'analysis': False, 'policy_set': ['original', '_fixed'], 'dimensions': ['dx', 'dy', 'PCA_1', 'PCA_2'], 'length_fac': 500, 'ccm_tau': 1, 'ccm_E': 4, 'pref_ccm_analysis': True, 'pref_granger_analysis': False, 'pref_graph_analysis': False, 'pref_spatial_ccm_analysis': False}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'train_batch_size': 256, 'model': {'use_lstm': True, 'fcnet_hiddens': [512, 512], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [2, 2], 1]], 'lstm_use_prev_reward': True, 'lstm_use_prev_action': True, 'conv_activation': 'relu', 'lstm_cell_size': 64, 'max_seq_len': 10}}, 'evaluate': {'eval_episodes': 500}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib5', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup', 'wandb_log_freq': 50, 'wandb_dir_path': '/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x146f40f25000>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len     iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_f7801_00000   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       71            99.5125   21513       1.15                      4                      0                  101                      3 │
│ train_algo_f7801_00001   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10       71           101.176    21513       1.43                      4                      0                  101                      3 │
│ train_algo_f7801_00002   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10       69            98.2459   20907       1.34                      4                      0                  101                      3 │
│ train_algo_f7801_00003   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10       71            99.276    21513       1.37                      5                      0                  101                      3 │
│ train_algo_f7801_00004   RUNNING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       72            99.5992   21816       1.45                      4                      0                  101                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
27 more RUNNING
Trial status: 32 RUNNING
Current time: 2023-12-06 22:48:13. Total running time: 2min 39s
Logical resource usage: 32.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: f7801_00030 with episode_len_mean=100.93 and params={'algorithm_type': 'independent', 'algorithm_class': 'ppo', 'framework': 'torch', 'tune': {'tune': True, 'num_samples': 5, 'max_episodes': 25000, 'max_concurrent_trials': 32}, 'analysis': {'num_trials': 5, 'analysis': False, 'policy_set': ['original', '_fixed'], 'dimensions': ['dx', 'dy', 'PCA_1', 'PCA_2'], 'length_fac': 500, 'ccm_tau': 1, 'ccm_E': 4, 'pref_ccm_analysis': True, 'pref_granger_analysis': False, 'pref_graph_analysis': False, 'pref_spatial_ccm_analysis': False}, 'training': {'lr': 0.0001, 'use_critic': True, 'use_kl_loss': True, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'train_batch_size': 256, 'model': {'use_lstm': True, 'fcnet_hiddens': [512, 512], 'fcnet_activation': 'tanh', 'conv_filters': [[16, [2, 2], 1]], 'lstm_use_prev_reward': True, 'lstm_use_prev_action': True, 'conv_activation': 'relu', 'lstm_cell_size': 64, 'max_seq_len': 10}}, 'evaluate': {'eval_episodes': 500}, 'rollouts': {'num_rollout_workers': 0, 'batch_mode': 'complete_episodes'}, 'wandb': {'wandb_init': True, 'wandb_project': 'rllib5', 'wandb_entity': 'tpn', 'wandb_notes': 'testing setup', 'wandb_log_freq': 50, 'wandb_dir_path': '/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb'}, 'env_name': 'discrete_pp_v1', 'env_config': {'map_size': 15, 'pred_vision': 2, 'prey_type': 'static', 'max_cycles': 100, 'npred': 2, 'nprey': 6, 'reward_type': 'type_1'}, 'ray': {'init_dashboard': False}, 'stop_fn': <function main.<locals>.stop_fn at 0x146f410b1d80>}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name               status     training/use_kl_loss       ...gd_minibatch_size     ...ning/num_sgd_iter     .../train_batch_size   ...ng/model/use_lstm     ...del/fcnet_hiddens     .../fcnet_activation     ...odel/conv_filters     ...m_use_prev_reward     ...m_use_prev_action     ...l/conv_activation       ...el/lstm_cell_size     ...model/max_seq_len     iter     total time (s)      ts     reward     episode_reward_max     episode_reward_min     episode_len_mean     episodes_this_iter │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_algo_f7801_00000   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       91            127.569   27573       1.26                      5                      0                  101                      3 │
│ train_algo_f7801_00001   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [3, 3], 1]]        True                     True                     tanh                                         32                       10       91            129.36    27573       1.2                       4                      0                  101                      3 │
│ train_algo_f7801_00002   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     relu                                         32                       10       88            125.611   26664       1.36                      4                      0                  101                      3 │
│ train_algo_f7801_00003   RUNNING    True                                         64                        5                      256   True                     [256, 256]               relu                     [[16, [2, 2], 1]]        True                     True                     tanh                                         32                       10       91            127.14    27573       1.58                      5                      0                  101                      3 │
│ train_algo_f7801_00004   RUNNING    True                                         64                        5                      256   True                     [256, 256]               tanh                     [[16, [3, 3], 1]]        True                     True                     relu                                         32                       10       92            127.217   27876       1.51                      4                      0                  101                      3 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
27 more RUNNING

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=113181, ip=172.26.92.196, actor_id=8de5d2bfd582fa166639317c01000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 115, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 226, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 116] Stale file handle

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1297, in _on_error
    on_error(trial, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1384, in _trial_task_failure
    self._process_trial_failure(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1406, in _process_trial_failure
    self._schedule_trial_stop(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1432, in _schedule_trial_stop
    trial.handle_error(exc=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/experiment/trial.py", line 741, in handle_error
    with open(self.pickled_error_file, "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-45-31/train_algo_f7801_00012_12_conv_activation=relu,conv_filters=16_3_3_1,fcnet_activation=tanh,fcnet_hiddens=512_512,lstm_cell_size=32_2023-12-06_22-45-42/error.pkl'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 364, in fit
    return self._local_tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 526, in fit
    analysis = self._fit_internal(trainable, param_space)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py", line 645, in _fit_internal
    analysis = run(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tune.py", line 1007, in run
    runner.step()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 731, in step
    if not self._actor_manager.next(timeout=0.1):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 224, in next
    self._actor_task_events.resolve_future(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 113, in resolve_future
    on_error(e)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 770, in on_error
    self._actor_task_failed(
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py", line 289, in _actor_task_failed
    tracked_actor_task._on_error(tracked_actor, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1306, in _on_error
    raise TuneError(traceback.format_exc())
ray.tune.error.TuneError: Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2563, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OSError): [36mray::ImplicitFunc.train()[39m (pid=113181, ip=172.26.92.196, actor_id=8de5d2bfd582fa166639317c01000000, repr=train_algo)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/air/_internal/util.py", line 91, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 115, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 226, in train_algo
    results = algo.train()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 397, in train
    self.log_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2170, in log_result
    Trainable.log_result(self, result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 970, in log_result
    self._result_logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/unified.py", line 62, in on_result
    _logger.on_result(result)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/logger/json.py", line 50, in on_result
    self.local_out.flush()
OSError: [Errno 116] Stale file handle

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1297, in _on_error
    on_error(trial, exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1384, in _trial_task_failure
    self._process_trial_failure(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1406, in _process_trial_failure
    self._schedule_trial_stop(trial, exception=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py", line 1432, in _schedule_trial_stop
    trial.handle_error(exc=exception)
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/experiment/trial.py", line 741, in handle_error
    with open(self.pickled_error_file, "wb") as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-45-31/train_algo_f7801_00012_12_conv_activation=relu,conv_filters=16_3_3_1,fcnet_activation=tanh,fcnet_hiddens=512_512,lstm_cell_size=32_2023-12-06_22-45-42/error.pkl'


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 396, in <module>
    main()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/./train.py", line 363, in main
    results = tuner.fit()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/ray/tune/tuner.py", line 366, in fit
    raise TuneError(
ray.tune.error.TuneError: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore("/home/dalmiapriyam/ray_results/train_algo_2023-12-06_22-45-31", trainable=...)`.
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415c5120>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f40b45d80>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f40b45750>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f40b45120>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163d3f0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f40b44dc0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f40b44790>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f40b44160>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415c5ea0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41533d90>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41533760>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41533130>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415c48b0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41532e60>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41532830>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41532170>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163e560>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41531ea0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415317e0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415311b0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415c45e0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41530e50>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f41530820>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415301f0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163c040>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163e8c0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163d630>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163e4d0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163e680>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f415c53f0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163fe20>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
Exception ignored in atexit callback: <function FileWriter.__init__.<locals>.cleanup at 0x146f4163d5a0>
Traceback (most recent call last):
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/writer.py", line 108, in cleanup
    self.event_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 158, in close
    self._ev_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/event_file_writer.py", line 76, in close
    self._py_recordio_writer.close()
  File "/data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/.venv/lib/python3.10/site-packages/tensorboardX/record_writer.py", line 196, in close
    self._writer.close()
OSError: [Errno 116] Stale file handle
[36m(train_algo pid=113193)[0m 2023-12-06 22:45:53,035	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.recurrent_net.RecurrentNetwork` has been deprecated. This will raise an error in the future![32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: Currently logged in as: theputernerdai (tpn). Use `wandb login --relogin` to force relogin[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: wandb version 0.16.1 is available!  To upgrade, please run:[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb:  $ pip install wandb --upgrade[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: Tracking run with wandb version 0.16.0[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: Run data is saved locally in /data/gpfs/projects/punim1355/dalmiapriyam/predator-prey/wandb/wandb/run-20231206_224554-8wnx3nqi[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: Run `wandb offline` to turn off syncing.[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: Syncing run df1701938881[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: ⭐️ View project at https://wandb.ai/tpn/rllib5[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m wandb: 🚀 View run at https://wandb.ai/tpn/rllib5/runs/8wnx3nqi[32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m 2023-12-06 22:45:56,298	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.train_one_step` has been deprecated. This will raise an error in the future![32m [repeated 31x across cluster][0m
[36m(train_algo pid=113193)[0m 2023-12-06 22:45:56,300	WARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future![32m [repeated 31x across cluster][0m
Job ID           : 54156258
Cluster          : spartan
User/Project     : dalmiapriyam/punim1355
Nodes            : 1
Wall-clock time  : 00:03:12 / 1-00:00:00

Displaying overall resources usage from 2023-12-06 22:45:17 to 2023-12-06 22:48:29:

NODE            CPU#        TOT%   ( USR   / SYS   / WIO   / IDLE  ) 

spartan-gpgpu095 : 
                CPU# 1    : 5.5    (   1.6 /   3.8 /   0.0 /  20.0 ) 
                CPU# 2    : 4.6    (   1.2 /   3.4 /   0.0 /  19.6 ) 
                CPU# 3    : 4.7    (   1.1 /   3.7 /   0.0 /  21.4 ) 
                CPU# 4    : 4.7    (   1.1 /   3.6 /   0.0 /  20.8 ) 
                CPU# 5    : 5.0    (   1.0 /   4.0 /   0.0 /  19.7 ) 
                CPU# 6    : 4.5    (   1.1 /   3.4 /   0.0 /  19.6 ) 
                CPU# 7    : 4.3    (   1.0 /   3.3 /   0.0 /  20.3 ) 
                CPU# 8    : 5.1    (   1.3 /   3.8 /   0.0 /  19.9 ) 
                CPU# 9    : 5.3    (   1.2 /   4.1 /   0.0 /  20.8 ) 
                CPU# 10   : 4.4    (   1.0 /   3.4 /   0.0 /  20.7 ) 
                CPU# 11   : 4.6    (   1.1 /   3.6 /   0.0 /  20.8 ) 
                CPU# 12   : 4.7    (   1.2 /   3.5 /   0.0 /  19.8 ) 
                CPU# 13   : 4.8    (   1.1 /   3.7 /   0.0 /  20.9 ) 
                CPU# 14   : 4.7    (   1.1 /   3.6 /   0.0 /  20.0 ) 
                CPU# 15   : 4.8    (   1.0 /   3.9 /   0.0 /  20.8 ) 
                CPU# 16   : 4.8    (   1.3 /   3.5 /   0.1 /  20.9 ) 
                CPU# 17   : 8.3    (   3.8 /   4.5 /   0.0 /  20.2 ) 
                CPU# 18   : 8.7    (   4.2 /   4.4 /   0.0 /  21.0 ) 
                CPU# 19   : 8.1    (   3.8 /   4.3 /   0.0 /  21.4 ) 
                CPU# 20   : 9.2    (   3.6 /   5.6 /   0.1 /  21.4 ) 
                CPU# 21   : 8.1    (   3.5 /   4.7 /   0.0 /  20.9 ) 
                CPU# 22   : 7.5    (   3.0 /   4.5 /   0.0 /  21.0 ) 
                CPU# 23   : 7.9    (   3.5 /   4.5 /   0.1 /  21.2 ) 
                CPU# 24   : 7.6    (   3.3 /   4.2 /   0.0 /  20.9 ) 
                CPU# 25   : 7.6    (   3.4 /   4.2 /   0.0 /  21.1 ) 
                CPU# 26   : 7.8    (   3.5 /   4.4 /   0.0 /  21.5 ) 
                CPU# 27   : 8.6    (   2.6 /   5.9 /   0.0 /  21.6 ) 
                CPU# 28   : 7.4    (   2.6 /   4.8 /   0.0 /  20.7 ) 
                CPU# 29   : 8.1    (   3.3 /   4.8 /   0.0 /  21.6 ) 
                CPU# 30   : 10.0   (   5.3 /   4.7 /   0.1 /  22.3 ) 
                CPU# 31   : 9.7    (   4.9 /   4.7 /   0.0 /  21.8 ) 
                CPU# 32   : 15.4   (  10.7 /   4.7 /   0.1 /  13.8 ) 

                GPU# 1    : 0.0   


Allocated CPUs            : 32   
  CPUs with usage <25%    : 32   
  CPUs with usage <50%    : 0    
  CPUs with usage >50%    : 0    


Allocated GPUs            : 1    
  GPUs with usage <25%    : 1    
  GPUs with usage <50%    : 0    
  GPUs with usage >50%    : 0    

Memory used (RAM)         : 16.2%  [21768MB of 134218MB]

--------------------------------------------

